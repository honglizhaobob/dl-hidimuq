{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05651ff2",
   "metadata": {},
   "source": [
    "# Regression with Fourier Features - Part 2\n",
    "\n",
    "Initially observed in: https://arxiv.org/abs/2006.10739\n",
    "\n",
    "The inclusion of Fourier features allows neural networks to capture high frequency information of the target function. In this short note, we compare a vanilla DNN with another Fourier-feature embedded DNN on the task of learning a (noise-perturbed) PDE solution in both space and time domains. The Fourier features embedding is done in both directions and results are aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1987ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10);\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import neural nets\n",
    "from PINN.utils.dnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d72af32",
   "metadata": {},
   "source": [
    "Generate data from the following PDE:\n",
    "$$\n",
    "    \\frac{\\partial u}{\\partial t} + u_0\\sin(\\omega t)\\frac{\\partial u}{\\partial x} = 0\n",
    "$$ whose analytical solution is given by:\n",
    "$$\n",
    "    u(t,x) = \\exp\\bigg(\n",
    "            -k[x - x_0 - 2v_0\\omega^{-1}\\sin^2(\\frac{1}{2}\\omega t)]^2\n",
    "        \\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac076416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "x0 = 2.0\n",
    "v0 = 2.0\n",
    "k = 5.0\n",
    "omega = 2.0*np.pi\n",
    "# time grid\n",
    "t_start = 0.0\n",
    "t_end = 2*np.pi\n",
    "dt = 0.001\n",
    "tgrid = np.arange(t_start, t_end, dt)\n",
    "nt = len(tgrid)\n",
    "# spatial grid\n",
    "x_left, x_right = 0.0, 5.0\n",
    "dx = 0.005\n",
    "xgrid = np.arange(x_left, x_right, dx)\n",
    "nx = len(xgrid)\n",
    "\n",
    "# solution\n",
    "u_sol = np.zeros([nt, nx])\n",
    "for i in range(nt):\n",
    "    t = tgrid[i]\n",
    "    u_sol[i, :] = np.exp(-k * (( xgrid - x0 ) - (2*v0/omega) * (np.sin(0.5*omega*t) ** 2)) ** 2 )\n",
    "\n",
    "# subsample grids\n",
    "subsample_t = 6\n",
    "subsample_x = 2\n",
    "xgrid_small = xgrid.reshape(1, -1)[:, 0:-1:subsample_x].squeeze(),\n",
    "tgrid_small = tgrid.reshape(1, -1)[:, 0:-1:subsample_t].squeeze()\n",
    "u_sol_small = u_sol[0:-1:subsample_t, 0:-1:subsample_x]\n",
    "print(u_sol_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1);\n",
    "plt.contourf(u_sol_small);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "X = cartesian_data(torch.tensor(tgrid_small.flatten()), torch.tensor(xgrid_small[0].flatten()))\n",
    "y = torch.tensor(u_sol_small).T.flatten().reshape(-1, 1)\n",
    "#y = torch.tensor(u_sol_small2).T.flatten().reshape(-1, 1)\n",
    "\n",
    "# define training function\n",
    "def train(inputs, outputs, model, optim, scheduler, batch_size, epochs, shuffle=True):\n",
    "    X, y = inputs, outputs\n",
    "    nx = X.shape[0]\n",
    "    num_batches = int(nx/batch_size)\n",
    "    for i in range(epochs):\n",
    "        print(\"============================================================\\n\")\n",
    "        print(\"Epoch = {}\\n\".format(i+1));\n",
    "        print(\"============================================================\\n\")\n",
    "        model.train()\n",
    "        if shuffle:\n",
    "            tmp = np.random.permutation(nx)\n",
    "            X, y = X[tmp, :].data.clone(), y[tmp, :].data.clone()\n",
    "        for idx in range(num_batches):\n",
    "            if idx % 100 == 0:\n",
    "                print(\"| => | Batch {} |\\n\".format(idx+1))\n",
    "        # closure definition\n",
    "            def closure():\n",
    "                optim.zero_grad()\n",
    "                start_idx = idx*batch_size\n",
    "                end_idx = (idx+1)*batch_size\n",
    "                if idx + 1 == num_batches:\n",
    "                    # if last batch\n",
    "                    end_idx = -1\n",
    "                Xb, yb = X[start_idx:end_idx, :].data.clone(), y[start_idx:end_idx, :].data.clone()\n",
    "\n",
    "                # require gradients\n",
    "                Xb.requires_grad = True\n",
    "                # make a prediction on the batch\n",
    "                y_pred = model.forward(Xb)\n",
    "                # compute L^2 loss\n",
    "                loss = torch.mean((y_pred - yb)**2)\n",
    "                # backpropagate\n",
    "                loss.backward()\n",
    "                if idx % 100 == 0:\n",
    "                    print(\"==> Batch {} loss = {}\".format(idx, loss.item()))\n",
    "                return loss\n",
    "            optim.step(closure=closure)\n",
    "        if scheduler:\n",
    "            # step scheduler after epoch if there is one\n",
    "            scheduler.step()\n",
    "            print(\"---------- \\n\")\n",
    "            print(\"++ Learning rate reduced, now at = {}\".format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test vanilla neural net\n",
    "nn_vanilla = DNN(layers=[2, 32, 32, 1])\n",
    "optim = torch.optim.Adam(\n",
    "    nn_vanilla.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(X, y, nn_vanilla, optim, scheduler, 2**12, 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions and compare contour plots\n",
    "nt_small = len(tgrid_small.flatten())\n",
    "nx_small = len(xgrid_small[0].flatten())\n",
    "u_sol_predict = nn_vanilla(X).reshape([nx_small, nt_small]).detach().numpy().T\n",
    "u_sol_exact = y.reshape([nx_small, nt_small]).detach().numpy().T\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].contourf(u_sol_predict);\n",
    "ax[1].contourf(u_sol_exact);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing Fourier embedded net in 2d\n",
    "nn_fourier2d = FourierEmbeddedDNN2d(\n",
    "    layers=[30, 32, 32, 1],\n",
    "    m=15, \n",
    "    freq_stds=np.array([[1.,2.,5.,10.,20.], [1.,1.,1.,1.,1.]]).T\n",
    ")\n",
    "optim = torch.optim.Adam(\n",
    "    nn_fourier2d.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(X, y, nn_fourier2d, optim, scheduler, 2**12, 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0132013",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_small = len(tgrid_small.flatten())\n",
    "nx_small = len(xgrid_small[0].flatten())\n",
    "u_sol_predict_fourier = nn_fourier2d(X).reshape([nx_small, nt_small]).detach().numpy().T\n",
    "u_sol_exact_fourier = y.reshape([nx_small, nt_small]).detach().numpy().T\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].contourf(u_sol_predict_fourier)\n",
    "ax[1].contourf(u_sol_exact_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e251ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((u_sol_predict_fourier-u_sol_exact_fourier)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ee36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tgrid_small[1]-tgrid_small[0]\n",
    "for idx in range(nt_small):\n",
    "    if idx % 5 == 0:\n",
    "        plt.figure(1);\n",
    "        plt.plot(xgrid_small[0].flatten(), u_sol_predict_fourier[idx, :], lw=2., color=\"black\");\n",
    "        plt.plot(xgrid_small[0].flatten(), u_sol_exact_fourier[idx, :], \"--\", lw=8.0, color=\"red\", alpha=0.6);\n",
    "        plt.plot(xgrid_small[0].flatten(), u_sol_predict[idx, :], lw=2., color=\"blue\", alpha=0.5);\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        plt.clf()\n",
    "        plt.title(r\"$t = {}$\".format(dt*(idx+1)))\n",
    "        time.sleep(0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6023fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49b7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699d902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd316449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918fde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
