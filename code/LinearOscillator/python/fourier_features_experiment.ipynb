{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9753357",
   "metadata": {},
   "source": [
    "# Regression with Fourier Features\n",
    "\n",
    "Initially observed in: https://arxiv.org/abs/2006.10739\n",
    "\n",
    "The inclusion of Fourier features allows neural networks to capture high frequency information of the target function. In this short note, we compare a vanilla DNN with another Fourier-feature embedded DNN on the task of learning a (noise-perturbed) high frequency function.\n",
    "\n",
    "This notebook should be self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d068d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10);\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4737684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vanilla deep neural net\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, layers, \n",
    "        activation=torch.nn.Tanh, \n",
    "        last_layer_activation=None,\n",
    "        initialization=None\n",
    "    ):\n",
    "        \"\"\" \n",
    "            Custom initialization of neural network layers with the option \n",
    "            of changing the output layer's activation function.\n",
    "        \"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = activation\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        if last_layer_activation is not None:\n",
    "            layer_list.append(\n",
    "            ('activation_%d' % (self.depth - 1), last_layer_activation())\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "        # custom initialization modes\n",
    "        self.initialize(mode=initialization)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def initialize(self, mode):\n",
    "        if mode == None:\n",
    "            return\n",
    "        else:\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, torch.nn.Linear):\n",
    "                    # initialize depending on mode\n",
    "                    if mode == \"xavier\":\n",
    "                        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "                    elif mode == \"kaiming\":\n",
    "                        torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "                    elif mode == \"normal\":\n",
    "                        torch.nn.init.normal_(layer.weight)\n",
    "                    elif mode == \"uniform\":\n",
    "                        torch.nn.init.uniform_(layer.weight)\n",
    "                    elif mode == \"ones\":\n",
    "                        torch.nn.init.ones_(layer.weight)\n",
    "                    else:\n",
    "                        raise NotImplementedError()\n",
    "            return\n",
    "        \n",
    "class FourierEmbeddedDNN(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 activation=torch.nn.Tanh, \n",
    "                 last_layer_activation=None, \n",
    "                 initialization=None,\n",
    "                 m=1,\n",
    "                 freq_stds=None):\n",
    "        super(FourierEmbeddedDNN, self).__init__()\n",
    "        # fourier embedding is applied prior to passing into neural net, \n",
    "        # need to make sure dimensions match\n",
    "        assert layers[0] == 2*m\n",
    "        # build main DNN\n",
    "        self.layer_spec = layers\n",
    "        self.layers = self.build_nn(\n",
    "            layers, activation, last_layer_activation, initialization\n",
    "        )\n",
    "        # build fourier feature embedding\n",
    "        self.fourier_embedding = self.build_embedding(m, freq_stds)\n",
    "        \n",
    "        # build final aggregator to combine outputs of different scale fourier embeddings\n",
    "        self.build_aggregator()\n",
    "    \n",
    "    def build_nn(self, layers, activation, last_layer_activation, initialization):\n",
    "        self.depth = len(layers) - 1\n",
    "        # set up layer order dict\n",
    "        self.activation = activation\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        if last_layer_activation is not None:\n",
    "            layer_list.append(\n",
    "            ('activation_%d' % (self.depth - 1), last_layer_activation())\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        return torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    def build_embedding(self, num_freqs, freq_stds):\n",
    "        # number of feature embeddings correspond to length of standard \n",
    "        # deviations specified. If `None`, by default uses only 1 embedding\n",
    "        # standard Gaussian.\n",
    "        if freq_stds:\n",
    "            self.num_embeddings = len(freq_stds)\n",
    "        else:\n",
    "            self.num_embeddings = 1\n",
    "            freq_stds = [1.0]\n",
    "        # draw frequency matrix\n",
    "        freq_matrix = [torch.randn(num_freqs, requires_grad=False) for _ in range(self.num_embeddings)]\n",
    "        for i in range(self.num_embeddings):\n",
    "            # scale by frequency standard deviation\n",
    "            freq_matrix[i] = torch.tensor(freq_stds[i])*freq_matrix[i]\n",
    "        return freq_matrix\n",
    "    \n",
    "    def build_aggregator(self):\n",
    "        # number of fourier embeddings\n",
    "        k = self.num_embeddings\n",
    "        # size of hidden layer final outputs\n",
    "        num_out = self.layer_spec[-1]\n",
    "        # create trainable aggregating weights for each embedding (simple linear aggregation\n",
    "        # , may also consider computing another nonlinear activation for each embedding, then \n",
    "        # summing all outputs).\n",
    "        self.aggregator = torch.nn.Linear(num_out*k, 1)\n",
    "        \n",
    "    def fourier_lifting(self, x, freq):\n",
    "        # input x has size (N x 1), output has size (N x 2*m) where m is number of Fourier bases\n",
    "        \n",
    "        # has size (N x m)\n",
    "        x = freq * x\n",
    "        # lift to sin and cos space\n",
    "        x = torch.concat(\n",
    "            [\n",
    "                torch.cos(2*torch.pi*x), \n",
    "                torch.sin(2*torch.pi*x)\n",
    "            ], dim=1\n",
    "        )\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # inputs x has size (N x 1)\n",
    "        # create Fourier features\n",
    "        lifted = []\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted.append(self.fourier_lifting(x, self.fourier_embedding[i]))\n",
    "        # lifted is a length-k list of (N x 2*m) tensors of lifted features according to \n",
    "        # k different scales.\n",
    "        \n",
    "        # now pass each (N x 2*m) features into the hidden layers\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted[i] = self.layers(lifted[i])\n",
    "        \n",
    "        # lifted is a length-k list of (N x num_out) tensor of transformed fourier features\n",
    "        # now concatenate into (N x num_out*k) and pass into aggregator to obtain (N x 1) prediction\n",
    "        lifted = torch.concat(lifted, dim=1)\n",
    "        # final aggregation\n",
    "        lifted = self.aggregator(lifted)\n",
    "        return lifted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a10ffe",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c02e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# oscillations with decay\n",
    "#f = lambda x: 100*(np.exp(-2.0*x)*np.sin(10*np.pi*x))+np.cos(5.0*np.pi*x)\n",
    "\n",
    "# different frequencies\n",
    "f = lambda x: np.sin(2*np.pi*x) + np.cos(10.*np.pi*x) + 2.0*np.sin(15.*np.pi*x) + np.sin(100.0*np.pi*x)\n",
    "\n",
    "# linear function\n",
    "#f = lambda x: 10.0*x\n",
    "x_start, x_end = 0.0, 1.0\n",
    "nx = 2048\n",
    "xgrid = np.linspace(x_start, x_end, nx)\n",
    "dx = xgrid[1]-xgrid[0]\n",
    "# visualize function with noise perturbation\n",
    "f_data = f(xgrid)\n",
    "noise_level = 0.0\n",
    "f_data = f_data + noise_level * np.random.randn(f_data.shape[0])\n",
    "plt.plot(xgrid, f_data, \"--\", color=\"red\", lw=3.0, label=\"exact\", alpha=0.6);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a12a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "inputs = torch.tensor(xgrid).reshape(-1, 1)\n",
    "outputs = torch.tensor(f_data).reshape(-1, 1)\n",
    "\n",
    "# define training function\n",
    "def train(inputs, outputs, model, optim, scheduler, batch_size, epochs, shuffle=True):\n",
    "    X, y = inputs, outputs\n",
    "    nx = X.shape[0]\n",
    "    num_batches = int(nx/batch_size)\n",
    "    for i in range(epochs):\n",
    "        print(\"============================================================\\n\")\n",
    "        print(\"Epoch = {}\\n\".format(i+1));\n",
    "        print(\"============================================================\\n\")\n",
    "        model.train()\n",
    "        if shuffle:\n",
    "            tmp = np.random.permutation(nx)\n",
    "            X, y = X[tmp, :].data.clone(), y[tmp, :].data.clone()\n",
    "        for idx in range(num_batches):\n",
    "            print(\"| => | Batch {} |\\n\".format(idx+1))\n",
    "        # closure definition\n",
    "            def closure():\n",
    "                optim.zero_grad()\n",
    "                start_idx = idx*batch_size\n",
    "                end_idx = (idx+1)*batch_size\n",
    "                if idx + 1 == num_batches:\n",
    "                    # if last batch\n",
    "                    end_idx = -1\n",
    "                Xb, yb = X[start_idx:end_idx, :].data.clone(), y[start_idx:end_idx, :].data.clone()\n",
    "\n",
    "                # require gradients\n",
    "                Xb.requires_grad = True\n",
    "                # make a prediction on the batch\n",
    "                y_pred = model.forward(Xb)\n",
    "                # compute L^2 loss\n",
    "                loss = torch.mean((y_pred - yb)**2)\n",
    "                # backpropagate\n",
    "                loss.backward()\n",
    "                print(\"==> Batch {} loss = {}\".format(idx, loss.item()))\n",
    "                return loss\n",
    "            optim.step(closure=closure)\n",
    "        if scheduler:\n",
    "            # step scheduler after epoch if there is one\n",
    "            scheduler.step()\n",
    "            print(\"---------- \\n\")\n",
    "            print(\"++ Learning rate reduced, now at = {}\".format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be654f9",
   "metadata": {},
   "source": [
    "Testing neural net performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fea2549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Epoch = 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.956295842874241\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 11.012131856475504\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079992\n",
      "============================================================\n",
      "\n",
      "Epoch = 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.67791213726915\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.852707488209644\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007998400079999999\n",
      "============================================================\n",
      "\n",
      "Epoch = 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 4.583756827890049\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.802496533962568\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007997600239991999\n",
      "============================================================\n",
      "\n",
      "Epoch = 4\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.346218629304337\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 4.833649608816145\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996800479968\n",
      "============================================================\n",
      "\n",
      "Epoch = 5\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.334635673925173\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 4.264169319634595\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996000799920003\n",
      "============================================================\n",
      "\n",
      "Epoch = 6\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.426899277110977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.5665435287470886\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007995201199840011\n",
      "============================================================\n",
      "\n",
      "Epoch = 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.8070995707326527\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.505230040714134\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007994401679720027\n",
      "============================================================\n",
      "\n",
      "Epoch = 8\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.911271437003205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.52964503362326\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007993602239552054\n",
      "============================================================\n",
      "\n",
      "Epoch = 9\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.5622679117585196\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.5357272020628603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992802879328098\n",
      "============================================================\n",
      "\n",
      "Epoch = 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.324117655200492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.6776406388614515\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992003599040166\n",
      "============================================================\n",
      "\n",
      "Epoch = 11\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.3276625198204592\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.7411792346088144\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007991204398680262\n",
      "============================================================\n",
      "\n",
      "Epoch = 12\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.3385134774498337\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.6273367665209326\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007990405278240395\n",
      "============================================================\n",
      "\n",
      "Epoch = 13\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.316326998973574\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.546322615471452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007989606237712572\n",
      "============================================================\n",
      "\n",
      "Epoch = 14\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.34441505063016\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.532648894412133\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079888072770888\n",
      "============================================================\n",
      "\n",
      "Epoch = 15\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.389423095052835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.505483328922314\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007988008396361091\n",
      "============================================================\n",
      "\n",
      "Epoch = 16\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.385061072540922\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.483873224949613\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007987209595521455\n",
      "============================================================\n",
      "\n",
      "Epoch = 17\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.3503911100893626\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.5017258815898487\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007986410874561903\n",
      "============================================================\n",
      "\n",
      "Epoch = 18\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.3197476502502603\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.5303454351307395\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007985612233474448\n",
      "============================================================\n",
      "\n",
      "Epoch = 19\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.3002651582567646\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.531495079321227\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079848136722511\n",
      "============================================================\n",
      "\n",
      "Epoch = 20\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.289175533350709\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.50910935321543\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007984015190883875\n",
      "============================================================\n",
      "\n",
      "Epoch = 21\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.284769891662048\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4914721863045535\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007983216789364787\n",
      "============================================================\n",
      "\n",
      "Epoch = 22\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2846886773331327\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4884361901452374\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00798241846768585\n",
      "============================================================\n",
      "\n",
      "Epoch = 23\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2840328633706766\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4857051795945004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007981620225839082\n",
      "============================================================\n",
      "\n",
      "Epoch = 24\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.278865886613852\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.475461508560788\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980822063816497\n",
      "============================================================\n",
      "\n",
      "Epoch = 25\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2714559338380154\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4662887053874734\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980023981610115\n",
      "============================================================\n",
      "\n",
      "Epoch = 26\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2666033381824926\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4638853965348697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007979225979211954\n",
      "============================================================\n",
      "\n",
      "Epoch = 27\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2639831794261047\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4630445685852917\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007978428056614032\n",
      "============================================================\n",
      "\n",
      "Epoch = 28\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2595403435149786\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4589153233532497\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007977630213808371\n",
      "============================================================\n",
      "\n",
      "Epoch = 29\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2521676801689763\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4541832914115576\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797683245078699\n",
      "============================================================\n",
      "\n",
      "Epoch = 30\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2446901155755348\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4526165863022897\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007976034767541912\n",
      "============================================================\n",
      "\n",
      "Epoch = 31\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.238935992609333\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4523411851795274\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007975237164065159\n",
      "============================================================\n",
      "\n",
      "Epoch = 32\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2334204368362487\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4500084038147385\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007974439640348753\n",
      "============================================================\n",
      "\n",
      "Epoch = 33\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2270151261435127\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.446724176398524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007973642196384719\n",
      "============================================================\n",
      "\n",
      "Epoch = 34\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.221030435180665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4448695472388327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797284483216508\n",
      "============================================================\n",
      "\n",
      "Epoch = 35\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2160416834278625\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.44357809563342\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007972047547681863\n",
      "============================================================\n",
      "\n",
      "Epoch = 36\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.210746184215248\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441617270955183\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007971250342927096\n",
      "============================================================\n",
      "\n",
      "Epoch = 37\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2043739474406596\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4405423744317125\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007970453217892803\n",
      "============================================================\n",
      "\n",
      "Epoch = 38\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.196888120777434\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 3.4415377580317275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007969656172571013\n",
      "============================================================\n",
      "\n",
      "Epoch = 39\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.188464456025904\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.442791963884722\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968859206953756\n",
      "============================================================\n",
      "\n",
      "Epoch = 40\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1805061449618153\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.442308707247383\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968062321033061\n",
      "============================================================\n",
      "\n",
      "Epoch = 41\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.173978464787674\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4405593350733485\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007967265514800958\n",
      "============================================================\n",
      "\n",
      "Epoch = 42\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1682927849350264\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.439338236165823\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007966468788249479\n",
      "============================================================\n",
      "\n",
      "Epoch = 43\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.161367400937128\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4396342380335603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007965672141370653\n",
      "============================================================\n",
      "\n",
      "Epoch = 44\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.15195778651084\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4410368663682234\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007964875574156515\n",
      "============================================================\n",
      "\n",
      "Epoch = 45\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1423879522802745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441925865362239\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079640790865991\n",
      "============================================================\n",
      "\n",
      "Epoch = 46\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1340223325978167\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4415415276851853\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007963282678690441\n",
      "============================================================\n",
      "\n",
      "Epoch = 47\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.125974975847973\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441171995734814\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007962486350422572\n",
      "============================================================\n",
      "\n",
      "Epoch = 48\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1167517217058514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4413487788475483\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00796169010178753\n",
      "============================================================\n",
      "\n",
      "Epoch = 49\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.1073418816106875\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441316218582452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960893932777352\n",
      "============================================================\n",
      "\n",
      "Epoch = 50\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.097897173681907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441563309872016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960097843384074\n",
      "============================================================\n",
      "\n",
      "Epoch = 51\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0874165784315766\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441995971029319\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007959301833599735\n",
      "============================================================\n",
      "\n",
      "Epoch = 52\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0770864653786787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.441194293239007\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007958505903416374\n",
      "============================================================\n",
      "\n",
      "Epoch = 53\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0677938378919745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4399880502470337\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007957710052826033\n",
      "============================================================\n",
      "\n",
      "Epoch = 54\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0575827464947136\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.439177182135072\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007956914281820751\n",
      "============================================================\n",
      "\n",
      "Epoch = 55\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.047123909061382\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4382675553015574\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00795611859039257\n",
      "============================================================\n",
      "\n",
      "Epoch = 56\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.036649027143308\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4375132178642787\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007955322978533531\n",
      "============================================================\n",
      "\n",
      "Epoch = 57\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.025590104358891\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4359661089078655\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007954527446235678\n",
      "============================================================\n",
      "\n",
      "Epoch = 58\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.015730984770955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.434066974230657\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007953731993491055\n",
      "============================================================\n",
      "\n",
      "Epoch = 59\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.004897114358048\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4317539513442683\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952936620291706\n",
      "============================================================\n",
      "\n",
      "Epoch = 60\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9954196768107657\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4301126243996034\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952141326629678\n",
      "============================================================\n",
      "\n",
      "Epoch = 61\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.984078625931914\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.427074795183558\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007951346112497015\n",
      "============================================================\n",
      "\n",
      "Epoch = 62\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9792767432345\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4266599881394506\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007950550977885766\n",
      "============================================================\n",
      "\n",
      "Epoch = 63\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.979297164690362\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4204852906857464\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007949755922787977\n",
      "============================================================\n",
      "\n",
      "Epoch = 64\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0545501064865435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.424824764294656\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948960947195698\n",
      "============================================================\n",
      "\n",
      "Epoch = 65\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.16093643196172\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.421566002055071\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948166051100979\n",
      "============================================================\n",
      "\n",
      "Epoch = 66\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9953131161330147\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4122941999346037\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007947371234495869\n",
      "============================================================\n",
      "\n",
      "Epoch = 67\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.929224379189963\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4163689444092418\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00794657649737242\n",
      "============================================================\n",
      "\n",
      "Epoch = 68\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9532715744924323\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4074209171265006\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007945781839722683\n",
      "============================================================\n",
      "\n",
      "Epoch = 69\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.050526785066102\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.406027662829742\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944987261538711\n",
      "============================================================\n",
      "\n",
      "Epoch = 70\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0584114702394984\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.4040462454551\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944192762812557\n",
      "============================================================\n",
      "\n",
      "Epoch = 71\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.945258281358913\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.398534119283471\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007943398343536277\n",
      "============================================================\n",
      "\n",
      "Epoch = 72\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.892878865629707\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3988577459145284\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007942604003701923\n",
      "============================================================\n",
      "\n",
      "Epoch = 73\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.915409150195505\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3894575002844327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941809743301553\n",
      "============================================================\n",
      "\n",
      "Epoch = 74\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9696824802853685\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3854256477909543\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941015562327224\n",
      "============================================================\n",
      "\n",
      "Epoch = 75\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9631338232406677\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3818158664822806\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007940221460770992\n",
      "============================================================\n",
      "\n",
      "Epoch = 76\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.909336925157849\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3754579136064393\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007939427438624915\n",
      "============================================================\n",
      "\n",
      "Epoch = 77\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.862731059752016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.369606980341328\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007938633495881052\n",
      "============================================================\n",
      "\n",
      "Epoch = 78\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.852847306015332\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3629563853427697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007937839632531463\n",
      "============================================================\n",
      "\n",
      "Epoch = 79\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8635054028806737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3561322124672324\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793704584856821\n",
      "============================================================\n",
      "\n",
      "Epoch = 80\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8761719793864176\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.348141692365889\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007936252143983354\n",
      "============================================================\n",
      "\n",
      "Epoch = 81\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8843476481720067\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.340375133729234\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007935458518768956\n",
      "============================================================\n",
      "\n",
      "Epoch = 82\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8760351815831946\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3308705698924617\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793466497291708\n",
      "============================================================\n",
      "\n",
      "Epoch = 83\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.862341328438534\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.3203667629529448\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933871506419788\n",
      "============================================================\n",
      "\n",
      "Epoch = 84\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.840690624827916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.309811746135115\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933078119269146\n",
      "============================================================\n",
      "\n",
      "Epoch = 85\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8234971307903596\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.2970009787974184\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007932284811457219\n",
      "============================================================\n",
      "\n",
      "Epoch = 86\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8075042210863153\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.284259994281953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007931491582976073\n",
      "============================================================\n",
      "\n",
      "Epoch = 87\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7955512958458644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.2689903919227463\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007930698433817775\n",
      "============================================================\n",
      "\n",
      "Epoch = 88\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.78816865104461\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.2535311892856704\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929905363974393\n",
      "============================================================\n",
      "\n",
      "Epoch = 89\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7847040211655294\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.2341840644707376\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929112373437996\n",
      "============================================================\n",
      "\n",
      "Epoch = 90\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.792598152575355\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.217522534146658\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007928319462200652\n",
      "============================================================\n",
      "\n",
      "Epoch = 91\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8250360522268227\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.1939522592861898\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007927526630254433\n",
      "============================================================\n",
      "\n",
      "Epoch = 92\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.909629271751819\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.1893258924997747\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007926733877591408\n",
      "============================================================\n",
      "\n",
      "Epoch = 93\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0121250987332404\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.2419223801720336\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792594120420365\n",
      "============================================================\n",
      "\n",
      "Epoch = 94\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.006386054532402\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.468916599616416\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007925148610083229\n",
      "============================================================\n",
      "\n",
      "Epoch = 95\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.833627437475359\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.235382005904536\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007924356095222221\n",
      "============================================================\n",
      "\n",
      "Epoch = 96\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7498427964374668\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.1112039682684958\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079235636596127\n",
      "============================================================\n",
      "\n",
      "Epoch = 97\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.813347436349233\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.178816500700222\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007922771303246739\n",
      "============================================================\n",
      "\n",
      "Epoch = 98\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8642379444724937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.168256346315467\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921979026116414\n",
      "============================================================\n",
      "\n",
      "Epoch = 99\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.9835185702218405\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.073584668383615\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921186828213802\n",
      "============================================================\n",
      "\n",
      "Epoch = 100\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.759283170183002\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.0635814335292255\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792039470953098\n",
      "============================================================\n",
      "\n",
      "Epoch = 101\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6886035673205653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.010299366656524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007919602670060026\n",
      "============================================================\n",
      "\n",
      "Epoch = 102\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8106287320340417\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.9642588090791957\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791881070979302\n",
      "============================================================\n",
      "\n",
      "Epoch = 103\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8863674533735137\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.9213990291220733\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791801882872204\n",
      "============================================================\n",
      "\n",
      "Epoch = 104\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.8074280796200166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.911842070173011\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007917227026839167\n",
      "============================================================\n",
      "\n",
      "Epoch = 105\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.674347176044803\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.901254407402526\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007916435304136483\n",
      "============================================================\n",
      "\n",
      "Epoch = 106\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6449166160598336\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.897702057753074\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791564366060607\n",
      "============================================================\n",
      "\n",
      "Epoch = 107\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.745804226757145\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.9468592840487253\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914852096240009\n",
      "============================================================\n",
      "\n",
      "Epoch = 108\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.82837713158533\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.842851096721865\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914060611030385\n",
      "============================================================\n",
      "\n",
      "Epoch = 109\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.737164302095288\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.8024800931228997\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007913269204969282\n",
      "============================================================\n",
      "\n",
      "Epoch = 110\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6075069609896024\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.7546522631315367\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007912477878048784\n",
      "============================================================\n",
      "\n",
      "Epoch = 111\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.623141182627882\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.7904535680237075\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791168663026098\n",
      "============================================================\n",
      "\n",
      "Epoch = 112\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6419078773160307\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.7563375301353474\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910895461597954\n",
      "============================================================\n",
      "\n",
      "Epoch = 113\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.784154107609954\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.6732590063734745\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910104372051793\n",
      "============================================================\n",
      "\n",
      "Epoch = 114\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7916942798826923\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.544246375579107\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007909313361614588\n",
      "============================================================\n",
      "\n",
      "Epoch = 115\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.582722281077646\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.6795712626246657\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007908522430278427\n",
      "============================================================\n",
      "\n",
      "Epoch = 116\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.559853994645156\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 3.0624196462779563\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007907731578035399\n",
      "============================================================\n",
      "\n",
      "Epoch = 117\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6278425685419773\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.666903081248085\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906940804877595\n",
      "============================================================\n",
      "\n",
      "Epoch = 118\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.575169374149743\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4975623617291016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906150110797107\n",
      "============================================================\n",
      "\n",
      "Epoch = 119\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6299497276200627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.559962423930295\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007905359495786028\n",
      "============================================================\n",
      "\n",
      "Epoch = 120\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6099240810721693\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.7221202841525773\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007904568959836449\n",
      "============================================================\n",
      "\n",
      "Epoch = 121\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5559346288588634\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.8850439514120274\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007903778502940466\n",
      "============================================================\n",
      "\n",
      "Epoch = 122\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5637114708521946\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.644687048150158\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902988125090172\n",
      "============================================================\n",
      "\n",
      "Epoch = 123\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.535176008910634\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.438892352812656\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902197826277664\n",
      "============================================================\n",
      "\n",
      "Epoch = 124\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.538927121200052\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.579071950603235\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007901407606495036\n",
      "============================================================\n",
      "\n",
      "Epoch = 125\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5021565979719558\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4741948344905116\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007900617465734385\n",
      "============================================================\n",
      "\n",
      "Epoch = 126\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.580245287996532\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3192664607454394\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899827403987812\n",
      "============================================================\n",
      "\n",
      "Epoch = 127\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5983952833512665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4779661920404368\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899037421247413\n",
      "============================================================\n",
      "\n",
      "Epoch = 128\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.481965579050958\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.7624589216798774\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789824751750529\n",
      "============================================================\n",
      "\n",
      "Epoch = 129\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.548225986675962\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.674512477678045\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007897457692753539\n",
      "============================================================\n",
      "\n",
      "Epoch = 130\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.589536081598794\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.6673069717533986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007896667946984263\n",
      "============================================================\n",
      "\n",
      "Epoch = 131\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.48028462578818\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.6471550914055912\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895878280189565\n",
      "============================================================\n",
      "\n",
      "Epoch = 132\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.459631987504001\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.6708103156925738\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895088692361546\n",
      "============================================================\n",
      "\n",
      "Epoch = 133\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4927485343338063\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.616605056687181\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789429918349231\n",
      "============================================================\n",
      "\n",
      "Epoch = 134\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.476742143312871\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4856703501197424\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007893509753573962\n",
      "============================================================\n",
      "\n",
      "Epoch = 135\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4519527851150897\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4322775767756917\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007892720402598604\n",
      "============================================================\n",
      "\n",
      "Epoch = 136\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4300595900014663\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.409835692499995\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891931130558345\n",
      "============================================================\n",
      "\n",
      "Epoch = 137\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4282454895987042\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4447335428588737\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891141937445289\n",
      "============================================================\n",
      "\n",
      "Epoch = 138\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4319219182063336\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3493282891642835\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007890352823251545\n",
      "============================================================\n",
      "\n",
      "Epoch = 139\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4420088838335148\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3001164669348833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788956378796922\n",
      "============================================================\n",
      "\n",
      "Epoch = 140\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.444747158539868\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3123956043735276\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007888774831590423\n",
      "============================================================\n",
      "\n",
      "Epoch = 141\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.450375258261774\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.307096281339261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887985954107264\n",
      "============================================================\n",
      "\n",
      "Epoch = 142\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5389428590509233\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.261741429468959\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887197155511854\n",
      "============================================================\n",
      "\n",
      "Epoch = 143\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6095543843132964\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4256117575547225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007886408435796303\n",
      "============================================================\n",
      "\n",
      "Epoch = 144\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.659302285822301\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.743891280024962\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007885619794952723\n",
      "============================================================\n",
      "\n",
      "Epoch = 145\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7016558667934367\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.82511483952431\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884831232973228\n",
      "============================================================\n",
      "\n",
      "Epoch = 146\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.562672310514682\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.329095662788164\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884042749849931\n",
      "============================================================\n",
      "\n",
      "Epoch = 147\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4609558838741377\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.337400769499743\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007883254345574946\n",
      "============================================================\n",
      "\n",
      "Epoch = 148\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.7184724296970937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.5517438620271884\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007882466020140389\n",
      "============================================================\n",
      "\n",
      "Epoch = 149\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4126833276733026\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.845351447896737\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007881677773538374\n",
      "============================================================\n",
      "\n",
      "Epoch = 150\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4460768697701463\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.5552655248732243\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788088960576102\n",
      "============================================================\n",
      "\n",
      "Epoch = 151\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3737835133763787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.5415264175915597\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007880101516800443\n",
      "============================================================\n",
      "\n",
      "Epoch = 152\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4602131033307058\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3092865675185106\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007879313506648764\n",
      "============================================================\n",
      "\n",
      "Epoch = 153\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3902327998495942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.4506158068854678\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007878525575298098\n",
      "============================================================\n",
      "\n",
      "Epoch = 154\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4097424483239007\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.3363316653328496\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007877737722740568\n",
      "============================================================\n",
      "\n",
      "Epoch = 155\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3791067473196206\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.33306146980947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876949948968294\n",
      "============================================================\n",
      "\n",
      "Epoch = 156\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.408193196327158\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.2917153222164743\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876162253973397\n",
      "============================================================\n",
      "\n",
      "Epoch = 157\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 2.407913382577404\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.207898117862099\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007875374637748\n",
      "============================================================\n",
      "\n",
      "Epoch = 158\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3690743909810674\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.2274462191144777\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007874587100284224\n",
      "============================================================\n",
      "\n",
      "Epoch = 159\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.382311953469798\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.161989006025453\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873799641574196\n",
      "============================================================\n",
      "\n",
      "Epoch = 160\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3720299277133394\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1593949983289393\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873012261610038\n",
      "============================================================\n",
      "\n",
      "Epoch = 161\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3444869012866802\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.153513485550376\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007872224960383877\n",
      "============================================================\n",
      "\n",
      "Epoch = 162\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.34321184564642\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.095326017829019\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00787143773788784\n",
      "============================================================\n",
      "\n",
      "Epoch = 163\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.326143170451433\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1222603900476757\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007870650594114051\n",
      "============================================================\n",
      "\n",
      "Epoch = 164\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3222117264348574\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.11377172293907\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786986352905464\n",
      "============================================================\n",
      "\n",
      "Epoch = 165\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.320076881918577\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0650193441025166\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007869076542701735\n",
      "============================================================\n",
      "\n",
      "Epoch = 166\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.34358989649344\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0434388889675437\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007868289635047465\n",
      "============================================================\n",
      "\n",
      "Epoch = 167\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.347803835596115\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0451751031008993\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786750280608396\n",
      "============================================================\n",
      "\n",
      "Epoch = 168\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.306692279039292\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.044558886207718\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007866716055803353\n",
      "============================================================\n",
      "\n",
      "Epoch = 169\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3228368223224662\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0533306796648496\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865929384197771\n",
      "============================================================\n",
      "\n",
      "Epoch = 170\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.338783884806649\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.020278920361448\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865142791259352\n",
      "============================================================\n",
      "\n",
      "Epoch = 171\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.339291188878744\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9957778467524814\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007864356276980226\n",
      "============================================================\n",
      "\n",
      "Epoch = 172\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3428065627167647\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.995539973929152\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007863569841352528\n",
      "============================================================\n",
      "\n",
      "Epoch = 173\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3615412795817607\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0260011376044176\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007862783484368393\n",
      "============================================================\n",
      "\n",
      "Epoch = 174\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.382315766215795\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.121781079553166\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861997206019955\n",
      "============================================================\n",
      "\n",
      "Epoch = 175\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4041450163861935\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.410946594824029\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861211006299353\n",
      "============================================================\n",
      "\n",
      "Epoch = 176\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4204574067840183\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.2414827558720103\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007860424885198723\n",
      "============================================================\n",
      "\n",
      "Epoch = 177\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3871755521181814\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.102335910926419\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007859638842710202\n",
      "============================================================\n",
      "\n",
      "Epoch = 178\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.288337486299966\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1177411400029795\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858852878825932\n",
      "============================================================\n",
      "\n",
      "Epoch = 179\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.314170008304825\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.344177666232592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858066993538049\n",
      "============================================================\n",
      "\n",
      "Epoch = 180\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3113238435889443\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.2531952234573223\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007857281186838695\n",
      "============================================================\n",
      "\n",
      "Epoch = 181\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.287566587088325\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.122758593035396\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007856495458720011\n",
      "============================================================\n",
      "\n",
      "Epoch = 182\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2930331295755955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9347925900793814\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00785570980917414\n",
      "============================================================\n",
      "\n",
      "Epoch = 183\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.325362011160845\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9326771502116096\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854924238193223\n",
      "============================================================\n",
      "\n",
      "Epoch = 184\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.326842027390841\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9612954006976866\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854138745769405\n",
      "============================================================\n",
      "\n",
      "Epoch = 185\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3458958231292355\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9732146503975483\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007853353331894828\n",
      "============================================================\n",
      "\n",
      "Epoch = 186\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3676324439353706\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.029408739454557\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007852567996561638\n",
      "============================================================\n",
      "\n",
      "Epoch = 187\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3472676845629707\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065788409532538\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007851782739761982\n",
      "============================================================\n",
      "\n",
      "Epoch = 188\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.303572698286929\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1700749399064185\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850997561488006\n",
      "============================================================\n",
      "\n",
      "Epoch = 189\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2790124781864933\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.138691164393833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850212461731856\n",
      "============================================================\n",
      "\n",
      "Epoch = 190\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2654208831342757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0804877543089373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007849427440485683\n",
      "============================================================\n",
      "\n",
      "Epoch = 191\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2692238680049623\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.958603872335148\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007848642497741636\n",
      "============================================================\n",
      "\n",
      "Epoch = 192\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.290131931728607\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8905997467491706\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847857633491861\n",
      "============================================================\n",
      "\n",
      "Epoch = 193\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3278292924101365\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8678507517339582\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847072847728512\n",
      "============================================================\n",
      "\n",
      "Epoch = 194\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3277072256897395\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.858761357936013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784628814044374\n",
      "============================================================\n",
      "\n",
      "Epoch = 195\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.292680467292148\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8542203252092029\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007845503511629695\n",
      "============================================================\n",
      "\n",
      "Epoch = 196\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2621075727196973\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8469550470406377\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007844718961278533\n",
      "============================================================\n",
      "\n",
      "Epoch = 197\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 2.2539319247561367\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8325405684533222\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843934489382405\n",
      "============================================================\n",
      "\n",
      "Epoch = 198\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2579084448256967\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8243343023435887\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843150095933466\n",
      "============================================================\n",
      "\n",
      "Epoch = 199\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2612721559395723\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8340718932976268\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007842365780923873\n",
      "============================================================\n",
      "\n",
      "Epoch = 200\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2543392106059916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8659677174849287\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784158154434578\n",
      "============================================================\n",
      "\n",
      "Epoch = 201\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2489671512643454\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9436337699934079\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840797386191346\n",
      "============================================================\n",
      "\n",
      "Epoch = 202\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2642291874574667\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.923218343730056\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840013306452728\n",
      "============================================================\n",
      "\n",
      "Epoch = 203\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.295769859351605\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9007358562936205\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007839229305122082\n",
      "============================================================\n",
      "\n",
      "Epoch = 204\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3151788223170775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8478793785088818\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783844538219157\n",
      "============================================================\n",
      "\n",
      "Epoch = 205\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2991539095718023\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.834248533844821\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783766153765335\n",
      "============================================================\n",
      "\n",
      "Epoch = 206\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2782967971460737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8594557383152228\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836877771499585\n",
      "============================================================\n",
      "\n",
      "Epoch = 207\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.26691970281124\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.911138708566179\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836094083722435\n",
      "============================================================\n",
      "\n",
      "Epoch = 208\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2639879445313364\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.904799158892147\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007835310474314064\n",
      "============================================================\n",
      "\n",
      "Epoch = 209\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2651275765006518\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9097301657957144\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007834526943266633\n",
      "============================================================\n",
      "\n",
      "Epoch = 210\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.257175909740371\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.851706356410419\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007833743490572306\n",
      "============================================================\n",
      "\n",
      "Epoch = 211\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.253908511600733\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8429999014758567\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832960116223248\n",
      "============================================================\n",
      "\n",
      "Epoch = 212\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.250679838474901\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8220979763348562\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832176820211626\n",
      "============================================================\n",
      "\n",
      "Epoch = 213\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.251484920044205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8603592016814792\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007831393602529605\n",
      "============================================================\n",
      "\n",
      "Epoch = 214\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.257031880853117\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.821904593079681\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007830610463169352\n",
      "============================================================\n",
      "\n",
      "Epoch = 215\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.273100757073897\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8711601981322217\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829827402123036\n",
      "============================================================\n",
      "\n",
      "Epoch = 216\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.278195474710623\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8184799533617577\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829044419382824\n",
      "============================================================\n",
      "\n",
      "Epoch = 217\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.284345305202387\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9018193957035863\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007828261514940886\n",
      "============================================================\n",
      "\n",
      "Epoch = 218\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.279143803637337\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.827830796351563\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007827478688789392\n",
      "============================================================\n",
      "\n",
      "Epoch = 219\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.272377985862576\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8986707854576945\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007826695940920513\n",
      "============================================================\n",
      "\n",
      "Epoch = 220\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2557263694818115\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.815676634908118\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825913271326422\n",
      "============================================================\n",
      "\n",
      "Epoch = 221\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2461805780959834\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8655902130618474\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825130679999289\n",
      "============================================================\n",
      "\n",
      "Epoch = 222\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.234247314423972\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7319567181629891\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00782434816693129\n",
      "============================================================\n",
      "\n",
      "Epoch = 223\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2294037891782787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.702190990528131\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007823565732114597\n",
      "============================================================\n",
      "\n",
      "Epoch = 224\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2269999833607454\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6603430449048135\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822783375541386\n",
      "============================================================\n",
      "\n",
      "Epoch = 225\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2267450464268217\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6807253828821163\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822001097203832\n",
      "============================================================\n",
      "\n",
      "Epoch = 226\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.226088879159076\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6245180396710768\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007821218897094112\n",
      "============================================================\n",
      "\n",
      "Epoch = 227\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2268420500387047\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.601710736178136\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007820436775204402\n",
      "============================================================\n",
      "\n",
      "Epoch = 228\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2305130766271706\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5404576441331155\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007819654731526881\n",
      "============================================================\n",
      "\n",
      "Epoch = 229\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2368041304382387\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.507089707614838\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818872766053728\n",
      "============================================================\n",
      "\n",
      "Epoch = 230\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2400784652060155\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.480754661963433\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818090878777124\n",
      "============================================================\n",
      "\n",
      "Epoch = 231\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2469381556599606\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4805573127993343\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007817309069689245\n",
      "============================================================\n",
      "\n",
      "Epoch = 232\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.252213759391464\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5035402893375438\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007816527338782277\n",
      "============================================================\n",
      "\n",
      "Epoch = 233\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.261463636332256\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5714367626849095\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078157456860484\n",
      "============================================================\n",
      "\n",
      "Epoch = 234\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.267762838701574\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6002832190490812\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814964111479795\n",
      "============================================================\n",
      "\n",
      "Epoch = 235\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2761038991842284\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6504494888600607\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814182615068646\n",
      "============================================================\n",
      "\n",
      "Epoch = 236\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.265594427083085\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.549333957971466\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781340119680714\n",
      "============================================================\n",
      "\n",
      "Epoch = 237\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2455395812692336\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.4647308897657834\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007812619856687459\n",
      "============================================================\n",
      "\n",
      "Epoch = 238\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.223202962036789\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3687413357250204\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781183859470179\n",
      "============================================================\n",
      "\n",
      "Epoch = 239\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.21976733235922\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2974760206879496\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781105741084232\n",
      "============================================================\n",
      "\n",
      "Epoch = 240\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.230224187481514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2443848107510977\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007810276305101236\n",
      "============================================================\n",
      "\n",
      "Epoch = 241\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.240974509366671\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1963233930216701\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007809495277470726\n",
      "============================================================\n",
      "\n",
      "Epoch = 242\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2451760927525517\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1706771719078553\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007808714327942979\n",
      "============================================================\n",
      "\n",
      "Epoch = 243\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2374514468712374\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1453489743087673\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807933456510184\n",
      "============================================================\n",
      "\n",
      "Epoch = 244\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.224281875163521\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1518150994608136\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807152663164533\n",
      "============================================================\n",
      "\n",
      "Epoch = 245\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.214734220233491\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.160301934956697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007806371947898217\n",
      "============================================================\n",
      "\n",
      "Epoch = 246\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.219479614038411\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2297456956678354\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007805591310703427\n",
      "============================================================\n",
      "\n",
      "Epoch = 247\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.251803081519741\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.325025786247794\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007804810751572357\n",
      "============================================================\n",
      "\n",
      "Epoch = 248\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.301583525414934\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4855938265788184\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078040302704972\n",
      "============================================================\n",
      "\n",
      "Epoch = 249\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.344591876389219\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7004013686990067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00780324986747015\n",
      "============================================================\n",
      "\n",
      "Epoch = 250\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.310731116886058\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6279562174893172\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007802469542483403\n",
      "============================================================\n",
      "\n",
      "Epoch = 251\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2470626839890704\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4596288924455678\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007801689295529155\n",
      "============================================================\n",
      "\n",
      "Epoch = 252\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.21506232589275\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2239773562537746\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007800909126599601\n",
      "============================================================\n",
      "\n",
      "Epoch = 253\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2712659052094124\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0598760028815573\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078001290356869415\n",
      "============================================================\n",
      "\n",
      "Epoch = 254\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3421254249741126\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9540793560963541\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007799349022783373\n",
      "============================================================\n",
      "\n",
      "Epoch = 255\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3169415771233597\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9175600804704697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007798569087881095\n",
      "============================================================\n",
      "\n",
      "Epoch = 256\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2510538068098436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9582979945775166\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797789230972307\n",
      "============================================================\n",
      "\n",
      "Epoch = 257\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.22137294026047\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0550394661454632\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797009452049209\n",
      "============================================================\n",
      "\n",
      "Epoch = 258\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.214019431276213\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1864546258653974\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077962297511040045\n",
      "============================================================\n",
      "\n",
      "Epoch = 259\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.212383200385455\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3633841473909194\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007795450128128894\n",
      "============================================================\n",
      "\n",
      "Epoch = 260\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2212615689052173\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4064135481116535\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077946705831160815\n",
      "============================================================\n",
      "\n",
      "Epoch = 261\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2319508141903524\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2510507213519142\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00779389111605777\n",
      "============================================================\n",
      "\n",
      "Epoch = 262\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2307013607246864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.046364428464964\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007793111726946164\n",
      "============================================================\n",
      "\n",
      "Epoch = 263\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.204698658137277\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.921590413855184\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007792332415773469\n",
      "============================================================\n",
      "\n",
      "Epoch = 264\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.21721176536924\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8734685840213898\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007791553182531892\n",
      "============================================================\n",
      "\n",
      "Epoch = 265\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.253052300320903\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8488282617688239\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007790774027213639\n",
      "============================================================\n",
      "\n",
      "Epoch = 266\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2584132744004584\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8352305491790775\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007789994949810917\n",
      "============================================================\n",
      "\n",
      "Epoch = 267\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2343294582030313\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8279436048314411\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077892159503159366\n",
      "============================================================\n",
      "\n",
      "Epoch = 268\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2093635718315365\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8201689989444585\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077884370287209055\n",
      "============================================================\n",
      "\n",
      "Epoch = 269\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1987900147752373\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8253801605518772\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007787658185018033\n",
      "============================================================\n",
      "\n",
      "Epoch = 270\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1992855927493986\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8578770305699702\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786879419199532\n",
      "============================================================\n",
      "\n",
      "Epoch = 271\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.197310468334265\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.929107791778602\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786100731257612\n",
      "============================================================\n",
      "\n",
      "Epoch = 272\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1996158374076193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0030572234310375\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007785322121184487\n",
      "============================================================\n",
      "\n",
      "Epoch = 273\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2211840758706276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0795153518577525\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007784543588972369\n",
      "============================================================\n",
      "\n",
      "Epoch = 274\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2513836033833665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0730083110564241\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007783765134613472\n",
      "============================================================\n",
      "\n",
      "Epoch = 275\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2599590654841952\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.055630206610594\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007782986758100011\n",
      "============================================================\n",
      "\n",
      "Epoch = 276\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2311168083065223\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0104318073165295\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077822084594242015\n",
      "============================================================\n",
      "\n",
      "Epoch = 277\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 2.2034470314867907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9819622802559109\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007781430238578259\n",
      "============================================================\n",
      "\n",
      "Epoch = 278\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.193849554812845\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9447651457548909\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007780652095554402\n",
      "============================================================\n",
      "\n",
      "Epoch = 279\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2017856438714682\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9159563395783248\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779874030344846\n",
      "============================================================\n",
      "\n",
      "Epoch = 280\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2136961682111553\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8763594764709202\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779096042941812\n",
      "============================================================\n",
      "\n",
      "Epoch = 281\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2123532693980903\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8367126713751947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077783181333375175\n",
      "============================================================\n",
      "\n",
      "Epoch = 282\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2071658770853215\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.799762091814469\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077775403015241835\n",
      "============================================================\n",
      "\n",
      "Epoch = 283\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2012266329803687\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.777278720981578\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077767625474940314\n",
      "============================================================\n",
      "\n",
      "Epoch = 284\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1966992262054816\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7652306753346921\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775984871239282\n",
      "============================================================\n",
      "\n",
      "Epoch = 285\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.192903571990283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.760390635875286\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775207272752158\n",
      "============================================================\n",
      "\n",
      "Epoch = 286\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.191453190223024\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7595534609207772\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007774429752024883\n",
      "============================================================\n",
      "\n",
      "Epoch = 287\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1906147718511777\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7618731478601879\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007773652309049681\n",
      "============================================================\n",
      "\n",
      "Epoch = 288\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1912248946198503\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.770697753435557\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772874943818776\n",
      "============================================================\n",
      "\n",
      "Epoch = 289\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1937112331082647\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7918803770203737\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772097656324394\n",
      "============================================================\n",
      "\n",
      "Epoch = 290\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2010280805468083\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8451255839619521\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007771320446558761\n",
      "============================================================\n",
      "\n",
      "Epoch = 291\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.216114206276169\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.929823623897388\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007770543314514105\n",
      "============================================================\n",
      "\n",
      "Epoch = 292\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.24393038483005\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0570371920282746\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007769766260182654\n",
      "============================================================\n",
      "\n",
      "Epoch = 293\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2653689377619584\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1169662999012062\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768989283556636\n",
      "============================================================\n",
      "\n",
      "Epoch = 294\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2541707733471794\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1173941028315215\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768212384628281\n",
      "============================================================\n",
      "\n",
      "Epoch = 295\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.211600223010699\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.013102319896138\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007767435563389818\n",
      "============================================================\n",
      "\n",
      "Epoch = 296\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1850621069955807\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9222942595459267\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007766658819833479\n",
      "============================================================\n",
      "\n",
      "Epoch = 297\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1958605323043976\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8354113198709813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765882153951496\n",
      "============================================================\n",
      "\n",
      "Epoch = 298\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2303081514426077\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7813717895459444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765105565736101\n",
      "============================================================\n",
      "\n",
      "Epoch = 299\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2494206150455467\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7432241411950922\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007764329055179527\n",
      "============================================================\n",
      "\n",
      "Epoch = 300\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2283234959497182\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7223359989579013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007763552622274009\n",
      "============================================================\n",
      "\n",
      "Epoch = 301\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2003606181367426\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7104640320296983\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077627762670117815\n",
      "============================================================\n",
      "\n",
      "Epoch = 302\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1853332701448416\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7047961077238296\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00776199998938508\n",
      "============================================================\n",
      "\n",
      "Epoch = 303\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.179361168950717\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7118899079451685\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007761223789386142\n",
      "============================================================\n",
      "\n",
      "Epoch = 304\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1776505055782596\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.745826015437142\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007760447667007203\n",
      "============================================================\n",
      "\n",
      "Epoch = 305\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1791097574020166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8315834196841307\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007759671622240502\n",
      "============================================================\n",
      "\n",
      "Epoch = 306\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.194491005046795\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9464278000866138\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007758895655078278\n",
      "============================================================\n",
      "\n",
      "Epoch = 307\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2365960514671603\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.047530119052758\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775811976551277\n",
      "============================================================\n",
      "\n",
      "Epoch = 308\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2697675573764435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.021071703445798\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077573439535362195\n",
      "============================================================\n",
      "\n",
      "Epoch = 309\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2463776658984678\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9404407411661332\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007756568219140866\n",
      "============================================================\n",
      "\n",
      "Epoch = 310\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1908923649235956\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8328424208675111\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007755792562318952\n",
      "============================================================\n",
      "\n",
      "Epoch = 311\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.175021713542726\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7629647295248358\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775501698306272\n",
      "============================================================\n",
      "\n",
      "Epoch = 312\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2097132598450937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7163587176680593\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007754241481364414\n",
      "============================================================\n",
      "\n",
      "Epoch = 313\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2392196702110203\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6864194934180283\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007753466057216277\n",
      "============================================================\n",
      "\n",
      "Epoch = 314\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.224861235235661\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6633595876912172\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007752690710610556\n",
      "============================================================\n",
      "\n",
      "Epoch = 315\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.190988231993959\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6465067315194261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751915441539495\n",
      "============================================================\n",
      "\n",
      "Epoch = 316\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 2.1703764160683714\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6329785900920045\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751140249995341\n",
      "============================================================\n",
      "\n",
      "Epoch = 317\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1659744475116405\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6282516739272528\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007750365135970342\n",
      "============================================================\n",
      "\n",
      "Epoch = 318\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.16465891970794\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6383198986514743\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007749590099456746\n",
      "============================================================\n",
      "\n",
      "Epoch = 319\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1635067747345835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6708963247011209\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077488151404468\n",
      "============================================================\n",
      "\n",
      "Epoch = 320\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.164833049077756\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7373727466084455\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007748040258932756\n",
      "============================================================\n",
      "\n",
      "Epoch = 321\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1832833055029823\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8263167944074336\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007747265454906863\n",
      "============================================================\n",
      "\n",
      "Epoch = 322\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2293830911509707\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9001971271246121\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007746490728361372\n",
      "============================================================\n",
      "\n",
      "Epoch = 323\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2552235815590214\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.931749729256495\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007745716079288536\n",
      "============================================================\n",
      "\n",
      "Epoch = 324\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2343154949451116\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.910997658982305\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744941507680608\n",
      "============================================================\n",
      "\n",
      "Epoch = 325\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1852197930750665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8585824060860813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744167013529839\n",
      "============================================================\n",
      "\n",
      "Epoch = 326\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1563888164037897\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7944000411712067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007743392596828487\n",
      "============================================================\n",
      "\n",
      "Epoch = 327\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1572270009131715\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7366906039750148\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007742618257568804\n",
      "============================================================\n",
      "\n",
      "Epoch = 328\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1706780613976395\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.694539149413997\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741843995743047\n",
      "============================================================\n",
      "\n",
      "Epoch = 329\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1835434250757864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6557771414837424\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741069811343473\n",
      "============================================================\n",
      "\n",
      "Epoch = 330\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1933191176115865\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6361072253540683\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007740295704362339\n",
      "============================================================\n",
      "\n",
      "Epoch = 331\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.17494430775884\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6192886061216426\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007739521674791903\n",
      "============================================================\n",
      "\n",
      "Epoch = 332\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.14235020874119\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6095109609985415\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007738747722624424\n",
      "============================================================\n",
      "\n",
      "Epoch = 333\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.131259857327227\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.589679861334577\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007737973847852161\n",
      "============================================================\n",
      "\n",
      "Epoch = 334\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.143325796047323\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5744993407029514\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077372000504673764\n",
      "============================================================\n",
      "\n",
      "Epoch = 335\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.153352516043852\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5673042804883487\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00773642633046233\n",
      "============================================================\n",
      "\n",
      "Epoch = 336\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.152239435989453\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5627118955639819\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007735652687829283\n",
      "============================================================\n",
      "\n",
      "Epoch = 337\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.172662011763281\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5616520271796717\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077348791225605\n",
      "============================================================\n",
      "\n",
      "Epoch = 338\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1718761192988816\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5641295454800942\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007734105634648244\n",
      "============================================================\n",
      "\n",
      "Epoch = 339\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.164666451182031\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5685483229307754\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007733332224084779\n",
      "============================================================\n",
      "\n",
      "Epoch = 340\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1647338502681785\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5728370572327063\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077325588908623705\n",
      "============================================================\n",
      "\n",
      "Epoch = 341\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1644261779722163\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5812084613306338\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731785634973285\n",
      "============================================================\n",
      "\n",
      "Epoch = 342\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1605738974203064\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5967726435326961\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731012456409787\n",
      "============================================================\n",
      "\n",
      "Epoch = 343\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1415274937184297\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6291400709402369\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007730239355164146\n",
      "============================================================\n",
      "\n",
      "Epoch = 344\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.275693033288793\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7057477180705776\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077294663312286295\n",
      "============================================================\n",
      "\n",
      "Epoch = 345\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.217061261567652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8707896238600282\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077286933845955065\n",
      "============================================================\n",
      "\n",
      "Epoch = 346\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.221832271999283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0836903751353566\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727920515257047\n",
      "============================================================\n",
      "\n",
      "Epoch = 347\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.21633834110038\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.0859020259444971\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727147723205522\n",
      "============================================================\n",
      "\n",
      "Epoch = 348\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1994846829406205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8918828815073891\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007726375008433201\n",
      "============================================================\n",
      "\n",
      "Epoch = 349\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1655597477718014\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7041508996615771\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077256023709323576\n",
      "============================================================\n",
      "\n",
      "Epoch = 350\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.100496835117011\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6010669577096045\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724829810695264\n",
      "============================================================\n",
      "\n",
      "Epoch = 351\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1246301212024816\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5626670619508932\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724057327714195\n",
      "============================================================\n",
      "\n",
      "Epoch = 352\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2634785296169886\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5497238176803763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007723284921981423\n",
      "============================================================\n",
      "\n",
      "Epoch = 353\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3029387951659914\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5446204126787308\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007722512593489225\n",
      "============================================================\n",
      "\n",
      "Epoch = 354\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.214283384631634\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.554019948930179\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007721740342229876\n",
      "============================================================\n",
      "\n",
      "Epoch = 355\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.169201080254564\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5643018313703324\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720968168195653\n",
      "============================================================\n",
      "\n",
      "Epoch = 356\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 2.1731112727230286\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.608649748278566\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720196071378833\n",
      "============================================================\n",
      "\n",
      "Epoch = 357\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.165385488581439\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7055826618552314\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007719424051771695\n",
      "============================================================\n",
      "\n",
      "Epoch = 358\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1580326190158354\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.882198265776432\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007718652109366518\n",
      "============================================================\n",
      "\n",
      "Epoch = 359\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1891123547744487\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9655349450762457\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717880244155581\n",
      "============================================================\n",
      "\n",
      "Epoch = 360\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2316845986232408\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8765751929227895\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717108456131165\n",
      "============================================================\n",
      "\n",
      "Epoch = 361\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.220568946134957\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7118588354992468\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007716336745285552\n",
      "============================================================\n",
      "\n",
      "Epoch = 362\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.168436417395754\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6164865756311197\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007715565111611023\n",
      "============================================================\n",
      "\n",
      "Epoch = 363\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.154391257658878\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.576360033599896\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714793555099862\n",
      "============================================================\n",
      "\n",
      "Epoch = 364\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1986951170300757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5589999776016377\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714022075744352\n",
      "============================================================\n",
      "\n",
      "Epoch = 365\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2312757535569427\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5528065465149443\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007713250673536777\n",
      "============================================================\n",
      "\n",
      "Epoch = 366\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1797495599861576\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5549257042284341\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007712479348469424\n",
      "============================================================\n",
      "\n",
      "Epoch = 367\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1429734463333374\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5544206337356021\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007711708100534577\n",
      "============================================================\n",
      "\n",
      "Epoch = 368\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.134663514466685\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5420178435952833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007710936929724523\n",
      "============================================================\n",
      "\n",
      "Epoch = 369\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.138074203615174\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5366659302755222\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00771016583603155\n",
      "============================================================\n",
      "\n",
      "Epoch = 370\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1395584135732486\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5469384136872244\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077093948194479475\n",
      "============================================================\n",
      "\n",
      "Epoch = 371\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1346283345233013\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5723064179668019\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007708623879966002\n",
      "============================================================\n",
      "\n",
      "Epoch = 372\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1227904000597246\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6106519468006842\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707853017578006\n",
      "============================================================\n",
      "\n",
      "Epoch = 373\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1311911345890553\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6438663455609065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707082232276248\n",
      "============================================================\n",
      "\n",
      "Epoch = 374\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1610629286255842\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.647208942229914\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007706311524053021\n",
      "============================================================\n",
      "\n",
      "Epoch = 375\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1836390605783738\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.62900371209352\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007705540892900616\n",
      "============================================================\n",
      "\n",
      "Epoch = 376\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.17432469977632\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6260992621392946\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007704770338811326\n",
      "============================================================\n",
      "\n",
      "Epoch = 377\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1483546407879857\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.638833115370199\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703999861777445\n",
      "============================================================\n",
      "\n",
      "Epoch = 378\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1233965090003046\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6870671713924229\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703229461791267\n",
      "============================================================\n",
      "\n",
      "Epoch = 379\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1139481904829482\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7630448644520497\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007702459138845088\n",
      "============================================================\n",
      "\n",
      "Epoch = 380\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.115183245386204\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8027784896173003\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007701688892931204\n",
      "============================================================\n",
      "\n",
      "Epoch = 381\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1253940228544916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7720375039641082\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700918724041911\n",
      "============================================================\n",
      "\n",
      "Epoch = 382\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1376477733109454\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.678947853697243\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700148632169506\n",
      "============================================================\n",
      "\n",
      "Epoch = 383\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.135627164703477\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.60063532023345\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007699378617306289\n",
      "============================================================\n",
      "\n",
      "Epoch = 384\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.123672448225845\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.556026983720364\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007698608679444559\n",
      "============================================================\n",
      "\n",
      "Epoch = 385\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0876319997782407\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.540011962570561\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007697838818576615\n",
      "============================================================\n",
      "\n",
      "Epoch = 386\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0736143800441895\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5440145127015061\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076970690346947574\n",
      "============================================================\n",
      "\n",
      "Epoch = 387\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.078437289923867\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5651460353418086\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007696299327791288\n",
      "============================================================\n",
      "\n",
      "Epoch = 388\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0949715361140977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6090699090739192\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007695529697858509\n",
      "============================================================\n",
      "\n",
      "Epoch = 389\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1049115231468383\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6950896943784168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076947601448887236\n",
      "============================================================\n",
      "\n",
      "Epoch = 390\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0943162919341947\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7514165529892942\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007693990668874235\n",
      "============================================================\n",
      "\n",
      "Epoch = 391\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.088831855555492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7716570450577442\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076932212698073476\n",
      "============================================================\n",
      "\n",
      "Epoch = 392\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.040256147756844\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7125695197068306\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007692451947680367\n",
      "============================================================\n",
      "\n",
      "Epoch = 393\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1139954820446087\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6184812412459435\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007691682702485599\n",
      "============================================================\n",
      "\n",
      "Epoch = 394\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1859478440516007\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5438218261650094\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076909135342153505\n",
      "============================================================\n",
      "\n",
      "Epoch = 395\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.157562195122098\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5534986766560013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007690144442861929\n",
      "============================================================\n",
      "\n",
      "Epoch = 396\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0210810434005353\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.6087083168524536\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076893754284176425\n",
      "============================================================\n",
      "\n",
      "Epoch = 397\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.036965233542597\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5836502578321368\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007688606490874801\n",
      "============================================================\n",
      "\n",
      "Epoch = 398\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.142262832311254\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5364919169549638\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687837630225713\n",
      "============================================================\n",
      "\n",
      "Epoch = 399\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.183442059826442\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5378669844079317\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687068846462691\n",
      "============================================================\n",
      "\n",
      "Epoch = 400\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0456336973444307\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5704996697884385\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076863001395780445\n",
      "============================================================\n",
      "\n",
      "Epoch = 401\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.091782367737367\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5888654740696507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007685531509564087\n",
      "============================================================\n",
      "\n",
      "Epoch = 402\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9517909331888448\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.632721114213559\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076847629564131305\n",
      "============================================================\n",
      "\n",
      "Epoch = 403\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9100654215933859\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7715866684760011\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00768399448011749\n",
      "============================================================\n",
      "\n",
      "Epoch = 404\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.971971978887762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.787410191602508\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007683226080669478\n",
      "============================================================\n",
      "\n",
      "Epoch = 405\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9709629279605996\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7049784312048462\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007682457758061411\n",
      "============================================================\n",
      "\n",
      "Epoch = 406\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.932070580087117\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6349966367742034\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007681689512285605\n",
      "============================================================\n",
      "\n",
      "Epoch = 407\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.891580713633287\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5801486873535424\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680921343334376\n",
      "============================================================\n",
      "\n",
      "Epoch = 408\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8622324634040006\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5394893611222413\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680153251200043\n",
      "============================================================\n",
      "\n",
      "Epoch = 409\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.858326236603919\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5660534705210664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007679385235874923\n",
      "============================================================\n",
      "\n",
      "Epoch = 410\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8619880618236038\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5946930297911004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007678617297351336\n",
      "============================================================\n",
      "\n",
      "Epoch = 411\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8871843586326669\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6851170258795847\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677849435621601\n",
      "============================================================\n",
      "\n",
      "Epoch = 412\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.884095411055835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8576492572275944\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677081650678039\n",
      "============================================================\n",
      "\n",
      "Epoch = 413\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8563594651376274\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8966465975981024\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007676313942512971\n",
      "============================================================\n",
      "\n",
      "Epoch = 414\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.803255436147633\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8026389828883401\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007675546311118719\n",
      "============================================================\n",
      "\n",
      "Epoch = 415\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7460100412722683\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6527449468913731\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007674778756487608\n",
      "============================================================\n",
      "\n",
      "Epoch = 416\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7268394852072284\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5551286409131158\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767401127861196\n",
      "============================================================\n",
      "\n",
      "Epoch = 417\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7853159678860826\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5333160450892275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007673243877484098\n",
      "============================================================\n",
      "\n",
      "Epoch = 418\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6992811434480513\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5640829092472055\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767247655309635\n",
      "============================================================\n",
      "\n",
      "Epoch = 419\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6311021591025996\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6050075049623324\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767170930544104\n",
      "============================================================\n",
      "\n",
      "Epoch = 420\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5938929501506394\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.657481430824742\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076709421345104965\n",
      "============================================================\n",
      "\n",
      "Epoch = 421\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6581084227309253\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7056327889434366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007670175040297046\n",
      "============================================================\n",
      "\n",
      "Epoch = 422\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9618974737382864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.697476710842188\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007669408022793016\n",
      "============================================================\n",
      "\n",
      "Epoch = 423\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.3091804634037545\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6447986208854857\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007668641081990737\n",
      "============================================================\n",
      "\n",
      "Epoch = 424\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8205342161112514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6442030956369664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667874217882537\n",
      "============================================================\n",
      "\n",
      "Epoch = 425\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.426603159495523\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7649013099759009\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667107430460749\n",
      "============================================================\n",
      "\n",
      "Epoch = 426\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5633948391883923\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.776872241329933\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007666340719717703\n",
      "============================================================\n",
      "\n",
      "Epoch = 427\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5071287318112607\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6890033313009452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076655740856457315\n",
      "============================================================\n",
      "\n",
      "Epoch = 428\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3583904304258398\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6356508273134623\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664807528237167\n",
      "============================================================\n",
      "\n",
      "Epoch = 429\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3681791622593051\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5902727245507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664041047484343\n",
      "============================================================\n",
      "\n",
      "Epoch = 430\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3299273215778211\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6272903925282\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007663274643379595\n",
      "============================================================\n",
      "\n",
      "Epoch = 431\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3538975904815729\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8166859620449614\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007662508315915257\n",
      "============================================================\n",
      "\n",
      "Epoch = 432\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.540089428748601\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8430339963025538\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007661742065083665\n",
      "============================================================\n",
      "\n",
      "Epoch = 433\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6833998527285838\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9153457579357894\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660975890877157\n",
      "============================================================\n",
      "\n",
      "Epoch = 434\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5937350571984055\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9444590375764389\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660209793288069\n",
      "============================================================\n",
      "\n",
      "Epoch = 435\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4767455935231821\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7182539407041184\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076594437723087406\n",
      "============================================================\n",
      "\n",
      "Epoch = 436\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 1.2013104677252262\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5928257523034123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00765867782793151\n",
      "============================================================\n",
      "\n",
      "Epoch = 437\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1212065224365644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5613841272082954\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076579119601487165\n",
      "============================================================\n",
      "\n",
      "Epoch = 438\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0789609859181706\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6288335180011334\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007657146168952702\n",
      "============================================================\n",
      "\n",
      "Epoch = 439\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.142665056175778\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7085851489955581\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007656380454335807\n",
      "============================================================\n",
      "\n",
      "Epoch = 440\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1802680657102083\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6718423083201263\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007655614816290374\n",
      "============================================================\n",
      "\n",
      "Epoch = 441\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2678794811658494\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5954488856874592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076548492548087444\n",
      "============================================================\n",
      "\n",
      "Epoch = 442\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3682537169280724\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5495563434144748\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007654083769883264\n",
      "============================================================\n",
      "\n",
      "Epoch = 443\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3347728961239271\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5301322255893528\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076533183615062755\n",
      "============================================================\n",
      "\n",
      "Epoch = 444\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9817495293323282\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5394149687635899\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007652553029670125\n",
      "============================================================\n",
      "\n",
      "Epoch = 445\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7885594116683063\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5315794910814198\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651787774367158\n",
      "============================================================\n",
      "\n",
      "Epoch = 446\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7354537774088321\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5316826521241881\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651022595589722\n",
      "============================================================\n",
      "\n",
      "Epoch = 447\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7480329428829584\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.546031363795495\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007650257493330163\n",
      "============================================================\n",
      "\n",
      "Epoch = 448\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7681542978677088\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5626063045288919\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00764949246758083\n",
      "============================================================\n",
      "\n",
      "Epoch = 449\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8325449203565581\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6464214950750101\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007648727518334072\n",
      "============================================================\n",
      "\n",
      "Epoch = 450\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9130495916945011\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.786899572728781\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647962645582239\n",
      "============================================================\n",
      "\n",
      "Epoch = 451\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9668029780414615\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8968265798064171\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647197849317681\n",
      "============================================================\n",
      "\n",
      "Epoch = 452\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9753543308274276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8366951616461052\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007646433129532749\n",
      "============================================================\n",
      "\n",
      "Epoch = 453\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9462991933566083\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6912208770395227\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007645668486219796\n",
      "============================================================\n",
      "\n",
      "Epoch = 454\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9454981080947729\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5901110779010778\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644903919371174\n",
      "============================================================\n",
      "\n",
      "Epoch = 455\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9279329904622946\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.530208876032926\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644139428979236\n",
      "============================================================\n",
      "\n",
      "Epoch = 456\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8667852825625977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.521905161206386\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076433750150363385\n",
      "============================================================\n",
      "\n",
      "Epoch = 457\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.757152994126631\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5430359954354202\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007642610677534835\n",
      "============================================================\n",
      "\n",
      "Epoch = 458\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6769252212693386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5778185448935742\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641846416467081\n",
      "============================================================\n",
      "\n",
      "Epoch = 459\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6599967736705655\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6206371096130157\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641082231825434\n",
      "============================================================\n",
      "\n",
      "Epoch = 460\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6273800531714553\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6929639584769295\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007640318123602252\n",
      "============================================================\n",
      "\n",
      "Epoch = 461\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.608675753400608\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7294679308708926\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076395540917898914\n",
      "============================================================\n",
      "\n",
      "Epoch = 462\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.610444032068592\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6540863063917984\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638790136380713\n",
      "============================================================\n",
      "\n",
      "Epoch = 463\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6101506048263357\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5745418584681625\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638026257367075\n",
      "============================================================\n",
      "\n",
      "Epoch = 464\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5965226861383042\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5357223947823662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007637262454741338\n",
      "============================================================\n",
      "\n",
      "Epoch = 465\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5748042068294942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5268614903423775\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007636498728495864\n",
      "============================================================\n",
      "\n",
      "Epoch = 466\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.555922307368282\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5266628610940789\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007635735078623015\n",
      "============================================================\n",
      "\n",
      "Epoch = 467\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5450365693992418\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5369578974142227\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634971505115153\n",
      "============================================================\n",
      "\n",
      "Epoch = 468\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5460769402843708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5457146986972936\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634208007964641\n",
      "============================================================\n",
      "\n",
      "Epoch = 469\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5490746021334044\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5533704069038023\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007633444587163845\n",
      "============================================================\n",
      "\n",
      "Epoch = 470\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5484071475001921\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5585176773546473\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007632681242705129\n",
      "============================================================\n",
      "\n",
      "Epoch = 471\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.555059033269037\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5589458124449839\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631917974580859\n",
      "============================================================\n",
      "\n",
      "Epoch = 472\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.602093733825114\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5497938166618944\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631154782783401\n",
      "============================================================\n",
      "\n",
      "Epoch = 473\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7382428648584737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.530813636614551\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007630391667305123\n",
      "============================================================\n",
      "\n",
      "Epoch = 474\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9477953239831644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.517411029599433\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007629628628138392\n",
      "============================================================\n",
      "\n",
      "Epoch = 475\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0313726595695223\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5261583424266774\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007628865665275579\n",
      "============================================================\n",
      "\n",
      "Epoch = 476\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8497961586576124\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.556262358520649\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076281027787090516\n",
      "============================================================\n",
      "\n",
      "Epoch = 477\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.6374549537163812\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5994418859985465\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007627339968431181\n",
      "============================================================\n",
      "\n",
      "Epoch = 478\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5409304885105148\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6107839363748911\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007626577234434338\n",
      "============================================================\n",
      "\n",
      "Epoch = 479\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5470808677801204\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5769861390825693\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625814576710895\n",
      "============================================================\n",
      "\n",
      "Epoch = 480\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.599219554210518\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.529360422036061\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625051995253224\n",
      "============================================================\n",
      "\n",
      "Epoch = 481\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6395038326660762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5150596377808688\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007624289490053699\n",
      "============================================================\n",
      "\n",
      "Epoch = 482\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6488952885466667\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.540390080969763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007623527061104694\n",
      "============================================================\n",
      "\n",
      "Epoch = 483\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6058996053458909\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5925654489476265\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076227647083985835\n",
      "============================================================\n",
      "\n",
      "Epoch = 484\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5506429982963433\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6499796944897379\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007622002431927744\n",
      "============================================================\n",
      "\n",
      "Epoch = 485\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5159105817202558\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6656911534203945\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007621240231684551\n",
      "============================================================\n",
      "\n",
      "Epoch = 486\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.523742718451285\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6345181376026386\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007620478107661383\n",
      "============================================================\n",
      "\n",
      "Epoch = 487\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5622594926810617\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5717673157578105\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007619716059850617\n",
      "============================================================\n",
      "\n",
      "Epoch = 488\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5947517606293307\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5263450269431095\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618954088244632\n",
      "============================================================\n",
      "\n",
      "Epoch = 489\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6039403698118735\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5128596891565758\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618192192835807\n",
      "============================================================\n",
      "\n",
      "Epoch = 490\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5806037929159131\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5247293936838875\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007617430373616524\n",
      "============================================================\n",
      "\n",
      "Epoch = 491\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5471115286041693\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5522619999352018\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007616668630579162\n",
      "============================================================\n",
      "\n",
      "Epoch = 492\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5166979243552632\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5819667648432746\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007615906963716104\n",
      "============================================================\n",
      "\n",
      "Epoch = 493\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5061430709749931\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6031258213936136\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076151453730197325\n",
      "============================================================\n",
      "\n",
      "Epoch = 494\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5196519645846782\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6037621185961467\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007614383858482431\n",
      "============================================================\n",
      "\n",
      "Epoch = 495\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5553950172078979\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5796146147742646\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007613622420096583\n",
      "============================================================\n",
      "\n",
      "Epoch = 496\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6126327632325812\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5466003670678989\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612861057854573\n",
      "============================================================\n",
      "\n",
      "Epoch = 497\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6515323514636275\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5240973759793554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612099771748788\n",
      "============================================================\n",
      "\n",
      "Epoch = 498\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6601312798957395\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5141248765735942\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007611338561771613\n",
      "============================================================\n",
      "\n",
      "Epoch = 499\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6148957060222969\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5120731755364389\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007610577427915436\n",
      "============================================================\n",
      "\n",
      "Epoch = 500\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5673002381888597\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5118472845382519\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007609816370172644\n"
     ]
    }
   ],
   "source": [
    "# vanilla PINN: initialize optimizer and scheduler\n",
    "nn_vanilla = DNN(layers=[1, 128, 128, 128, 1])\n",
    "optim = torch.optim.Adam(\n",
    "    nn_vanilla.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(inputs, outputs, nn_vanilla, optim, scheduler, 2**10, 500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0478710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Epoch = 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.568956763908943\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 4.35030509184441\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079992\n",
      "============================================================\n",
      "\n",
      "Epoch = 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.2022838508871283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 3.229678735352697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007998400079999999\n",
      "============================================================\n",
      "\n",
      "Epoch = 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.57201378670652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.5087222223426275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007997600239991999\n",
      "============================================================\n",
      "\n",
      "Epoch = 4\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.147741565715648\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1948419719546557\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996800479968\n",
      "============================================================\n",
      "\n",
      "Epoch = 5\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8543511951021443\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.179051625113739\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996000799920003\n",
      "============================================================\n",
      "\n",
      "Epoch = 6\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6872925780783894\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8956868274972414\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007995201199840011\n",
      "============================================================\n",
      "\n",
      "Epoch = 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5335059283651282\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7140678582826776\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007994401679720027\n",
      "============================================================\n",
      "\n",
      "Epoch = 8\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3937053754807844\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5166658991819661\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007993602239552054\n",
      "============================================================\n",
      "\n",
      "Epoch = 9\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3067433812742968\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3566760663751953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992802879328098\n",
      "============================================================\n",
      "\n",
      "Epoch = 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1409061767157984\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.299280821767668\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992003599040166\n",
      "============================================================\n",
      "\n",
      "Epoch = 11\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0008725717838582\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1548910234437508\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007991204398680262\n",
      "============================================================\n",
      "\n",
      "Epoch = 12\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9230360984284176\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9873431869469554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007990405278240395\n",
      "============================================================\n",
      "\n",
      "Epoch = 13\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8397572731044483\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9114944621640799\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007989606237712572\n",
      "============================================================\n",
      "\n",
      "Epoch = 14\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.80174006524464\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7768830013098533\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079888072770888\n",
      "============================================================\n",
      "\n",
      "Epoch = 15\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7546293802941294\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.678205622396126\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007988008396361091\n",
      "============================================================\n",
      "\n",
      "Epoch = 16\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7046156996930695\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.644225528441903\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007987209595521455\n",
      "============================================================\n",
      "\n",
      "Epoch = 17\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6377761398106405\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5963006862419445\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007986410874561903\n",
      "============================================================\n",
      "\n",
      "Epoch = 18\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.624085706273825\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.541855090458983\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007985612233474448\n",
      "============================================================\n",
      "\n",
      "Epoch = 19\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5882849967925089\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5116407872247168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079848136722511\n",
      "============================================================\n",
      "\n",
      "Epoch = 20\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5643407898386092\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.494393160404657\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007984015190883875\n",
      "============================================================\n",
      "\n",
      "Epoch = 21\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5443985513435872\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.47287393781248954\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007983216789364787\n",
      "============================================================\n",
      "\n",
      "Epoch = 22\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5332111322376714\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.46307232872049525\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00798241846768585\n",
      "============================================================\n",
      "\n",
      "Epoch = 23\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5213733923030045\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.46186347769242864\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007981620225839082\n",
      "============================================================\n",
      "\n",
      "Epoch = 24\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5107882913065767\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.4504603904134483\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980822063816497\n",
      "============================================================\n",
      "\n",
      "Epoch = 25\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.509147554944634\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.4527657033823952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980023981610115\n",
      "============================================================\n",
      "\n",
      "Epoch = 26\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5036869674980291\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.4764509920750935\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007979225979211954\n",
      "============================================================\n",
      "\n",
      "Epoch = 27\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.49779395026417794\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.4592721189198626\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007978428056614032\n",
      "============================================================\n",
      "\n",
      "Epoch = 28\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.48269222641960907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.43829595648135505\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007977630213808371\n",
      "============================================================\n",
      "\n",
      "Epoch = 29\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.46873345910413394\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.39776342152734484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797683245078699\n",
      "============================================================\n",
      "\n",
      "Epoch = 30\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.46494603373883936\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.37214333976181274\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007976034767541912\n",
      "============================================================\n",
      "\n",
      "Epoch = 31\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.46780803387433095\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.36865966847696985\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007975237164065159\n",
      "============================================================\n",
      "\n",
      "Epoch = 32\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.46470778444579053\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.36268672056640155\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007974439640348753\n",
      "============================================================\n",
      "\n",
      "Epoch = 33\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4455906544146795\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.34968419491026603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007973642196384719\n",
      "============================================================\n",
      "\n",
      "Epoch = 34\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4283471502094407\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.3385881236441677\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797284483216508\n",
      "============================================================\n",
      "\n",
      "Epoch = 35\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.42264931947049356\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.3245229766648286\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007972047547681863\n",
      "============================================================\n",
      "\n",
      "Epoch = 36\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4210267280162309\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.3108755372651195\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007971250342927096\n",
      "============================================================\n",
      "\n",
      "Epoch = 37\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.42018466126282283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.29649808711775616\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007970453217892803\n",
      "============================================================\n",
      "\n",
      "Epoch = 38\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.42870307709107647\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.287693271620079\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007969656172571013\n",
      "============================================================\n",
      "\n",
      "Epoch = 39\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.45598398891738323\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2824763138171056\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968859206953756\n",
      "============================================================\n",
      "\n",
      "Epoch = 40\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4307532215442852\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2856055929890336\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968062321033061\n",
      "============================================================\n",
      "\n",
      "Epoch = 41\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.38429408813400256\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.39918285302052026\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007967265514800958\n",
      "============================================================\n",
      "\n",
      "Epoch = 42\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3648821370931338\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.6948185860243163\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007966468788249479\n",
      "============================================================\n",
      "\n",
      "Epoch = 43\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.44516124053641637\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5443787621340962\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007965672141370653\n",
      "============================================================\n",
      "\n",
      "Epoch = 44\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.38184744380312363\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.3378907950673531\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007964875574156515\n",
      "============================================================\n",
      "\n",
      "Epoch = 45\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5354956351659705\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2893254151514577\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079640790865991\n",
      "============================================================\n",
      "\n",
      "Epoch = 46\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.40070418898750315\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.3552588386925439\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007963282678690441\n",
      "============================================================\n",
      "\n",
      "Epoch = 47\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3829991205650868\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2645326341769953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007962486350422572\n",
      "============================================================\n",
      "\n",
      "Epoch = 48\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3247979633713874\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.25982580858469306\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00796169010178753\n",
      "============================================================\n",
      "\n",
      "Epoch = 49\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.32645583046490445\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.22782687102587426\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960893932777352\n",
      "============================================================\n",
      "\n",
      "Epoch = 50\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2744891395061616\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2201116421147794\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960097843384074\n",
      "============================================================\n",
      "\n",
      "Epoch = 51\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.26131839570800774\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.1877239550083953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007959301833599735\n",
      "============================================================\n",
      "\n",
      "Epoch = 52\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2527233889439779\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.1630921910087622\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007958505903416374\n",
      "============================================================\n",
      "\n",
      "Epoch = 53\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2141949713306363\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.17333019974674807\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007957710052826033\n",
      "============================================================\n",
      "\n",
      "Epoch = 54\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19656251764513882\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.13103237991091707\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007956914281820751\n",
      "============================================================\n",
      "\n",
      "Epoch = 55\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.17141490780771523\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.12382691040978186\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00795611859039257\n",
      "============================================================\n",
      "\n",
      "Epoch = 56\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.15001880852556818\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.12622341771227832\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007955322978533531\n",
      "============================================================\n",
      "\n",
      "Epoch = 57\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.13540257671743205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.08866063457954047\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007954527446235678\n",
      "============================================================\n",
      "\n",
      "Epoch = 58\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12346400386340751\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.08658913070130253\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007953731993491055\n",
      "============================================================\n",
      "\n",
      "Epoch = 59\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10715400358511452\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.07942816009928641\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952936620291706\n",
      "============================================================\n",
      "\n",
      "Epoch = 60\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0955392823240952\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.06921405051252114\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952141326629678\n",
      "============================================================\n",
      "\n",
      "Epoch = 61\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08847876395573935\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.05412874488650708\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007951346112497015\n",
      "============================================================\n",
      "\n",
      "Epoch = 62\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08072282615020705\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0514391858390645\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007950550977885766\n",
      "============================================================\n",
      "\n",
      "Epoch = 63\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0742149618800594\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.051396734500442395\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007949755922787977\n",
      "============================================================\n",
      "\n",
      "Epoch = 64\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07180340312838776\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.05555361948290377\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948960947195698\n",
      "============================================================\n",
      "\n",
      "Epoch = 65\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.09582059796620138\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.056731415409740124\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948166051100979\n",
      "============================================================\n",
      "\n",
      "Epoch = 66\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.20041851415567913\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.09081621397118167\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007947371234495869\n",
      "============================================================\n",
      "\n",
      "Epoch = 67\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.48282069782110637\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.12586960691776716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00794657649737242\n",
      "============================================================\n",
      "\n",
      "Epoch = 68\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12586905277320748\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.14334399370332915\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007945781839722683\n",
      "============================================================\n",
      "\n",
      "Epoch = 69\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19128610228293697\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.09111838389677282\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944987261538711\n",
      "============================================================\n",
      "\n",
      "Epoch = 70\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.11964970110649475\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.08915353408046321\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944192762812557\n",
      "============================================================\n",
      "\n",
      "Epoch = 71\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12342757290644084\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.08985646048571024\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007943398343536277\n",
      "============================================================\n",
      "\n",
      "Epoch = 72\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.09108393085127771\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0705365539569493\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007942604003701923\n",
      "============================================================\n",
      "\n",
      "Epoch = 73\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0770826446522352\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.06981852087737925\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941809743301553\n",
      "============================================================\n",
      "\n",
      "Epoch = 74\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07860156555756248\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.046957552022988146\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941015562327224\n",
      "============================================================\n",
      "\n",
      "Epoch = 75\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06689213777710734\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.05117266207579869\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007940221460770992\n",
      "============================================================\n",
      "\n",
      "Epoch = 76\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05733829724644514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.043867439525352415\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007939427438624915\n",
      "============================================================\n",
      "\n",
      "Epoch = 77\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05553508435581276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.03326327106253795\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007938633495881052\n",
      "============================================================\n",
      "\n",
      "Epoch = 78\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05415702074352377\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.034484020327817\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007937839632531463\n",
      "============================================================\n",
      "\n",
      "Epoch = 79\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04197589942620604\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.032026462326108014\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793704584856821\n",
      "============================================================\n",
      "\n",
      "Epoch = 80\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.039572877640192634\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.028103217075025343\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007936252143983354\n",
      "============================================================\n",
      "\n",
      "Epoch = 81\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03576655942162501\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.023980487524938227\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007935458518768956\n",
      "============================================================\n",
      "\n",
      "Epoch = 82\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.032895877441482535\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.022971212699933546\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793466497291708\n",
      "============================================================\n",
      "\n",
      "Epoch = 83\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027694544078629185\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.021019234752625605\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933871506419788\n",
      "============================================================\n",
      "\n",
      "Epoch = 84\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02650029854779565\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.020008173580442865\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933078119269146\n",
      "============================================================\n",
      "\n",
      "Epoch = 85\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02370218584194371\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.017750387537369964\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007932284811457219\n",
      "============================================================\n",
      "\n",
      "Epoch = 86\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.021741688381682684\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.017867363306736123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007931491582976073\n",
      "============================================================\n",
      "\n",
      "Epoch = 87\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01928289132762794\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01630158453101928\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007930698433817775\n",
      "============================================================\n",
      "\n",
      "Epoch = 88\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01820119369017595\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.015553680628347567\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929905363974393\n",
      "============================================================\n",
      "\n",
      "Epoch = 89\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01649163103968643\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014393217344266525\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929112373437996\n",
      "============================================================\n",
      "\n",
      "Epoch = 90\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015303137468772758\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014009208479397642\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007928319462200652\n",
      "============================================================\n",
      "\n",
      "Epoch = 91\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.014344809117521897\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01294196655360395\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007927526630254433\n",
      "============================================================\n",
      "\n",
      "Epoch = 92\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013166916187036231\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.012309775079289183\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007926733877591408\n",
      "============================================================\n",
      "\n",
      "Epoch = 93\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012488110717295834\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01161631748988475\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792594120420365\n",
      "============================================================\n",
      "\n",
      "Epoch = 94\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011723877835778385\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.010835779069839822\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007925148610083229\n",
      "============================================================\n",
      "\n",
      "Epoch = 95\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011090170897714642\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.010423314197933882\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007924356095222221\n",
      "============================================================\n",
      "\n",
      "Epoch = 96\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010513115058121674\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009897938192406162\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079235636596127\n",
      "============================================================\n",
      "\n",
      "Epoch = 97\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009705061495015209\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009516582782385211\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007922771303246739\n",
      "============================================================\n",
      "\n",
      "Epoch = 98\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009209100966135562\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008967076277774504\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921979026116414\n",
      "============================================================\n",
      "\n",
      "Epoch = 99\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008723211137124463\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008694617504965986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921186828213802\n",
      "============================================================\n",
      "\n",
      "Epoch = 100\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008304546580286514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00815955703383689\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792039470953098\n",
      "============================================================\n",
      "\n",
      "Epoch = 101\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007863936406154425\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007853017242511877\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007919602670060026\n",
      "============================================================\n",
      "\n",
      "Epoch = 102\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0075611096847785254\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007380035533258918\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791881070979302\n",
      "============================================================\n",
      "\n",
      "Epoch = 103\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007169943903549906\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007083631744725373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791801882872204\n",
      "============================================================\n",
      "\n",
      "Epoch = 104\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006920859134092363\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006723988723698829\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007917227026839167\n",
      "============================================================\n",
      "\n",
      "Epoch = 105\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006606681959272911\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006434133216530916\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007916435304136483\n",
      "============================================================\n",
      "\n",
      "Epoch = 106\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006320548245948894\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006125158576715151\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791564366060607\n",
      "============================================================\n",
      "\n",
      "Epoch = 107\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006035465514718754\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00588946582035319\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914852096240009\n",
      "============================================================\n",
      "\n",
      "Epoch = 108\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005785272197643165\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00560833484679399\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914060611030385\n",
      "============================================================\n",
      "\n",
      "Epoch = 109\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005564134199824062\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005370601108379418\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007913269204969282\n",
      "============================================================\n",
      "\n",
      "Epoch = 110\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.005324939734168097\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005142053415391146\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007912477878048784\n",
      "============================================================\n",
      "\n",
      "Epoch = 111\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0051075862080967455\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0049377669854832615\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791168663026098\n",
      "============================================================\n",
      "\n",
      "Epoch = 112\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0049093649034266515\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004727714432144189\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910895461597954\n",
      "============================================================\n",
      "\n",
      "Epoch = 113\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004718364725244766\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004543615556484537\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910104372051793\n",
      "============================================================\n",
      "\n",
      "Epoch = 114\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004537337081868971\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004353416228583268\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007909313361614588\n",
      "============================================================\n",
      "\n",
      "Epoch = 115\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004359844194603904\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004189567161642996\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007908522430278427\n",
      "============================================================\n",
      "\n",
      "Epoch = 116\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004203143353329608\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00402325032638197\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007907731578035399\n",
      "============================================================\n",
      "\n",
      "Epoch = 117\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004044637162864911\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003874054210060618\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906940804877595\n",
      "============================================================\n",
      "\n",
      "Epoch = 118\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003889684881748698\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0037357871338662817\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906150110797107\n",
      "============================================================\n",
      "\n",
      "Epoch = 119\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0037397615233555146\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003596524542588897\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007905359495786028\n",
      "============================================================\n",
      "\n",
      "Epoch = 120\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003605151915245736\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00346792468153078\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007904568959836449\n",
      "============================================================\n",
      "\n",
      "Epoch = 121\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0034844268707300515\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003343835308891405\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007903778502940466\n",
      "============================================================\n",
      "\n",
      "Epoch = 122\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0033759358070894986\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003219949024587071\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902988125090172\n",
      "============================================================\n",
      "\n",
      "Epoch = 123\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0033049460845624846\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003107085857220109\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902197826277664\n",
      "============================================================\n",
      "\n",
      "Epoch = 124\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003220882282385093\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0030255647580434484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007901407606495036\n",
      "============================================================\n",
      "\n",
      "Epoch = 125\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0031482322957718132\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003053309875621774\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007900617465734385\n",
      "============================================================\n",
      "\n",
      "Epoch = 126\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0030244622592483306\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003259790126815342\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899827403987812\n",
      "============================================================\n",
      "\n",
      "Epoch = 127\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0029282984905740677\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0037835511074100887\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899037421247413\n",
      "============================================================\n",
      "\n",
      "Epoch = 128\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003228541305895529\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004398735601758509\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789824751750529\n",
      "============================================================\n",
      "\n",
      "Epoch = 129\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005043910287269622\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0045890914191420405\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007897457692753539\n",
      "============================================================\n",
      "\n",
      "Epoch = 130\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01055329763364172\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004703497208209142\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007896667946984263\n",
      "============================================================\n",
      "\n",
      "Epoch = 131\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.020712563237335266\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.010944155023669168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895878280189565\n",
      "============================================================\n",
      "\n",
      "Epoch = 132\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03020511467162809\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.042268957215055816\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895088692361546\n",
      "============================================================\n",
      "\n",
      "Epoch = 133\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.030435765484160375\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.11398262461716915\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789429918349231\n",
      "============================================================\n",
      "\n",
      "Epoch = 134\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027856395560459345\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.16822029510467418\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007893509753573962\n",
      "============================================================\n",
      "\n",
      "Epoch = 135\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03246769098662455\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.09263977182897275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007892720402598604\n",
      "============================================================\n",
      "\n",
      "Epoch = 136\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.018029162559845942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0509173508414085\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891931130558345\n",
      "============================================================\n",
      "\n",
      "Epoch = 137\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016106186332816762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02729598559263731\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891141937445289\n",
      "============================================================\n",
      "\n",
      "Epoch = 138\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04585109950930847\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014414595286715097\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007890352823251545\n",
      "============================================================\n",
      "\n",
      "Epoch = 139\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03379711680237024\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02058251050480487\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788956378796922\n",
      "============================================================\n",
      "\n",
      "Epoch = 140\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015412891820060769\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.022745410096526694\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007888774831590423\n",
      "============================================================\n",
      "\n",
      "Epoch = 141\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01806758022713088\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.010466791938854542\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887985954107264\n",
      "============================================================\n",
      "\n",
      "Epoch = 142\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012660890789024666\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01262596549748056\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887197155511854\n",
      "============================================================\n",
      "\n",
      "Epoch = 143\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011959541526829648\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008299901164692182\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007886408435796303\n",
      "============================================================\n",
      "\n",
      "Epoch = 144\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.019795454967820484\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006023642839995135\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007885619794952723\n",
      "============================================================\n",
      "\n",
      "Epoch = 145\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009108315858587438\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008180262959743539\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884831232973228\n",
      "============================================================\n",
      "\n",
      "Epoch = 146\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005308592424324991\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00934155386977935\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884042749849931\n",
      "============================================================\n",
      "\n",
      "Epoch = 147\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0072110732089023435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005052449975349957\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007883254345574946\n",
      "============================================================\n",
      "\n",
      "Epoch = 148\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007190449632319355\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005159339630836599\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007882466020140389\n",
      "============================================================\n",
      "\n",
      "Epoch = 149\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006677621480288704\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00551138350099524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007881677773538374\n",
      "============================================================\n",
      "\n",
      "Epoch = 150\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0041870330499759485\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003601193141964746\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788088960576102\n",
      "============================================================\n",
      "\n",
      "Epoch = 151\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004641870213282772\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004387454782151261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007880101516800443\n",
      "============================================================\n",
      "\n",
      "Epoch = 152\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0039030654739282775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0038097547214779397\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007879313506648764\n",
      "============================================================\n",
      "\n",
      "Epoch = 153\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0040127840157667466\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002604218277372276\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007878525575298098\n",
      "============================================================\n",
      "\n",
      "Epoch = 154\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0034906403231588926\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0032595577933973875\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007877737722740568\n",
      "============================================================\n",
      "\n",
      "Epoch = 155\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0027310507411683295\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0028269479580626373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876949948968294\n",
      "============================================================\n",
      "\n",
      "Epoch = 156\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002954365062018729\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002341866994736707\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876162253973397\n",
      "============================================================\n",
      "\n",
      "Epoch = 157\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002809306622791583\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0023466169316304726\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007875374637748\n",
      "============================================================\n",
      "\n",
      "Epoch = 158\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0026821309797231347\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002215238578968525\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007874587100284224\n",
      "============================================================\n",
      "\n",
      "Epoch = 159\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0024020276288796716\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0021134616127398095\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873799641574196\n",
      "============================================================\n",
      "\n",
      "Epoch = 160\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0022186216450430602\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001915052413680868\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873012261610038\n",
      "============================================================\n",
      "\n",
      "Epoch = 161\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002160326336691835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0018309271687363695\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007872224960383877\n",
      "============================================================\n",
      "\n",
      "Epoch = 162\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0022115339950097308\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0017486842294416622\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00787143773788784\n",
      "============================================================\n",
      "\n",
      "Epoch = 163\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0021599515442004215\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016243845134921568\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007870650594114051\n",
      "============================================================\n",
      "\n",
      "Epoch = 164\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001892830358348363\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016357234967022594\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786986352905464\n",
      "============================================================\n",
      "\n",
      "Epoch = 165\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018595906527428506\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015927398950200194\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007869076542701735\n",
      "============================================================\n",
      "\n",
      "Epoch = 166\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017866717058235787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00150200115173923\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007868289635047465\n",
      "============================================================\n",
      "\n",
      "Epoch = 167\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017182726802926977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014639898441190997\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786750280608396\n",
      "============================================================\n",
      "\n",
      "Epoch = 168\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017166655214791026\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014160327241258255\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007866716055803353\n",
      "============================================================\n",
      "\n",
      "Epoch = 169\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00163595706712697\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013720387092329986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865929384197771\n",
      "============================================================\n",
      "\n",
      "Epoch = 170\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001564775731604737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013407763716310674\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865142791259352\n",
      "============================================================\n",
      "\n",
      "Epoch = 171\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015060554479925123\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013078853705415813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007864356276980226\n",
      "============================================================\n",
      "\n",
      "Epoch = 172\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014771779616153092\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001279682917177576\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007863569841352528\n",
      "============================================================\n",
      "\n",
      "Epoch = 173\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001447372530189169\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0012323109492657545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007862783484368393\n",
      "============================================================\n",
      "\n",
      "Epoch = 174\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014026411322054133\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0012039340931672055\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861997206019955\n",
      "============================================================\n",
      "\n",
      "Epoch = 175\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013730600544783174\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011788822743973252\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861211006299353\n",
      "============================================================\n",
      "\n",
      "Epoch = 176\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013447079552862218\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011499887528322991\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007860424885198723\n",
      "============================================================\n",
      "\n",
      "Epoch = 177\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013078030654546365\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011223161667858592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007859638842710202\n",
      "============================================================\n",
      "\n",
      "Epoch = 178\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012651896051448044\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010997791883775947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858852878825932\n",
      "============================================================\n",
      "\n",
      "Epoch = 179\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001240401738052037\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010751746454280662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858066993538049\n",
      "============================================================\n",
      "\n",
      "Epoch = 180\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012198668559869341\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001055572099566783\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007857281186838695\n",
      "============================================================\n",
      "\n",
      "Epoch = 181\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011904422192991076\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010317175000331602\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007856495458720011\n",
      "============================================================\n",
      "\n",
      "Epoch = 182\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011627591577617938\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010125458885748347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00785570980917414\n",
      "============================================================\n",
      "\n",
      "Epoch = 183\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001135148569308762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009939776361541067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854924238193223\n",
      "============================================================\n",
      "\n",
      "Epoch = 184\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011138771359968675\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009745744117211206\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854138745769405\n",
      "============================================================\n",
      "\n",
      "Epoch = 185\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010884007754380861\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009572551186671336\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007853353331894828\n",
      "============================================================\n",
      "\n",
      "Epoch = 186\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010658364895156098\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000939414251378966\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007852567996561638\n",
      "============================================================\n",
      "\n",
      "Epoch = 187\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010435652377582649\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009234542817125045\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007851782739761982\n",
      "============================================================\n",
      "\n",
      "Epoch = 188\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0010232469116589762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009069240053771375\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850997561488006\n",
      "============================================================\n",
      "\n",
      "Epoch = 189\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010046475747542403\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008913109400312815\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850212461731856\n",
      "============================================================\n",
      "\n",
      "Epoch = 190\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009842777083103056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008760396290236666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007849427440485683\n",
      "============================================================\n",
      "\n",
      "Epoch = 191\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000965609292472958\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000861961897317566\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007848642497741636\n",
      "============================================================\n",
      "\n",
      "Epoch = 192\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009469453517044876\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008478743158472245\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847857633491861\n",
      "============================================================\n",
      "\n",
      "Epoch = 193\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009302502210342103\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008341285390795716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847072847728512\n",
      "============================================================\n",
      "\n",
      "Epoch = 194\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009126115120863038\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008209313641007858\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784628814044374\n",
      "============================================================\n",
      "\n",
      "Epoch = 195\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008959012357135996\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000808300794362593\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007845503511629695\n",
      "============================================================\n",
      "\n",
      "Epoch = 196\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008789775418718475\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007959296220455325\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007844718961278533\n",
      "============================================================\n",
      "\n",
      "Epoch = 197\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008634457615275417\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007837829135775127\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843934489382405\n",
      "============================================================\n",
      "\n",
      "Epoch = 198\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008479596010623055\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007720373255269706\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843150095933466\n",
      "============================================================\n",
      "\n",
      "Epoch = 199\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008334204391004115\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007606803716154843\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007842365780923873\n",
      "============================================================\n",
      "\n",
      "Epoch = 200\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008186655028369651\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007496279507193662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784158154434578\n",
      "============================================================\n",
      "\n",
      "Epoch = 201\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008048027769693146\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007387733628587046\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840797386191346\n",
      "============================================================\n",
      "\n",
      "Epoch = 202\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007909755656378245\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007283790463758255\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840013306452728\n",
      "============================================================\n",
      "\n",
      "Epoch = 203\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007777841382381348\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007180468459476153\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007839229305122082\n",
      "============================================================\n",
      "\n",
      "Epoch = 204\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007648943039193308\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007080637388739441\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783844538219157\n",
      "============================================================\n",
      "\n",
      "Epoch = 205\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007523100939079745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000698320010405118\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783766153765335\n",
      "============================================================\n",
      "\n",
      "Epoch = 206\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007400914573267398\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006888399679551636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836877771499585\n",
      "============================================================\n",
      "\n",
      "Epoch = 207\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007281705413842441\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000679537864570176\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836094083722435\n",
      "============================================================\n",
      "\n",
      "Epoch = 208\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007165268810332911\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006704651672150371\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007835310474314064\n",
      "============================================================\n",
      "\n",
      "Epoch = 209\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007051715225788156\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006616438615353578\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007834526943266633\n",
      "============================================================\n",
      "\n",
      "Epoch = 210\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006941325994860386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006529793275346507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007833743490572306\n",
      "============================================================\n",
      "\n",
      "Epoch = 211\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006833758290379468\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006445291234017545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832960116223248\n",
      "============================================================\n",
      "\n",
      "Epoch = 212\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006728634452401597\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006362356292572429\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832176820211626\n",
      "============================================================\n",
      "\n",
      "Epoch = 213\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006626430628681321\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006281785551571888\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007831393602529605\n",
      "============================================================\n",
      "\n",
      "Epoch = 214\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0006525963478449707\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006202501320961796\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007830610463169352\n",
      "============================================================\n",
      "\n",
      "Epoch = 215\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006428655848046711\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006124884022526487\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829827402123036\n",
      "============================================================\n",
      "\n",
      "Epoch = 216\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006333042007885672\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006049054364680438\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829044419382824\n",
      "============================================================\n",
      "\n",
      "Epoch = 217\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006240151215526494\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005974635828543036\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007828261514940886\n",
      "============================================================\n",
      "\n",
      "Epoch = 218\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000614901280949862\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005901637755140279\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007827478688789392\n",
      "============================================================\n",
      "\n",
      "Epoch = 219\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006060303603318482\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005830213337337167\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007826695940920513\n",
      "============================================================\n",
      "\n",
      "Epoch = 220\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005973340416590232\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005760145186159128\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825913271326422\n",
      "============================================================\n",
      "\n",
      "Epoch = 221\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005888629082120935\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005691397313122004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825130679999289\n",
      "============================================================\n",
      "\n",
      "Epoch = 222\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005805472912011618\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005623905091251053\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00782434816693129\n",
      "============================================================\n",
      "\n",
      "Epoch = 223\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005724489218596741\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000555789172470299\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007823565732114597\n",
      "============================================================\n",
      "\n",
      "Epoch = 224\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005645011711709102\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005492715318677835\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822783375541386\n",
      "============================================================\n",
      "\n",
      "Epoch = 225\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005567552946617207\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005429238425560368\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822001097203832\n",
      "============================================================\n",
      "\n",
      "Epoch = 226\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005491446082838289\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005366262249013014\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007821218897094112\n",
      "============================================================\n",
      "\n",
      "Epoch = 227\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005417576864278396\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005305349992721176\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007820436775204402\n",
      "============================================================\n",
      "\n",
      "Epoch = 228\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005344729703696642\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005244240030227351\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007819654731526881\n",
      "============================================================\n",
      "\n",
      "Epoch = 229\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005274601732124589\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005186062475285564\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818872766053728\n",
      "============================================================\n",
      "\n",
      "Epoch = 230\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000520535284946494\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005126775226428751\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818090878777124\n",
      "============================================================\n",
      "\n",
      "Epoch = 231\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005140245656578963\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005072110108276362\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007817309069689245\n",
      "============================================================\n",
      "\n",
      "Epoch = 232\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005077037733706067\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005015017128769112\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007816527338782277\n",
      "============================================================\n",
      "\n",
      "Epoch = 233\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005022634107817994\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004966745731716513\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078157456860484\n",
      "============================================================\n",
      "\n",
      "Epoch = 234\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004977276391204385\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004915027900941743\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814964111479795\n",
      "============================================================\n",
      "\n",
      "Epoch = 235\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004960407026687901\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004883938589629347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814182615068646\n",
      "============================================================\n",
      "\n",
      "Epoch = 236\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004991720452475258\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00048556629923679137\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781340119680714\n",
      "============================================================\n",
      "\n",
      "Epoch = 237\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005146489086315131\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004889291987005502\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007812619856687459\n",
      "============================================================\n",
      "\n",
      "Epoch = 238\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005561491252449224\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004977728910385979\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781183859470179\n",
      "============================================================\n",
      "\n",
      "Epoch = 239\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000660627967001565\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005303294912528039\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781105741084232\n",
      "============================================================\n",
      "\n",
      "Epoch = 240\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0009105704683207193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006001713390660807\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007810276305101236\n",
      "============================================================\n",
      "\n",
      "Epoch = 241\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015132585072951672\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007802141048598522\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007809495277470726\n",
      "============================================================\n",
      "\n",
      "Epoch = 242\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002956201781134005\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011809219258053967\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007808714327942979\n",
      "============================================================\n",
      "\n",
      "Epoch = 243\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0064315353276876465\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0021445031278446375\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807933456510184\n",
      "============================================================\n",
      "\n",
      "Epoch = 244\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.014429836445847635\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004280178254580594\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807152663164533\n",
      "============================================================\n",
      "\n",
      "Epoch = 245\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03166337329816048\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008879556312852303\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007806371947898217\n",
      "============================================================\n",
      "\n",
      "Epoch = 246\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05839948160680309\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.016792767405676447\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007805591310703427\n",
      "============================================================\n",
      "\n",
      "Epoch = 247\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07857128840057476\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.027457253250358155\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007804810751572357\n",
      "============================================================\n",
      "\n",
      "Epoch = 248\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.044733061031568384\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.03387720623366669\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078040302704972\n",
      "============================================================\n",
      "\n",
      "Epoch = 249\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009864026243890909\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.024974119762221744\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00780324986747015\n",
      "============================================================\n",
      "\n",
      "Epoch = 250\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.022850923074738808\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01010542035495926\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007802469542483403\n",
      "============================================================\n",
      "\n",
      "Epoch = 251\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.030403582311888\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007948152928865644\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007801689295529155\n",
      "============================================================\n",
      "\n",
      "Epoch = 252\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0337211564931114\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007716185555831528\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007800909126599601\n",
      "============================================================\n",
      "\n",
      "Epoch = 253\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04443070654921629\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006745550349865102\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078001290356869415\n",
      "============================================================\n",
      "\n",
      "Epoch = 254\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03374106426642436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004681650953796036\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007799349022783373\n",
      "============================================================\n",
      "\n",
      "Epoch = 255\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01656027920552757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0058858613308273204\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007798569087881095\n",
      "============================================================\n",
      "\n",
      "Epoch = 256\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01113611959845991\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00787618994852019\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797789230972307\n",
      "============================================================\n",
      "\n",
      "Epoch = 257\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004943012814313356\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00811484986647329\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797009452049209\n",
      "============================================================\n",
      "\n",
      "Epoch = 258\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0038633782671147997\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005944108872360014\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077962297511040045\n",
      "============================================================\n",
      "\n",
      "Epoch = 259\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005680548229295427\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004111634934079138\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007795450128128894\n",
      "============================================================\n",
      "\n",
      "Epoch = 260\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006205576643333585\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0031682076359741723\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077946705831160815\n",
      "============================================================\n",
      "\n",
      "Epoch = 261\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005662844959244613\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0018535839580997634\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00779389111605777\n",
      "============================================================\n",
      "\n",
      "Epoch = 262\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0034793660100577244\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022755116409891064\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007793111726946164\n",
      "============================================================\n",
      "\n",
      "Epoch = 263\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016020002368908209\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0031089271747715636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007792332415773469\n",
      "============================================================\n",
      "\n",
      "Epoch = 264\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015638616294877117\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003013666066976139\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007791553182531892\n",
      "============================================================\n",
      "\n",
      "Epoch = 265\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016150210079383868\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002219677679002272\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007790774027213639\n",
      "============================================================\n",
      "\n",
      "Epoch = 266\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0018379253108918511\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0012610435036764516\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007789994949810917\n",
      "============================================================\n",
      "\n",
      "Epoch = 267\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002008676718861171\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008631296241160378\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077892159503159366\n",
      "============================================================\n",
      "\n",
      "Epoch = 268\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012759857489201784\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010563319518530248\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077884370287209055\n",
      "============================================================\n",
      "\n",
      "Epoch = 269\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009523958413533212\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001417490657788134\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007787658185018033\n",
      "============================================================\n",
      "\n",
      "Epoch = 270\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008421422065529201\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015916791531139101\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786879419199532\n",
      "============================================================\n",
      "\n",
      "Epoch = 271\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007507393995129718\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011404502539651947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786100731257612\n",
      "============================================================\n",
      "\n",
      "Epoch = 272\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009014982866389768\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007159508517420419\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007785322121184487\n",
      "============================================================\n",
      "\n",
      "Epoch = 273\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008622454663375715\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006346872965864151\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007784543588972369\n",
      "============================================================\n",
      "\n",
      "Epoch = 274\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007755573816506877\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006449299506926087\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007783765134613472\n",
      "============================================================\n",
      "\n",
      "Epoch = 275\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006944865957416266\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007484284318558636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007782986758100011\n",
      "============================================================\n",
      "\n",
      "Epoch = 276\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000580036708048757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007797504278474773\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077822084594242015\n",
      "============================================================\n",
      "\n",
      "Epoch = 277\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005701271680490156\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006782921019719545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007781430238578259\n",
      "============================================================\n",
      "\n",
      "Epoch = 278\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005793930351013789\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005890701427785013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007780652095554402\n",
      "============================================================\n",
      "\n",
      "Epoch = 279\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005722828194533149\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005097728422282625\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779874030344846\n",
      "============================================================\n",
      "\n",
      "Epoch = 280\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005720088892513204\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004899196253668554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779096042941812\n",
      "============================================================\n",
      "\n",
      "Epoch = 281\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005427260410717917\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005183895970693225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077783181333375175\n",
      "============================================================\n",
      "\n",
      "Epoch = 282\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005012530403562234\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00052341396478046\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077775403015241835\n",
      "============================================================\n",
      "\n",
      "Epoch = 283\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004890783116551907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005146807130854797\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077767625474940314\n",
      "============================================================\n",
      "\n",
      "Epoch = 284\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004756345288810429\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004938611627658626\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775984871239282\n",
      "============================================================\n",
      "\n",
      "Epoch = 285\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00047200320648089784\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000456111447991424\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775207272752158\n",
      "============================================================\n",
      "\n",
      "Epoch = 286\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00046775414104243074\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004336650980120264\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007774429752024883\n",
      "============================================================\n",
      "\n",
      "Epoch = 287\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004541411568841948\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00042780499026303346\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007773652309049681\n",
      "============================================================\n",
      "\n",
      "Epoch = 288\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00044956681307649885\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004264733729320962\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772874943818776\n",
      "============================================================\n",
      "\n",
      "Epoch = 289\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000438473271665824\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00042577402004136713\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772097656324394\n",
      "============================================================\n",
      "\n",
      "Epoch = 290\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00042625608061073344\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00041967403909734866\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007771320446558761\n",
      "============================================================\n",
      "\n",
      "Epoch = 291\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00041816219804899043\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00041261689853285357\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007770543314514105\n",
      "============================================================\n",
      "\n",
      "Epoch = 292\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00041091663236095775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000402426585490396\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007769766260182654\n",
      "============================================================\n",
      "\n",
      "Epoch = 293\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040400023539711983\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003939723990534714\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768989283556636\n",
      "============================================================\n",
      "\n",
      "Epoch = 294\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003982424262742258\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00038678279031547204\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768212384628281\n",
      "============================================================\n",
      "\n",
      "Epoch = 295\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00039253611183478565\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00038135642621792175\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007767435563389818\n",
      "============================================================\n",
      "\n",
      "Epoch = 296\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00038620495476626726\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00037742469981845645\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007766658819833479\n",
      "============================================================\n",
      "\n",
      "Epoch = 297\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003811582616091466\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003736705779545667\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765882153951496\n",
      "============================================================\n",
      "\n",
      "Epoch = 298\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003749565676047247\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00036938236843221016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765105565736101\n",
      "============================================================\n",
      "\n",
      "Epoch = 299\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00036838383021736655\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00036497535193392094\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007764329055179527\n",
      "============================================================\n",
      "\n",
      "Epoch = 300\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003627810613686716\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003608353121769644\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007763552622274009\n",
      "============================================================\n",
      "\n",
      "Epoch = 301\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00035807190487690903\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003560795511353865\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077627762670117815\n",
      "============================================================\n",
      "\n",
      "Epoch = 302\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003527849691435049\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003517825288907361\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00776199998938508\n",
      "============================================================\n",
      "\n",
      "Epoch = 303\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00034812398524685745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003473741364293868\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007761223789386142\n",
      "============================================================\n",
      "\n",
      "Epoch = 304\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00034382435051720105\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00034356931001379833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007760447667007203\n",
      "============================================================\n",
      "\n",
      "Epoch = 305\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00033901772918494983\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003396799679796659\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007759671622240502\n",
      "============================================================\n",
      "\n",
      "Epoch = 306\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000334757218113874\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003359573643796545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007758895655078278\n",
      "============================================================\n",
      "\n",
      "Epoch = 307\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00033032068897958963\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003324493096374839\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775811976551277\n",
      "============================================================\n",
      "\n",
      "Epoch = 308\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00032608587945530816\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003290068181762544\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077573439535362195\n",
      "============================================================\n",
      "\n",
      "Epoch = 309\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003218104133755504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003256296934642174\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007756568219140866\n",
      "============================================================\n",
      "\n",
      "Epoch = 310\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00031780812790485987\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003222592785968183\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007755792562318952\n",
      "============================================================\n",
      "\n",
      "Epoch = 311\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000313719164419139\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003190085144941432\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775501698306272\n",
      "============================================================\n",
      "\n",
      "Epoch = 312\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003098876041026427\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00031567100549366445\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007754241481364414\n",
      "============================================================\n",
      "\n",
      "Epoch = 313\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003061608662738334\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00031247161656176327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007753466057216277\n",
      "============================================================\n",
      "\n",
      "Epoch = 314\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003024506919775627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00030923647497824576\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007752690710610556\n",
      "============================================================\n",
      "\n",
      "Epoch = 315\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00029886874243654745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003061478549715278\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751915441539495\n",
      "============================================================\n",
      "\n",
      "Epoch = 316\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002953307148699726\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003030966388298247\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751140249995341\n",
      "============================================================\n",
      "\n",
      "Epoch = 317\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002919138705406653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000300066706551791\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007750365135970342\n",
      "============================================================\n",
      "\n",
      "Epoch = 318\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00028849049210794453\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002970916889724748\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007749590099456746\n",
      "============================================================\n",
      "\n",
      "Epoch = 319\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002852058944030481\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00029416118095918956\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077488151404468\n",
      "============================================================\n",
      "\n",
      "Epoch = 320\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00028192710685314\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00029128674730899705\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007748040258932756\n",
      "============================================================\n",
      "\n",
      "Epoch = 321\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002787556466135464\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00028843568179140716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007747265454906863\n",
      "============================================================\n",
      "\n",
      "Epoch = 322\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002756175953763782\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00028565121512046316\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007746490728361372\n",
      "============================================================\n",
      "\n",
      "Epoch = 323\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002725670080023532\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002828915835232505\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007745716079288536\n",
      "============================================================\n",
      "\n",
      "Epoch = 324\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00026953583514004946\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002801921558662695\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744941507680608\n",
      "============================================================\n",
      "\n",
      "Epoch = 325\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00026660049330274357\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00027749744669281623\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744167013529839\n",
      "============================================================\n",
      "\n",
      "Epoch = 326\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002636998365067875\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002748783438573304\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007743392596828487\n",
      "============================================================\n",
      "\n",
      "Epoch = 327\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002608600495536831\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002722574209590845\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007742618257568804\n",
      "============================================================\n",
      "\n",
      "Epoch = 328\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00025807281376655683\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002697125885755168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741843995743047\n",
      "============================================================\n",
      "\n",
      "Epoch = 329\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00025533136159344683\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002671789206631051\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741069811343473\n",
      "============================================================\n",
      "\n",
      "Epoch = 330\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00025264453849999297\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000264720113363767\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007740295704362339\n",
      "============================================================\n",
      "\n",
      "Epoch = 331\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00024999707925584447\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00026226789587716125\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007739521674791903\n",
      "============================================================\n",
      "\n",
      "Epoch = 332\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000247404584489854\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00025990206780096683\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007738747722624424\n",
      "============================================================\n",
      "\n",
      "Epoch = 333\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00024484895806694943\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00025755046799256956\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007737973847852161\n",
      "============================================================\n",
      "\n",
      "Epoch = 334\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002423528199478912\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002553196936068647\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077372000504673764\n",
      "============================================================\n",
      "\n",
      "Epoch = 335\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023989159930667273\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002531240265129667\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00773642633046233\n",
      "============================================================\n",
      "\n",
      "Epoch = 336\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023749100134779969\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002511189106384985\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007735652687829283\n",
      "============================================================\n",
      "\n",
      "Epoch = 337\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023513130421224743\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002492227035204717\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077348791225605\n",
      "============================================================\n",
      "\n",
      "Epoch = 338\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023283964398910698\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002477091764515369\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007734105634648244\n",
      "============================================================\n",
      "\n",
      "Epoch = 339\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023061573083526458\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002465445617125356\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007733332224084779\n",
      "============================================================\n",
      "\n",
      "Epoch = 340\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002284985367626519\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002462842787097921\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077325588908623705\n",
      "============================================================\n",
      "\n",
      "Epoch = 341\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022652684386350024\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002471481792824524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731785634973285\n",
      "============================================================\n",
      "\n",
      "Epoch = 342\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022476572089603152\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002504543699490021\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731012456409787\n",
      "============================================================\n",
      "\n",
      "Epoch = 343\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022338866611783747\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002574750263943944\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007730239355164146\n",
      "============================================================\n",
      "\n",
      "Epoch = 344\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00022258796688789668\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00027181674360770165\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077294663312286295\n",
      "============================================================\n",
      "\n",
      "Epoch = 345\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022297556640025784\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002988583164991212\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077286933845955065\n",
      "============================================================\n",
      "\n",
      "Epoch = 346\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022524876743340276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00034961271480565\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727920515257047\n",
      "============================================================\n",
      "\n",
      "Epoch = 347\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023155451873428128\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00044563231583156306\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727147723205522\n",
      "============================================================\n",
      "\n",
      "Epoch = 348\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002443581558929003\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006229158389590493\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007726375008433201\n",
      "============================================================\n",
      "\n",
      "Epoch = 349\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00027170488996763366\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009691957341950992\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077256023709323576\n",
      "============================================================\n",
      "\n",
      "Epoch = 350\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003221289245750502\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016012816251491267\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724829810695264\n",
      "============================================================\n",
      "\n",
      "Epoch = 351\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004281716777461537\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0028837211628627906\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724057327714195\n",
      "============================================================\n",
      "\n",
      "Epoch = 352\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006138947655694168\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00511321971406978\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007723284921981423\n",
      "============================================================\n",
      "\n",
      "Epoch = 353\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001014722253250421\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009732487850862209\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007722512593489225\n",
      "============================================================\n",
      "\n",
      "Epoch = 354\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016314321550679304\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.016371598772747038\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007721740342229876\n",
      "============================================================\n",
      "\n",
      "Epoch = 355\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0029728324447169992\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.029140840309860718\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720968168195653\n",
      "============================================================\n",
      "\n",
      "Epoch = 356\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004325776677335764\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.036615841720903174\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720196071378833\n",
      "============================================================\n",
      "\n",
      "Epoch = 357\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007167557349761014\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.045740900413842475\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007719424051771695\n",
      "============================================================\n",
      "\n",
      "Epoch = 358\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008031193200924377\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02787512369430233\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007718652109366518\n",
      "============================================================\n",
      "\n",
      "Epoch = 359\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010542316114286951\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.019422779927404456\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717880244155581\n",
      "============================================================\n",
      "\n",
      "Epoch = 360\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010771401482711003\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.016680348745123447\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717108456131165\n",
      "============================================================\n",
      "\n",
      "Epoch = 361\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008870835914282608\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014510953516420946\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007716336745285552\n",
      "============================================================\n",
      "\n",
      "Epoch = 362\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007896036031278308\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005144182323527012\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007715565111611023\n",
      "============================================================\n",
      "\n",
      "Epoch = 363\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009855727951568078\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007675172301375837\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714793555099862\n",
      "============================================================\n",
      "\n",
      "Epoch = 364\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009900986381355614\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004324502600618527\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714022075744352\n",
      "============================================================\n",
      "\n",
      "Epoch = 365\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0060037727257345715\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0048242860041681065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007713250673536777\n",
      "============================================================\n",
      "\n",
      "Epoch = 366\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0028228785580648556\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0024027319294673472\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007712479348469424\n",
      "============================================================\n",
      "\n",
      "Epoch = 367\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0031727874368218598\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022963339608226816\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007711708100534577\n",
      "============================================================\n",
      "\n",
      "Epoch = 368\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0032889720688632504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0017674968026709678\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007710936929724523\n",
      "============================================================\n",
      "\n",
      "Epoch = 369\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0021787483060932444\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007562518446633566\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00771016583603155\n",
      "============================================================\n",
      "\n",
      "Epoch = 370\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0010959639419008639\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0018759039013103297\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077093948194479475\n",
      "============================================================\n",
      "\n",
      "Epoch = 371\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008495458333477604\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0025650533281173804\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007708623879966002\n",
      "============================================================\n",
      "\n",
      "Epoch = 372\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008808147899936659\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014856070000648996\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707853017578006\n",
      "============================================================\n",
      "\n",
      "Epoch = 373\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000955759004772118\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007324638050869628\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707082232276248\n",
      "============================================================\n",
      "\n",
      "Epoch = 374\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008066859543189069\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006783413492531283\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007706311524053021\n",
      "============================================================\n",
      "\n",
      "Epoch = 375\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005994507826489575\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007125115426281852\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007705540892900616\n",
      "============================================================\n",
      "\n",
      "Epoch = 376\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004739343082312108\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007624642381373883\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007704770338811326\n",
      "============================================================\n",
      "\n",
      "Epoch = 377\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004973514999062913\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006402061957274238\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703999861777445\n",
      "============================================================\n",
      "\n",
      "Epoch = 378\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006247438097256084\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00037225075489551266\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703229461791267\n",
      "============================================================\n",
      "\n",
      "Epoch = 379\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000626211573731515\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00039084591740554597\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007702459138845088\n",
      "============================================================\n",
      "\n",
      "Epoch = 380\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004792311646683714\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000499057612347921\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007701688892931204\n",
      "============================================================\n",
      "\n",
      "Epoch = 381\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040251462091261085\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004244300104319592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700918724041911\n",
      "============================================================\n",
      "\n",
      "Epoch = 382\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003566216142087756\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003320889000990889\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700148632169506\n",
      "============================================================\n",
      "\n",
      "Epoch = 383\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003180260652193576\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00030381565672079507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007699378617306289\n",
      "============================================================\n",
      "\n",
      "Epoch = 384\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003524026460394881\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00027733645345727785\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007698608679444559\n",
      "============================================================\n",
      "\n",
      "Epoch = 385\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003678179936507695\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00026740643414760804\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007697838818576615\n",
      "============================================================\n",
      "\n",
      "Epoch = 386\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002939868831824637\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002838696413793628\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076970690346947574\n",
      "============================================================\n",
      "\n",
      "Epoch = 387\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002567871525237492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00027738261463241317\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007696299327791288\n",
      "============================================================\n",
      "\n",
      "Epoch = 388\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00028590760760297603\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002453973890379711\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007695529697858509\n",
      "============================================================\n",
      "\n",
      "Epoch = 389\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00029873989111395207\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023598709672822022\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076947601448887236\n",
      "============================================================\n",
      "\n",
      "Epoch = 390\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00026759636036192817\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002379076371300426\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007693990668874235\n",
      "============================================================\n",
      "\n",
      "Epoch = 391\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00024765312749691637\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023170895933068714\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076932212698073476\n",
      "============================================================\n",
      "\n",
      "Epoch = 392\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023521265638791242\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002320725479641134\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007692451947680367\n",
      "============================================================\n",
      "\n",
      "Epoch = 393\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002246530407991627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023181465644231292\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007691682702485599\n",
      "============================================================\n",
      "\n",
      "Epoch = 394\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002134011605035399\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002206765325163262\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076909135342153505\n",
      "============================================================\n",
      "\n",
      "Epoch = 395\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00021091572425339597\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021143031010159393\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007690144442861929\n",
      "============================================================\n",
      "\n",
      "Epoch = 396\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00020655682237998463\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021104606351281352\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076893754284176425\n",
      "============================================================\n",
      "\n",
      "Epoch = 397\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00020094984223621788\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021150749445322182\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007688606490874801\n",
      "============================================================\n",
      "\n",
      "Epoch = 398\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019751632336442937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020822015176047185\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687837630225713\n",
      "============================================================\n",
      "\n",
      "Epoch = 399\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019763458490730713\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002044062053621528\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687068846462691\n",
      "============================================================\n",
      "\n",
      "Epoch = 400\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001959201210878654\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020076669476708735\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076863001395780445\n",
      "============================================================\n",
      "\n",
      "Epoch = 401\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019461282029984445\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019805821222963925\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007685531509564087\n",
      "============================================================\n",
      "\n",
      "Epoch = 402\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019159522638174343\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001967770227755216\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076847629564131305\n",
      "============================================================\n",
      "\n",
      "Epoch = 403\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018855197663815817\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001966033848229459\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00768399448011749\n",
      "============================================================\n",
      "\n",
      "Epoch = 404\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018350448398660093\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001945907479424412\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007683226080669478\n",
      "============================================================\n",
      "\n",
      "Epoch = 405\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018024541742772175\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019178623507513018\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007682457758061411\n",
      "============================================================\n",
      "\n",
      "Epoch = 406\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017778866093784602\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018917217880112442\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007681689512285605\n",
      "============================================================\n",
      "\n",
      "Epoch = 407\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017610892577071163\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018719621114289515\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680921343334376\n",
      "============================================================\n",
      "\n",
      "Epoch = 408\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017406083801541262\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001849575300480102\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680153251200043\n",
      "============================================================\n",
      "\n",
      "Epoch = 409\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017203373792521923\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018332847470925716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007679385235874923\n",
      "============================================================\n",
      "\n",
      "Epoch = 410\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016986001155982472\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018160843109987047\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007678617297351336\n",
      "============================================================\n",
      "\n",
      "Epoch = 411\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001679989890258984\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001803407024462438\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677849435621601\n",
      "============================================================\n",
      "\n",
      "Epoch = 412\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016605819512831264\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017821040576121384\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677081650678039\n",
      "============================================================\n",
      "\n",
      "Epoch = 413\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016466206899173191\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017655447097234805\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007676313942512971\n",
      "============================================================\n",
      "\n",
      "Epoch = 414\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001629365564064959\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017480034944748586\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007675546311118719\n",
      "============================================================\n",
      "\n",
      "Epoch = 415\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001615253331330979\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000173674848668982\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007674778756487608\n",
      "============================================================\n",
      "\n",
      "Epoch = 416\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015970123089598223\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017227855651869047\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767401127861196\n",
      "============================================================\n",
      "\n",
      "Epoch = 417\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015814275653973185\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017135858839409138\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007673243877484098\n",
      "============================================================\n",
      "\n",
      "Epoch = 418\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015628891192407012\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001701043967841383\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767247655309635\n",
      "============================================================\n",
      "\n",
      "Epoch = 419\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015467013221533358\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016889704928143252\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767170930544104\n",
      "============================================================\n",
      "\n",
      "Epoch = 420\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015296269516156457\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016695477917923364\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076709421345104965\n",
      "============================================================\n",
      "\n",
      "Epoch = 421\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015149707349061583\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001650814469955692\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007670175040297046\n",
      "============================================================\n",
      "\n",
      "Epoch = 422\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00015006396512126885\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016297444486638977\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007669408022793016\n",
      "============================================================\n",
      "\n",
      "Epoch = 423\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014870213780169894\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016123562394698636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007668641081990737\n",
      "============================================================\n",
      "\n",
      "Epoch = 424\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014740806275514892\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001594446383304509\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667874217882537\n",
      "============================================================\n",
      "\n",
      "Epoch = 425\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014608152309026566\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015789412747685443\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667107430460749\n",
      "============================================================\n",
      "\n",
      "Epoch = 426\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014487495840392905\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001562649004710289\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007666340719717703\n",
      "============================================================\n",
      "\n",
      "Epoch = 427\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014359176692223165\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015478461233247952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076655740856457315\n",
      "============================================================\n",
      "\n",
      "Epoch = 428\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014243874656317052\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015327463767377474\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664807528237167\n",
      "============================================================\n",
      "\n",
      "Epoch = 429\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001411758869236914\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015188743979673673\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664041047484343\n",
      "============================================================\n",
      "\n",
      "Epoch = 430\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014002391763446594\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015057772616521576\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007663274643379595\n",
      "============================================================\n",
      "\n",
      "Epoch = 431\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013876258580509444\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014931729313081072\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007662508315915257\n",
      "============================================================\n",
      "\n",
      "Epoch = 432\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001376053256652621\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014814695692871835\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007661742065083665\n",
      "============================================================\n",
      "\n",
      "Epoch = 433\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001363690482238003\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001469334478404829\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660975890877157\n",
      "============================================================\n",
      "\n",
      "Epoch = 434\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013523564720034552\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014579407523412127\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660209793288069\n",
      "============================================================\n",
      "\n",
      "Epoch = 435\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013405937957167928\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014457908085821765\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076594437723087406\n",
      "============================================================\n",
      "\n",
      "Epoch = 436\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001329685360324334\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014341332160123512\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00765867782793151\n",
      "============================================================\n",
      "\n",
      "Epoch = 437\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000131883020714476\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014218716176316536\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076579119601487165\n",
      "============================================================\n",
      "\n",
      "Epoch = 438\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013084241024441883\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001409822924160165\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007657146168952702\n",
      "============================================================\n",
      "\n",
      "Epoch = 439\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001298460999534372\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013978169710755948\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007656380454335807\n",
      "============================================================\n",
      "\n",
      "Epoch = 440\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012883117594427517\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013858532690273832\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007655614816290374\n",
      "============================================================\n",
      "\n",
      "Epoch = 441\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012788021436859804\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001374893553077888\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076548492548087444\n",
      "============================================================\n",
      "\n",
      "Epoch = 442\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012685169080343492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001363869643719215\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007654083769883264\n",
      "============================================================\n",
      "\n",
      "Epoch = 443\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012589002491418777\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013544556197481346\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076533183615062755\n",
      "============================================================\n",
      "\n",
      "Epoch = 444\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012483378393583864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013444068058566957\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007652553029670125\n",
      "============================================================\n",
      "\n",
      "Epoch = 445\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012386543356534676\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013353721683639414\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651787774367158\n",
      "============================================================\n",
      "\n",
      "Epoch = 446\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012287544081262942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001324822889113636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651022595589722\n",
      "============================================================\n",
      "\n",
      "Epoch = 447\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012201047623505422\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013141716094690125\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007650257493330163\n",
      "============================================================\n",
      "\n",
      "Epoch = 448\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00012121880613638652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013026818573298043\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00764949246758083\n",
      "============================================================\n",
      "\n",
      "Epoch = 449\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012049109723351586\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000129121934476532\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007648727518334072\n",
      "============================================================\n",
      "\n",
      "Epoch = 450\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011980423916148201\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012820927185651812\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647962645582239\n",
      "============================================================\n",
      "\n",
      "Epoch = 451\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001189671214139562\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012740738537038893\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647197849317681\n",
      "============================================================\n",
      "\n",
      "Epoch = 452\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001180602538784128\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001270808906898452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007646433129532749\n",
      "============================================================\n",
      "\n",
      "Epoch = 453\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011692916961447174\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012666294951301925\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007645668486219796\n",
      "============================================================\n",
      "\n",
      "Epoch = 454\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011592400085166803\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012634539314678359\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644903919371174\n",
      "============================================================\n",
      "\n",
      "Epoch = 455\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011515902605794447\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012536701155494497\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644139428979236\n",
      "============================================================\n",
      "\n",
      "Epoch = 456\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011504236157791855\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012399471569234365\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076433750150363385\n",
      "============================================================\n",
      "\n",
      "Epoch = 457\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011556428405269157\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012246960313560065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007642610677534835\n",
      "============================================================\n",
      "\n",
      "Epoch = 458\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001163165548413072\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012164378596840329\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641846416467081\n",
      "============================================================\n",
      "\n",
      "Epoch = 459\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011658801912090193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001230510016876787\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641082231825434\n",
      "============================================================\n",
      "\n",
      "Epoch = 460\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011541225997280033\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012637379894105314\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007640318123602252\n",
      "============================================================\n",
      "\n",
      "Epoch = 461\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011304306230572463\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013142325338529585\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076395540917898914\n",
      "============================================================\n",
      "\n",
      "Epoch = 462\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011101388913107413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013412404549684344\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638790136380713\n",
      "============================================================\n",
      "\n",
      "Epoch = 463\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011276725143647578\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013274198493029826\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638026257367075\n",
      "============================================================\n",
      "\n",
      "Epoch = 464\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012133061831603273\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012725648741471904\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007637262454741338\n",
      "============================================================\n",
      "\n",
      "Epoch = 465\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013598914900865458\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012585894925215923\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007636498728495864\n",
      "============================================================\n",
      "\n",
      "Epoch = 466\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015004895608863\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014314512667414853\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007635735078623015\n",
      "============================================================\n",
      "\n",
      "Epoch = 467\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001525097258212815\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000187850536763955\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634971505115153\n",
      "============================================================\n",
      "\n",
      "Epoch = 468\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013924467287565007\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002539731178350667\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634208007964641\n",
      "============================================================\n",
      "\n",
      "Epoch = 469\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012826579468619542\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00030150975106497913\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007633444587163845\n",
      "============================================================\n",
      "\n",
      "Epoch = 470\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016544745458618374\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002950251181839959\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007632681242705129\n",
      "============================================================\n",
      "\n",
      "Epoch = 471\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002985668626060669\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002455965144278705\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631917974580859\n",
      "============================================================\n",
      "\n",
      "Epoch = 472\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005197336271308652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00030068922247366545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631154782783401\n",
      "============================================================\n",
      "\n",
      "Epoch = 473\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007059065526432567\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006991440840592068\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007630391667305123\n",
      "============================================================\n",
      "\n",
      "Epoch = 474\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.000696608372468112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001566136925520006\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007629628628138392\n",
      "============================================================\n",
      "\n",
      "Epoch = 475\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00048338665657039103\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002614269685915495\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007628865665275579\n",
      "============================================================\n",
      "\n",
      "Epoch = 476\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005697376438044112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0030159943898561436\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076281027787090516\n",
      "============================================================\n",
      "\n",
      "Epoch = 477\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0019054815770668506\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0024976009464243803\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007627339968431181\n",
      "============================================================\n",
      "\n",
      "Epoch = 478\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004856275941624341\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002154017125445495\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007626577234434338\n",
      "============================================================\n",
      "\n",
      "Epoch = 479\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008447173848239085\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005678112469236226\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625814576710895\n",
      "============================================================\n",
      "\n",
      "Epoch = 480\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009277863782030587\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01495613711922504\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625051995253224\n",
      "============================================================\n",
      "\n",
      "Epoch = 481\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00719741425971492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02613055740720123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007624289490053699\n",
      "============================================================\n",
      "\n",
      "Epoch = 482\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004720954710860386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.031886538090072046\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007623527061104694\n",
      "============================================================\n",
      "\n",
      "Epoch = 483\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006121580631313384\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02712098743371886\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076227647083985835\n",
      "============================================================\n",
      "\n",
      "Epoch = 484\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010904059443369358\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.025893569969172747\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007622002431927744\n",
      "============================================================\n",
      "\n",
      "Epoch = 485\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012462598446197614\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01837150227096877\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007621240231684551\n",
      "============================================================\n",
      "\n",
      "Epoch = 486\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013948566346466473\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.012838749637901823\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007620478107661383\n",
      "============================================================\n",
      "\n",
      "Epoch = 487\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015114538314763795\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005551273118120016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007619716059850617\n",
      "============================================================\n",
      "\n",
      "Epoch = 488\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015420545633270081\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004621851265319749\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618954088244632\n",
      "============================================================\n",
      "\n",
      "Epoch = 489\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01345377739447838\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00512689217532827\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618192192835807\n",
      "============================================================\n",
      "\n",
      "Epoch = 490\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011862179190484982\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003624288481094683\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007617430373616524\n",
      "============================================================\n",
      "\n",
      "Epoch = 491\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01112328491698528\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002101793039248502\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007616668630579162\n",
      "============================================================\n",
      "\n",
      "Epoch = 492\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011218207350097844\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0019101898406787554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007615906963716104\n",
      "============================================================\n",
      "\n",
      "Epoch = 493\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009086339005237518\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0025807633638906787\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076151453730197325\n",
      "============================================================\n",
      "\n",
      "Epoch = 494\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006853712626666555\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0021097344193069098\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007614383858482431\n",
      "============================================================\n",
      "\n",
      "Epoch = 495\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005301902208807947\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001285990414845013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007613622420096583\n",
      "============================================================\n",
      "\n",
      "Epoch = 496\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004425579299255886\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016796913892288586\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612861057854573\n",
      "============================================================\n",
      "\n",
      "Epoch = 497\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0032168987030781653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002302337162467108\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612099771748788\n",
      "============================================================\n",
      "\n",
      "Epoch = 498\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002134439423248329\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001955930085620589\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007611338561771613\n",
      "============================================================\n",
      "\n",
      "Epoch = 499\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001445220849149971\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010904798820386028\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007610577427915436\n",
      "============================================================\n",
      "\n",
      "Epoch = 500\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0010582197316779804\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006432730952618067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007609816370172644\n"
     ]
    }
   ],
   "source": [
    "# test fourier net\n",
    "nn_fourier = FourierEmbeddedDNN(\n",
    "    layers=[60, 128, 128, 128, 1],\n",
    "    m=30, \n",
    "    freq_stds=[1.,2.,5.,10.,20.,50.,100.]\n",
    ")\n",
    "optim = torch.optim.Adam(\n",
    "    nn_fourier.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(inputs, outputs, nn_fourier, optim, scheduler, 2**10, 500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e3ad36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(15, 5))\n",
    "# interpolate on finer grid\n",
    "x_start, x_end = 0.0, 1.0\n",
    "nx = 10000\n",
    "xgrid = np.linspace(x_start, x_end, nx)\n",
    "inputs = torch.tensor(xgrid).reshape(-1, 1)\n",
    "plt.plot(xgrid, nn_fourier(inputs).detach().numpy().flatten(), color=\"black\", label=\"Fourier Embedded\");\n",
    "plt.plot(xgrid, nn_vanilla(inputs).detach().numpy().flatten(), lw=2.0, color='blue', label=\"Vanilla\");\n",
    "plt.plot(xgrid, f(xgrid), lw=6.0, alpha=0.4, color=\"red\", label=\"exact\");\n",
    "plt.legend();\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
