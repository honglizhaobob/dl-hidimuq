{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36233a32",
   "metadata": {},
   "source": [
    "# Regression with Fourier Features - Part 3\n",
    "\n",
    "Apply the space-time Fourier embedded net on the original linear oscillator problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe062395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10);\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07a74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vanilla deep neural net\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, layers, \n",
    "        activation=torch.nn.ReLU, \n",
    "        last_layer_activation=None,\n",
    "        initialization=None\n",
    "    ):\n",
    "        \"\"\" \n",
    "            Custom initialization of neural network layers with the option \n",
    "            of changing the output layer's activation function.\n",
    "            \n",
    "            The deep net is in space-time.\n",
    "        \"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = activation\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        if last_layer_activation is not None:\n",
    "            layer_list.append(\n",
    "            ('activation_%d' % (self.depth - 1), last_layer_activation())\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "        # custom initialization modes\n",
    "        self.initialize(mode=initialization)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def initialize(self, mode):\n",
    "        if mode == None:\n",
    "            return\n",
    "        else:\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, torch.nn.Linear):\n",
    "                    # initialize depending on mode\n",
    "                    if mode == \"xavier\":\n",
    "                        torch.nn.init.xavier_uniform_(layer.weight)\n",
    "                    elif mode == \"kaiming\":\n",
    "                        torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "                    elif mode == \"normal\":\n",
    "                        torch.nn.init.normal_(layer.weight)\n",
    "                    elif mode == \"uniform\":\n",
    "                        torch.nn.init.uniform_(layer.weight)\n",
    "                    elif mode == \"ones\":\n",
    "                        torch.nn.init.ones_(layer.weight)\n",
    "                    else:\n",
    "                        raise NotImplementedError()\n",
    "            return\n",
    "        \n",
    "class FourierEmbeddedDNN(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 activation=torch.nn.Tanh, \n",
    "                 last_layer_activation=None, \n",
    "                 initialization=None,\n",
    "                 m=1,\n",
    "                 freq_stds=None):\n",
    "        super(FourierEmbeddedDNN, self).__init__()\n",
    "        # fourier embedding is applied prior to passing into neural net, \n",
    "        # need to make sure dimensions match\n",
    "        assert layers[0] == 2*m\n",
    "        # build main DNN\n",
    "        self.layer_spec = layers\n",
    "        self.layers = self.build_nn(\n",
    "            layers, activation, last_layer_activation, initialization\n",
    "        )\n",
    "        # build fourier feature embedding\n",
    "        self.fourier_embedding = self.build_embedding(m, freq_stds)\n",
    "        \n",
    "        # build final aggregator to combine outputs of different scale fourier embeddings\n",
    "        self.build_aggregator()\n",
    "    \n",
    "    def build_nn(self, layers, activation, last_layer_activation, initialization):\n",
    "        self.depth = len(layers) - 1\n",
    "        # set up layer order dict\n",
    "        self.activation = activation\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        if last_layer_activation is not None:\n",
    "            layer_list.append(\n",
    "            ('activation_%d' % (self.depth - 1), last_layer_activation())\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        return torch.nn.Sequential(layerDict)\n",
    "    \n",
    "    def build_embedding(self, num_freqs, freq_stds):\n",
    "        # number of feature embeddings correspond to length of standard \n",
    "        # deviations specified. If `None`, by default uses only 1 embedding\n",
    "        # standard Gaussian.\n",
    "        if freq_stds:\n",
    "            self.num_embeddings = len(freq_stds)\n",
    "        else:\n",
    "            self.num_embeddings = 1\n",
    "            freq_stds = [1.0]\n",
    "        # draw frequency matrix\n",
    "        freq_matrix = [torch.randn(num_freqs, requires_grad=False) for _ in range(self.num_embeddings)]\n",
    "        for i in range(self.num_embeddings):\n",
    "            # scale by frequency standard deviation\n",
    "            freq_matrix[i] = torch.tensor(freq_stds[i])*freq_matrix[i]\n",
    "        return freq_matrix\n",
    "    \n",
    "    def build_aggregator(self):\n",
    "        # number of fourier embeddings\n",
    "        k = self.num_embeddings\n",
    "        # size of hidden layer final outputs\n",
    "        num_out = self.layer_spec[-1]\n",
    "        # create trainable aggregating weights for each embedding (simple linear aggregation\n",
    "        # , may also consider computing another nonlinear activation for each embedding, then \n",
    "        # summing all outputs).\n",
    "        self.aggregator = torch.nn.Linear(num_out*k, 1)\n",
    "        \n",
    "    def fourier_lifting(self, x, freq):\n",
    "        # input x has size (N x 1), output has size (N x 2*m) where m is number of Fourier bases\n",
    "        \n",
    "        # has size (N x m)\n",
    "        x = freq * x\n",
    "        # lift to sin and cos space\n",
    "        x = torch.concat(\n",
    "            [\n",
    "                torch.cos(2*torch.pi*x), \n",
    "                torch.sin(2*torch.pi*x)\n",
    "            ], dim=1\n",
    "        )\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # inputs x has size (N x 1)\n",
    "        # create Fourier features\n",
    "        lifted = []\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted.append(self.fourier_lifting(x, self.fourier_embedding[i]))\n",
    "        # lifted is a length-k list of (N x 2*m) tensors of lifted features according to \n",
    "        # k different scales.\n",
    "        \n",
    "        # now pass each (N x 2*m) features into the hidden layers\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted[i] = self.layers(lifted[i])\n",
    "        \n",
    "        # lifted is a length-k list of (N x num_out) tensor of transformed fourier features\n",
    "        # now concatenate into (N x num_out*k) and pass into aggregator to obtain (N x 1) prediction\n",
    "        lifted = torch.concat(lifted, dim=1)\n",
    "        # final aggregation\n",
    "        lifted = self.aggregator(lifted)\n",
    "        return lifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b0c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierEmbeddedDNN2d(torch.nn.Module):\n",
    "    \"\"\" \n",
    "        A deep neural network suitable for learning space-time functions by stacking\n",
    "        two separate Fourier embedded nets together and combining the results.\n",
    "\n",
    "        The spatial and temporal Fourier mappings share the same DNN for hidden transformations.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, activation=torch.nn.Tanh, \n",
    "                 last_layer_activation=None, initialization=None, \n",
    "                 m=1, freq_stds=None):\n",
    "        super(FourierEmbeddedDNN2d, self).__init__()\n",
    "        # fourier embedding is applied prior to passing into neural net, \n",
    "        # need to make sure dimensions match\n",
    "        assert layers[0] == 2*m\n",
    "        if freq_stds is not None:\n",
    "            assert freq_stds.shape[1] == 2, \"Specify both space and time frequency scales. \"\n",
    "        else:\n",
    "            freq_stds = np.ones([1, 2])\n",
    "        \n",
    "        # build main DNN\n",
    "        self.layer_spec = layers\n",
    "        self.layers = self.build_nn(\n",
    "            layers, activation, last_layer_activation, initialization\n",
    "        )\n",
    "        # build fourier feature embedding\n",
    "        self.fourier_embedding_time, self.fourier_embedding_space = self.build_embedding(m, freq_stds)\n",
    "        \n",
    "        # build final aggregator to combine outputs of different scale fourier embeddings\n",
    "        self.build_aggregator()\n",
    "    \n",
    "    def build_nn(self, layers, activation, last_layer_activation, initialization):\n",
    "        self.depth = len(layers) - 1\n",
    "        # set up layer order dict\n",
    "        self.activation = activation\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        if last_layer_activation is not None:\n",
    "            layer_list.append(\n",
    "            ('activation_%d' % (self.depth - 1), last_layer_activation())\n",
    "        )\n",
    "\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        return torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def build_embedding(self, num_freqs, freq_stds):\n",
    "        # number of feature embeddings correspond to length of standard \n",
    "        # deviations specified. If `None`, by default uses only 1 embedding\n",
    "        # standard Gaussian.\n",
    "        self.num_embeddings = freq_stds.shape[0]\n",
    "        # time domain scales\n",
    "        freq_stds_t = freq_stds[:, 0].flatten()\n",
    "        # spatial domain scales\n",
    "        freq_stds_x = freq_stds[:, 1].flatten()\n",
    "        \n",
    "        # draw frequency matrix (time)\n",
    "        freq_matrix_t = [torch.randn(num_freqs, requires_grad=False) for _ in range(self.num_embeddings)]\n",
    "        # draw frequency matrix (space)\n",
    "        freq_matrix_x = [torch.randn(num_freqs, requires_grad=False) for _ in range(self.num_embeddings)]\n",
    "        \n",
    "        for i in range(self.num_embeddings):\n",
    "            # scale by frequency standard deviation\n",
    "            freq_matrix_t[i] = torch.tensor(freq_stds_t[i])*freq_matrix_t[i]\n",
    "            freq_matrix_x[i] = torch.tensor(freq_stds_x[i])*freq_matrix_x[i]\n",
    "        return freq_matrix_t, freq_matrix_x\n",
    "\n",
    "    def fourier_lifting(self, x, freq):\n",
    "        # input x has size (N x 1), output has size (N x 2*m) where m is number of Fourier bases\n",
    "        \n",
    "        # has size (N x m)\n",
    "        x = freq * x\n",
    "        # lift to sin and cos space\n",
    "        x = torch.concat(\n",
    "            [\n",
    "                torch.cos(2*torch.pi*x), \n",
    "                torch.sin(2*torch.pi*x)\n",
    "            ], dim=1\n",
    "        )\n",
    "        return x\n",
    "    \n",
    "    def build_aggregator(self):\n",
    "        # number of fourier embeddings\n",
    "        k = self.num_embeddings\n",
    "        # size of hidden layer final outputs\n",
    "        num_out = self.layer_spec[-1]\n",
    "        # create trainable aggregating weights for each embedding (simple linear aggregation\n",
    "        # , may also consider computing another nonlinear activation for each embedding, then \n",
    "        # summing all outputs).\n",
    "        self.aggregator = torch.nn.Linear(num_out*k, 1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # inputs has size (N x 2)\n",
    "        # create Fourier features for t\n",
    "        t = inputs[:, 0][:, None]\n",
    "        x = inputs[:, 1][:, None]\n",
    "        \n",
    "        lifted_t, lifted_x = [], []\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted_t.append(self.fourier_lifting(t, self.fourier_embedding_time[i]))\n",
    "            lifted_x.append(self.fourier_lifting(x, self.fourier_embedding_space[i]))\n",
    "            \n",
    "        # lifted is a length-k list of (N x 2*m) tensors of lifted features according to \n",
    "        # k different scales.\n",
    "        \n",
    "        # now pass each (N x 2*m) features into the hidden layers\n",
    "        for i in range(self.num_embeddings):\n",
    "            lifted_t[i] = self.layers(lifted_t[i])\n",
    "            lifted_x[i] = self.layers(lifted_x[i])\n",
    "        \n",
    "        \n",
    "        # lifted is a length-k list of (N x num_out) tensor of transformed fourier features\n",
    "        # now concatenate into (N x num_out*k) and pass into aggregator to obtain (N x 1) prediction\n",
    "        lifted_t = torch.concat(lifted_t, dim=1)\n",
    "        lifted_x = torch.concat(lifted_x, dim=1)\n",
    "        \n",
    "        # elementwise multiplication\n",
    "        lifted = lifted_t * lifted_x\n",
    "        # final aggregation\n",
    "        lifted = self.aggregator(lifted)\n",
    "        return lifted\n",
    "    \n",
    "# helper\n",
    "def cartesian_data(x, y):\n",
    "    \"\"\"\n",
    "        Given two 1d arrays of points, return their Carteisan product\n",
    "        as a list, assuming column-major flattening.\n",
    "    \"\"\"\n",
    "    nx, ny = len(x), len(y)\n",
    "    y_mesh, x_mesh = torch.meshgrid(y, x, indexing=None)\n",
    "    x_mesh_flat = x_mesh.ravel().reshape(-1, 1)\n",
    "    y_mesh_flat = y_mesh.ravel().reshape(-1, 1)\n",
    "    res = torch.cat(\n",
    "        [x_mesh_flat, y_mesh_flat], dim=1\n",
    "    )\n",
    "    assert len(res) == nx * ny\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92445366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/honglizhaobob/opt/anaconda3/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:227: MatReadWarning: Duplicate variable name \"None\" in stream - replacing previous with new\n",
      "Consider mio5.varmats_from_mat to split file into single variable files\n",
      "  matfile_dict = MR.get_variables(variable_names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000) (1, 1000) (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "# modify dataset\n",
    "full_data_path = \"../data/LinearOscillator/OU_Noise_energy.mat\"\n",
    "data = scipy.io.loadmat(full_data_path)\n",
    "# subsample factor\n",
    "space_factor = 5\n",
    "time_factor = 5\n",
    "new_pmc = (data[\"v_density\"].T)[0:-1:time_factor, 0:-1:space_factor]\n",
    "new_xgrid = data[\"xi\"][:, 0:-1:space_factor]\n",
    "new_tgrid = data[\"tspan\"][:, 0:-1:time_factor]\n",
    "# save new data\n",
    "new_data_path = \"../data/LinearOscillator/OU_Noise_energy_subsample{}.mat\".format(int(space_factor*time_factor))\n",
    "scipy.io.savemat(\n",
    "    new_data_path, {\"pmc\": new_pmc, \"xgrid\": new_xgrid, \"tgrid\": new_tgrid}\n",
    ")\n",
    "# test saved data\n",
    "new_data_path = \"../data/LinearOscillator/OU_Noise_energy_subsample25.mat\"\n",
    "data = scipy.io.loadmat(new_data_path)\n",
    "print(data[\"pmc\"].shape, data[\"xgrid\"].shape, data[\"tgrid\"].shape)\n",
    "# set random seeds\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10);\n",
    "\n",
    "data_path = \"../data/LinearOscillator/OU_Noise_energy_subsample25.mat\"\n",
    "data = scipy.io.loadmat(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a27423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/honglizhaobob/opt/anaconda3/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_2a19nf9hj1/croot/pytorch_1675190251927/work/aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "X = cartesian_data(torch.tensor(new_tgrid[0].flatten()), torch.tensor(new_xgrid.flatten()))\n",
    "y = torch.tensor(new_pmc).T.flatten().reshape(-1, 1)\n",
    "# define training function\n",
    "def train(inputs, outputs, model, optim, scheduler, batch_size, epochs, shuffle=True):\n",
    "    X, y = inputs, outputs\n",
    "    nx = X.shape[0]\n",
    "    num_batches = int(nx/batch_size)\n",
    "    for i in range(epochs):\n",
    "        print(\"============================================================\\n\")\n",
    "        print(\"Epoch = {}\\n\".format(i+1));\n",
    "        print(\"============================================================\\n\")\n",
    "        model.train()\n",
    "        if shuffle:\n",
    "            tmp = np.random.permutation(nx)\n",
    "            X, y = X[tmp, :].data.clone(), y[tmp, :].data.clone()\n",
    "        for idx in range(num_batches):\n",
    "            if idx % 100 == 0:\n",
    "                print(\"| => | Batch {} |\\n\".format(idx+1))\n",
    "        # closure definition\n",
    "            def closure():\n",
    "                optim.zero_grad()\n",
    "                start_idx = idx*batch_size\n",
    "                end_idx = (idx+1)*batch_size\n",
    "                if idx + 1 == num_batches:\n",
    "                    # if last batch\n",
    "                    end_idx = -1\n",
    "                Xb, yb = X[start_idx:end_idx, :].data.clone(), y[start_idx:end_idx, :].data.clone()\n",
    "\n",
    "                # require gradients\n",
    "                Xb.requires_grad = True\n",
    "                # make a prediction on the batch\n",
    "                y_pred = model.forward(Xb)\n",
    "                # compute L^2 loss\n",
    "                loss = torch.mean((y_pred - yb)**2)\n",
    "                # backpropagate\n",
    "                loss.backward()\n",
    "                if idx % 100 == 0:\n",
    "                    print(\"==> Batch {} loss = {}\".format(idx, loss.item()))\n",
    "                return loss\n",
    "            optim.step(closure=closure)\n",
    "        if scheduler:\n",
    "            # step scheduler after epoch if there is one\n",
    "            scheduler.step()\n",
    "            print(\"---------- \\n\")\n",
    "            print(\"++ Learning rate reduced, now at = {}\".format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dced14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Epoch = 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001138279138701199\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.7454255658454435e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.6799766812487297e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079992\n",
      "============================================================\n",
      "\n",
      "Epoch = 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6774457860591782e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.8571954020556704e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.9517191435465477e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007998400079999999\n",
      "============================================================\n",
      "\n",
      "Epoch = 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.401034934061155e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 2.897535656921271e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.7518109540887333e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007997600239991999\n",
      "============================================================\n",
      "\n",
      "Epoch = 4\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.4110320024138943e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.7000886393870017e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.471781534950747e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996800479968\n",
      "============================================================\n",
      "\n",
      "Epoch = 5\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1347971008574573e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 2.691149657441059e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.3295204108516836e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996000799920003\n",
      "============================================================\n",
      "\n",
      "Epoch = 6\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.232241702123127e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.59078665202917e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.7319535749651354e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007995201199840011\n",
      "============================================================\n",
      "\n",
      "Epoch = 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.605525769570971e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.8094261717192355e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.076238348687648e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007994401679720027\n",
      "============================================================\n",
      "\n",
      "Epoch = 8\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.674500889364086e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.6261681075762562e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.4550802025691e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007993602239552054\n",
      "============================================================\n",
      "\n",
      "Epoch = 9\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.467583467265064e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 2.203015480627185e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.1211555445871368e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992802879328098\n",
      "============================================================\n",
      "\n",
      "Epoch = 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8721850488887172e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 2.1071861472492066e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.7034403081530785e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992003599040166\n",
      "============================================================\n",
      "\n",
      "Epoch = 11\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3802880698031327e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.8586382266379308e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.4352208634798067e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007991204398680262\n",
      "============================================================\n",
      "\n",
      "Epoch = 12\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.99088617691309e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.8129315211803644e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.286550757317894e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007990405278240395\n",
      "============================================================\n",
      "\n",
      "Epoch = 13\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7224859601819312e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.529663546463601e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.4602398286268692e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007989606237712572\n",
      "============================================================\n",
      "\n",
      "Epoch = 14\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3529847159549504e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.159989659752708e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.5624499852083176e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079888072770888\n",
      "============================================================\n",
      "\n",
      "Epoch = 15\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.26811618661845e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.5047780525538924e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.6120399075197074e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007988008396361091\n",
      "============================================================\n",
      "\n",
      "Epoch = 16\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7777519457929459e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.1591141594675089e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.5004967223916295e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007987209595521455\n",
      "============================================================\n",
      "\n",
      "Epoch = 17\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7104708958885193e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.328987569675142e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.3589465812134096e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007986410874561903\n",
      "============================================================\n",
      "\n",
      "Epoch = 18\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4964658096104913e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.1033690689667343e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.0034278765609864e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007985612233474448\n",
      "============================================================\n",
      "\n",
      "Epoch = 19\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3103744856859697e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.6530460167847082e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.3034759730955433e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079848136722511\n",
      "============================================================\n",
      "\n",
      "Epoch = 20\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2112743907373056e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.3928161754249403e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.1144584410714667e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007984015190883875\n",
      "============================================================\n",
      "\n",
      "Epoch = 21\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1245333023616448e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.0179873907900387e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.476444509533931e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007983216789364787\n",
      "============================================================\n",
      "\n",
      "Epoch = 22\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 9.642378235876923e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.2596340991066998e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.08290196866084e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00798241846768585\n",
      "============================================================\n",
      "\n",
      "Epoch = 23\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1960414152381779e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.1005260024317373e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.664729690557584e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007981620225839082\n",
      "============================================================\n",
      "\n",
      "Epoch = 24\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.309967719284402e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 1.0729614753536355e-06\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 9.470345750777385e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980822063816497\n",
      "============================================================\n",
      "\n",
      "Epoch = 25\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 6.265683032743988e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 7.665081675237523e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 8.874479323418739e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980023981610115\n",
      "============================================================\n",
      "\n",
      "Epoch = 26\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.087789511137158e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 7.103609687992377e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.0849944871931945e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007979225979211954\n",
      "============================================================\n",
      "\n",
      "Epoch = 27\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 6.587531585592959e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 9.027148100427629e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 9.383261485133808e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007978428056614032\n",
      "============================================================\n",
      "\n",
      "Epoch = 28\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.095260665554454e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 9.021031351932557e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 7.33540394832251e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007977630213808371\n",
      "============================================================\n",
      "\n",
      "Epoch = 29\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 6.239654360094138e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 7.840408202264935e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.790153725622246e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797683245078699\n",
      "============================================================\n",
      "\n",
      "Epoch = 30\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.317733058978703e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 9.592889295667523e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 8.057637491719341e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007976034767541912\n",
      "============================================================\n",
      "\n",
      "Epoch = 31\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.955842291687717e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 7.180313182623208e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 8.554579635105444e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007975237164065159\n",
      "============================================================\n",
      "\n",
      "Epoch = 32\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2174669891978993e-06\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.988476834940848e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.654949959588269e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007974439640348753\n",
      "============================================================\n",
      "\n",
      "Epoch = 33\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.164240315259122e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.904420270303292e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.825278028328968e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007973642196384719\n",
      "============================================================\n",
      "\n",
      "Epoch = 34\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 6.482194275059344e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 6.492030507033638e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.028504782526788e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797284483216508\n",
      "============================================================\n",
      "\n",
      "Epoch = 35\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.95199641750884e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 6.187381108495866e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 8.291168546877336e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007972047547681863\n",
      "============================================================\n",
      "\n",
      "Epoch = 36\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.636042994771548e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.636398934308206e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.965344880636532e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007971250342927096\n",
      "============================================================\n",
      "\n",
      "Epoch = 37\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 6.373344022291644e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 6.103687371133919e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.803549501045996e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007970453217892803\n",
      "============================================================\n",
      "\n",
      "Epoch = 38\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.746486577033133e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.837951789791505e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 8.073277308505461e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007969656172571013\n",
      "============================================================\n",
      "\n",
      "Epoch = 39\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 4.912617917990345e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.609908185587464e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.048519201871429e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968859206953756\n",
      "============================================================\n",
      "\n",
      "Epoch = 40\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 5.211750576957671e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.127753742061343e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.307243633055334e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968062321033061\n",
      "============================================================\n",
      "\n",
      "Epoch = 41\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.820928934267195e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.131344565857963e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.963378807966427e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007967265514800958\n",
      "============================================================\n",
      "\n",
      "Epoch = 42\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.824495397363416e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 6.961123373426314e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 1.040216740638796e-06\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007966468788249479\n",
      "============================================================\n",
      "\n",
      "Epoch = 43\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.437615612111251e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.7029858182040574e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 3.940345472757975e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007965672141370653\n",
      "============================================================\n",
      "\n",
      "Epoch = 44\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.726468796101935e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 4.4919615762879174e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 3.449624541035282e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007964875574156515\n",
      "============================================================\n",
      "\n",
      "Epoch = 45\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 4.135636885271273e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 5.824323676046979e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.15724686609621e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079640790865991\n",
      "============================================================\n",
      "\n",
      "Epoch = 46\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.409354857155012e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.1981398149688323e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 5.792363596824148e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007963282678690441\n",
      "============================================================\n",
      "\n",
      "Epoch = 47\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 4.0435932609676927e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 4.302781615943332e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 4.844339947571941e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007962486350422572\n",
      "============================================================\n",
      "\n",
      "Epoch = 48\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.792714883978727e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.0164223280868204e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 2.9275952116804286e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00796169010178753\n",
      "============================================================\n",
      "\n",
      "Epoch = 49\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.6385972628793725e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.160023824122858e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 3.2288552356624715e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960893932777352\n",
      "============================================================\n",
      "\n",
      "Epoch = 50\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.5734753687304546e-07\n",
      "| => | Batch 101 |\n",
      "\n",
      "==> Batch 100 loss = 3.392908521068288e-07\n",
      "| => | Batch 201 |\n",
      "\n",
      "==> Batch 200 loss = 6.733864142089095e-07\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960097843384074\n"
     ]
    }
   ],
   "source": [
    "# testing Fourier embedded net in 2d\n",
    "nn_fourier2d = FourierEmbeddedDNN2d(\n",
    "    layers=[40, 128, 128, 128, 1],\n",
    "    m=20, \n",
    "    freq_stds=np.array([[1.,2.,10.,20.,100.], [1.,2.,10.,20.,100.]]).T\n",
    ")\n",
    "optim = torch.optim.Adam(\n",
    "    nn_fourier2d.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(X, y, nn_fourier2d, optim, scheduler, 2**12, 50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38e45926",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pred = nn_fourier2d(X).reshape([len(new_xgrid[0]), len(new_tgrid[0])]).detach().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5886944",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exact = data[\"pmc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef3f8618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 100\n",
    "plt.figure(1);\n",
    "plt.plot(data[\"xgrid\"].flatten(), p_pred[idx, :]);\n",
    "plt.plot(data[\"xgrid\"].flatten(), p_exact[idx, :]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b934f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
