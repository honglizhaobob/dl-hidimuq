{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9753357",
   "metadata": {},
   "source": [
    "# Regression with Fourier Features\n",
    "\n",
    "Initially observed in: https://arxiv.org/abs/2006.10739\n",
    "\n",
    "The inclusion of Fourier features allows neural networks to capture high frequency information of the target function. In this short note, we compare a vanilla DNN with another Fourier-feature embedded DNN on the task of learning a (noise-perturbed) high frequency function.\n",
    "\n",
    "This notebook should be self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d068d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10);\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# import basic DNNs\n",
    "from PINN.utils.dnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a10ffe",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c02e364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# oscillations with decay\n",
    "#f = lambda x: 100*(np.exp(-2.0*x)*np.sin(10*np.pi*x))+np.cos(5.0*np.pi*x)\n",
    "\n",
    "# different frequencies\n",
    "#f = lambda x: np.sin(2*np.pi*x) + np.cos(10.*np.pi*x) + 2.0*np.sin(15.*np.pi*x) + np.sin(100.0*np.pi*x)\n",
    "\n",
    "# linear function\n",
    "#f = lambda x: 10.0*(x**2)\n",
    "\n",
    "# oscillations\n",
    "f = lambda x: 2.0 * np.sin(2.0*np.pi*x)\n",
    "\n",
    "# 1/x\n",
    "#f = lambda x: np.sin(10.0*np.pi/x)\n",
    "x_start, x_end = 0.0, 2*np.pi\n",
    "nx = 2048\n",
    "xgrid = np.linspace(x_start, x_end, nx)\n",
    "dx = xgrid[1]-xgrid[0]\n",
    "# visualize function with noise perturbation\n",
    "f_data = f(xgrid)\n",
    "noise_level = 0.0\n",
    "f_data = f_data + noise_level * np.random.randn(f_data.shape[0])\n",
    "plt.plot(xgrid, f_data, \"--\", color=\"red\", lw=3.0, label=\"exact\", alpha=0.6);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a12a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "inputs = torch.tensor(xgrid).reshape(-1, 1)\n",
    "outputs = torch.tensor(f_data).reshape(-1, 1)\n",
    "\n",
    "# define training function\n",
    "def train(inputs, outputs, model, optim, scheduler, batch_size, epochs, shuffle=True):\n",
    "    X, y = inputs, outputs\n",
    "    nx = X.shape[0]\n",
    "    num_batches = int(nx/batch_size)\n",
    "    for i in range(epochs):\n",
    "        print(\"============================================================\\n\")\n",
    "        print(\"Epoch = {}\\n\".format(i+1));\n",
    "        print(\"============================================================\\n\")\n",
    "        model.train()\n",
    "        if shuffle:\n",
    "            tmp = np.random.permutation(nx)\n",
    "            X, y = X[tmp, :].data.clone(), y[tmp, :].data.clone()\n",
    "        for idx in range(num_batches):\n",
    "            print(\"| => | Batch {} |\\n\".format(idx+1))\n",
    "        # closure definition\n",
    "            def closure():\n",
    "                optim.zero_grad()\n",
    "                start_idx = idx*batch_size\n",
    "                end_idx = (idx+1)*batch_size\n",
    "                if idx + 1 == num_batches:\n",
    "                    # if last batch\n",
    "                    end_idx = -1\n",
    "                Xb, yb = X[start_idx:end_idx, :].data.clone(), y[start_idx:end_idx, :].data.clone()\n",
    "\n",
    "                # require gradients\n",
    "                Xb.requires_grad = True\n",
    "                # make a prediction on the batch\n",
    "                y_pred = model.forward(Xb)\n",
    "                # compute L^2 loss\n",
    "                loss = torch.mean((y_pred - yb)**2)\n",
    "                # backpropagate\n",
    "                loss.backward()\n",
    "                print(\"==> Batch {} loss = {}\".format(idx, loss.item()))\n",
    "                return loss\n",
    "            optim.step(closure=closure)\n",
    "        if scheduler:\n",
    "            # step scheduler after epoch if there is one\n",
    "            scheduler.step()\n",
    "            print(\"---------- \\n\")\n",
    "            print(\"++ Learning rate reduced, now at = {}\".format(scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be654f9",
   "metadata": {},
   "source": [
    "Testing neural net performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea2549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Epoch = 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9808361107062167\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.657134237836763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079992\n",
      "============================================================\n",
      "\n",
      "Epoch = 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 3.0828958499129056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 4.85536430164416\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007998400079999999\n",
      "============================================================\n",
      "\n",
      "Epoch = 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.2825732955195885\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.225056636824656\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007997600239991999\n",
      "============================================================\n",
      "\n",
      "Epoch = 4\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.36306096064594\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.89311583985132\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996800479968\n",
      "============================================================\n",
      "\n",
      "Epoch = 5\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.1336723078229496\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1896497826234733\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996000799920003\n",
      "============================================================\n",
      "\n",
      "Epoch = 6\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.919674855373356\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1337488720971076\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007995201199840011\n",
      "============================================================\n",
      "\n",
      "Epoch = 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.159130926834679\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.242887629629778\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007994401679720027\n",
      "============================================================\n",
      "\n",
      "Epoch = 8\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.0594379029433165\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0846411465929195\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007993602239552054\n",
      "============================================================\n",
      "\n",
      "Epoch = 9\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8675611060316015\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1247121439964145\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992802879328098\n",
      "============================================================\n",
      "\n",
      "Epoch = 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8911441436533503\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.2518499738819484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992003599040166\n",
      "============================================================\n",
      "\n",
      "Epoch = 11\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8781002459134768\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1621274982983985\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007991204398680262\n",
      "============================================================\n",
      "\n",
      "Epoch = 12\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8144560780490189\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0660566506124876\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007990405278240395\n",
      "============================================================\n",
      "\n",
      "Epoch = 13\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.865973499671064\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0828101582988947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007989606237712572\n",
      "============================================================\n",
      "\n",
      "Epoch = 14\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.9080813613742464\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.079757020808738\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079888072770888\n",
      "============================================================\n",
      "\n",
      "Epoch = 15\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.8383516549320436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065803012877556\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007988008396361091\n",
      "============================================================\n",
      "\n",
      "Epoch = 16\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7672604822880347\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1104860161809627\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007987209595521455\n",
      "============================================================\n",
      "\n",
      "Epoch = 17\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.755048258443526\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1319271795235104\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007986410874561903\n",
      "============================================================\n",
      "\n",
      "Epoch = 18\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7420748342751622\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0893846410410113\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007985612233474448\n",
      "============================================================\n",
      "\n",
      "Epoch = 19\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7357579299165078\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0647937820503612\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079848136722511\n",
      "============================================================\n",
      "\n",
      "Epoch = 20\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7525935780253965\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.067472015771825\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007984015190883875\n",
      "============================================================\n",
      "\n",
      "Epoch = 21\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.7428644659551205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.064687199387279\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007983216789364787\n",
      "============================================================\n",
      "\n",
      "Epoch = 22\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.705611295305112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.076916885175118\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00798241846768585\n",
      "============================================================\n",
      "\n",
      "Epoch = 23\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6819018467747417\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.095553381484738\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007981620225839082\n",
      "============================================================\n",
      "\n",
      "Epoch = 24\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6703993933002752\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.08594664778355\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980822063816497\n",
      "============================================================\n",
      "\n",
      "Epoch = 25\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6632374786733783\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0684215965691983\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980023981610115\n",
      "============================================================\n",
      "\n",
      "Epoch = 26\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6652175641715146\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.064975544882956\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007979225979211954\n",
      "============================================================\n",
      "\n",
      "Epoch = 27\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6589566929308492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065221489741762\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007978428056614032\n",
      "============================================================\n",
      "\n",
      "Epoch = 28\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6380399809538657\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0706053429611266\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007977630213808371\n",
      "============================================================\n",
      "\n",
      "Epoch = 29\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6202910593787632\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.077738449654371\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797683245078699\n",
      "============================================================\n",
      "\n",
      "Epoch = 30\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6089031690827653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0733903078455564\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007976034767541912\n",
      "============================================================\n",
      "\n",
      "Epoch = 31\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.6006416960122043\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0664354604502875\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007975237164065159\n",
      "============================================================\n",
      "\n",
      "Epoch = 32\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5948616482955216\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0649824996993575\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007974439640348753\n",
      "============================================================\n",
      "\n",
      "Epoch = 33\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.583386031118955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065508138477379\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007973642196384719\n",
      "============================================================\n",
      "\n",
      "Epoch = 34\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5674731931699502\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.068466205166071\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797284483216508\n",
      "============================================================\n",
      "\n",
      "Epoch = 35\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5541641547663079\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 2.0692711011302127\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007972047547681863\n",
      "============================================================\n",
      "\n",
      "Epoch = 36\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5426219670438794\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.066099473919615\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007971250342927096\n",
      "============================================================\n",
      "\n",
      "Epoch = 37\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.532546126478858\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06434586816664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007970453217892803\n",
      "============================================================\n",
      "\n",
      "Epoch = 38\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5214393591354174\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0642387752172753\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007969656172571013\n",
      "============================================================\n",
      "\n",
      "Epoch = 39\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5073036483745357\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0653854363910256\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968859206953756\n",
      "============================================================\n",
      "\n",
      "Epoch = 40\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4935882123851254\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0661715458040244\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968062321033061\n",
      "============================================================\n",
      "\n",
      "Epoch = 41\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.48124711115154\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.064764379389927\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007967265514800958\n",
      "============================================================\n",
      "\n",
      "Epoch = 42\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4698689665783653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0635845993658366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007966468788249479\n",
      "============================================================\n",
      "\n",
      "Epoch = 43\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.458382945931588\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06340805393458\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007965672141370653\n",
      "============================================================\n",
      "\n",
      "Epoch = 44\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4458055541479569\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063868673768301\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007964875574156515\n",
      "============================================================\n",
      "\n",
      "Epoch = 45\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.433752275590022\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.064136887563729\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079640790865991\n",
      "============================================================\n",
      "\n",
      "Epoch = 46\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4229558449646913\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0634632167000144\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007963282678690441\n",
      "============================================================\n",
      "\n",
      "Epoch = 47\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.413275649402968\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062902505334934\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007962486350422572\n",
      "============================================================\n",
      "\n",
      "Epoch = 48\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.4042091125862801\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062827002397402\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00796169010178753\n",
      "============================================================\n",
      "\n",
      "Epoch = 49\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3953385270011252\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0630793404780596\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960893932777352\n",
      "============================================================\n",
      "\n",
      "Epoch = 50\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3871999169216391\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0631442889454106\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960097843384074\n",
      "============================================================\n",
      "\n",
      "Epoch = 51\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3800064985403737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0627716632074\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007959301833599735\n",
      "============================================================\n",
      "\n",
      "Epoch = 52\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3735378159527887\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0624917922050083\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007958505903416374\n",
      "============================================================\n",
      "\n",
      "Epoch = 53\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3674166583712961\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0624893758543363\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007957710052826033\n",
      "============================================================\n",
      "\n",
      "Epoch = 54\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3615078406448788\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062631630760624\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007956914281820751\n",
      "============================================================\n",
      "\n",
      "Epoch = 55\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3561408875256666\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625901024855917\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00795611859039257\n",
      "============================================================\n",
      "\n",
      "Epoch = 56\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3513426166830966\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062362252395888\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007955322978533531\n",
      "============================================================\n",
      "\n",
      "Epoch = 57\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.346895032474314\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062243644341722\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007954527446235678\n",
      "============================================================\n",
      "\n",
      "Epoch = 58\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3424609487836245\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0623190788075894\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007953731993491055\n",
      "============================================================\n",
      "\n",
      "Epoch = 59\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3380028687271488\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062432211088666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952936620291706\n",
      "============================================================\n",
      "\n",
      "Epoch = 60\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3336788877923524\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0623631524965775\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952141326629678\n",
      "============================================================\n",
      "\n",
      "Epoch = 61\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3294610912020801\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062233388231295\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007951346112497015\n",
      "============================================================\n",
      "\n",
      "Epoch = 62\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3251038762770921\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062277428273139\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007950550977885766\n",
      "============================================================\n",
      "\n",
      "Epoch = 63\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3204303680466831\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062472861713501\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007949755922787977\n",
      "============================================================\n",
      "\n",
      "Epoch = 64\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3156161594825853\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062563214734261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948960947195698\n",
      "============================================================\n",
      "\n",
      "Epoch = 65\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3107909173315988\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625419217766128\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948166051100979\n",
      "============================================================\n",
      "\n",
      "Epoch = 66\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3056922776503515\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0627087288629293\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007947371234495869\n",
      "============================================================\n",
      "\n",
      "Epoch = 67\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2999350043512563\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063126035044642\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00794657649737242\n",
      "============================================================\n",
      "\n",
      "Epoch = 68\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2935429619825805\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06348452018841\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007945781839722683\n",
      "============================================================\n",
      "\n",
      "Epoch = 69\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.286708475932002\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063721232572043\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944987261538711\n",
      "============================================================\n",
      "\n",
      "Epoch = 70\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.279279480653468\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0642388895787858\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944192762812557\n",
      "============================================================\n",
      "\n",
      "Epoch = 71\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2709811970455056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065191976357574\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007943398343536277\n",
      "============================================================\n",
      "\n",
      "Epoch = 72\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2619947760076717\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.066231335802292\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007942604003701923\n",
      "============================================================\n",
      "\n",
      "Epoch = 73\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2525154091577742\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0672036894967696\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941809743301553\n",
      "============================================================\n",
      "\n",
      "Epoch = 74\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 1.2421291418241547\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.068257851490725\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941015562327224\n",
      "============================================================\n",
      "\n",
      "Epoch = 75\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.23057617924117\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.069125553499817\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007940221460770992\n",
      "============================================================\n",
      "\n",
      "Epoch = 76\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2183854697389047\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.069575368853999\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007939427438624915\n",
      "============================================================\n",
      "\n",
      "Epoch = 77\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.2057963481662775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0701472214973813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007938633495881052\n",
      "============================================================\n",
      "\n",
      "Epoch = 78\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1923445514163329\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0713724795548734\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007937839632531463\n",
      "============================================================\n",
      "\n",
      "Epoch = 79\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1778758623358707\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.073025447745639\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793704584856821\n",
      "============================================================\n",
      "\n",
      "Epoch = 80\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.162894536199425\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0745957806789783\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007936252143983354\n",
      "============================================================\n",
      "\n",
      "Epoch = 81\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1479104774973385\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.075931825748236\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007935458518768956\n",
      "============================================================\n",
      "\n",
      "Epoch = 82\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.133079210007325\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.077044555492117\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793466497291708\n",
      "============================================================\n",
      "\n",
      "Epoch = 83\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1186186320692904\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.077900508299114\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933871506419788\n",
      "============================================================\n",
      "\n",
      "Epoch = 84\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.1048575742068265\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0786753202299617\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933078119269146\n",
      "============================================================\n",
      "\n",
      "Epoch = 85\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0918336151682817\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0796321962874695\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007932284811457219\n",
      "============================================================\n",
      "\n",
      "Epoch = 86\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0795654101532954\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0806834588084206\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007931491582976073\n",
      "============================================================\n",
      "\n",
      "Epoch = 87\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.068413776738064\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.081522422674225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007930698433817775\n",
      "============================================================\n",
      "\n",
      "Epoch = 88\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.058679389707681\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.082074031689935\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929905363974393\n",
      "============================================================\n",
      "\n",
      "Epoch = 89\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.050266548117602\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0824549486549606\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929112373437996\n",
      "============================================================\n",
      "\n",
      "Epoch = 90\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0429051420793405\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0827520238513375\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007928319462200652\n",
      "============================================================\n",
      "\n",
      "Epoch = 91\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0363397945822581\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0830386748457848\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007927526630254433\n",
      "============================================================\n",
      "\n",
      "Epoch = 92\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0303845407335255\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0833589208275844\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007926733877591408\n",
      "============================================================\n",
      "\n",
      "Epoch = 93\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0249893956770653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083606914452214\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792594120420365\n",
      "============================================================\n",
      "\n",
      "Epoch = 94\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0202414957954509\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083670189861123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007925148610083229\n",
      "============================================================\n",
      "\n",
      "Epoch = 95\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.016101754305238\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0836405507944677\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007924356095222221\n",
      "============================================================\n",
      "\n",
      "Epoch = 96\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0123779973129419\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0836939053268067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079235636596127\n",
      "============================================================\n",
      "\n",
      "Epoch = 97\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0089235987738232\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.08379015552953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007922771303246739\n",
      "============================================================\n",
      "\n",
      "Epoch = 98\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0058351069509386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083802262941443\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921979026116414\n",
      "============================================================\n",
      "\n",
      "Epoch = 99\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0030912296686796\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0836817459124863\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921186828213802\n",
      "============================================================\n",
      "\n",
      "Epoch = 100\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0006676161647503\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0835853475575594\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792039470953098\n",
      "============================================================\n",
      "\n",
      "Epoch = 101\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9983989760890892\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083434756306981\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007919602670060026\n",
      "============================================================\n",
      "\n",
      "Epoch = 102\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9969458941192881\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083372660359269\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791881070979302\n",
      "============================================================\n",
      "\n",
      "Epoch = 103\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9973964767777346\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083067053173511\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791801882872204\n",
      "============================================================\n",
      "\n",
      "Epoch = 104\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.000882388436708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0829492396350435\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007917227026839167\n",
      "============================================================\n",
      "\n",
      "Epoch = 105\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0032952927143093\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.08249963461008\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007916435304136483\n",
      "============================================================\n",
      "\n",
      "Epoch = 106\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9925201749987008\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0817917197657603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791564366060607\n",
      "============================================================\n",
      "\n",
      "Epoch = 107\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9821700504856941\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0816377432049364\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914852096240009\n",
      "============================================================\n",
      "\n",
      "Epoch = 108\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.981307417149051\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.081393515204467\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914060611030385\n",
      "============================================================\n",
      "\n",
      "Epoch = 109\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9798549577291829\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.080591251486452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007913269204969282\n",
      "============================================================\n",
      "\n",
      "Epoch = 110\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9724551307002989\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0791034768227874\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007912477878048784\n",
      "============================================================\n",
      "\n",
      "Epoch = 111\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9654100347170784\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0778176657171827\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791168663026098\n",
      "============================================================\n",
      "\n",
      "Epoch = 112\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9618687454990072\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.077039826430412\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910895461597954\n",
      "============================================================\n",
      "\n",
      "Epoch = 113\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.9567801161612487\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.075766289814062\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910104372051793\n",
      "============================================================\n",
      "\n",
      "Epoch = 114\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9484537378036888\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0740964545436595\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007909313361614588\n",
      "============================================================\n",
      "\n",
      "Epoch = 115\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9406083077951276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0729011264961237\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007908522430278427\n",
      "============================================================\n",
      "\n",
      "Epoch = 116\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9336342353445163\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.072113757412058\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007907731578035399\n",
      "============================================================\n",
      "\n",
      "Epoch = 117\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9252590831634577\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.071234068267447\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906940804877595\n",
      "============================================================\n",
      "\n",
      "Epoch = 118\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9151671027430699\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.070214612168661\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906150110797107\n",
      "============================================================\n",
      "\n",
      "Epoch = 119\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9042315609864089\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.069097335765977\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007905359495786028\n",
      "============================================================\n",
      "\n",
      "Epoch = 120\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8935330508321708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.068063104453774\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007904568959836449\n",
      "============================================================\n",
      "\n",
      "Epoch = 121\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8825900427774931\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.067470814602599\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007903778502940466\n",
      "============================================================\n",
      "\n",
      "Epoch = 122\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.870557181548108\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06686948749981\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902988125090172\n",
      "============================================================\n",
      "\n",
      "Epoch = 123\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8583567995715331\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0662277670358384\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902197826277664\n",
      "============================================================\n",
      "\n",
      "Epoch = 124\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.845637238594769\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065388461124627\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007901407606495036\n",
      "============================================================\n",
      "\n",
      "Epoch = 125\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8332425647981454\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.064887247595155\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007900617465734385\n",
      "============================================================\n",
      "\n",
      "Epoch = 126\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8203801713920809\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0645636543861756\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899827403987812\n",
      "============================================================\n",
      "\n",
      "Epoch = 127\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8083254511449491\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0641935484348966\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899037421247413\n",
      "============================================================\n",
      "\n",
      "Epoch = 128\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7967444796777542\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0637498191683954\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789824751750529\n",
      "============================================================\n",
      "\n",
      "Epoch = 129\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7864950031641055\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063525087692838\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007897457692753539\n",
      "============================================================\n",
      "\n",
      "Epoch = 130\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7784840447474324\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063192061377603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007896667946984263\n",
      "============================================================\n",
      "\n",
      "Epoch = 131\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7793452283738136\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063244250214603\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895878280189565\n",
      "============================================================\n",
      "\n",
      "Epoch = 132\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7935101608971802\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0628104072681066\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895088692361546\n",
      "============================================================\n",
      "\n",
      "Epoch = 133\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8324995799908689\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0629442887876004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789429918349231\n",
      "============================================================\n",
      "\n",
      "Epoch = 134\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7872916567464839\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063001465703814\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007893509753573962\n",
      "============================================================\n",
      "\n",
      "Epoch = 135\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7383819181562977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625188922229576\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007892720402598604\n",
      "============================================================\n",
      "\n",
      "Epoch = 136\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7345907144630641\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062447897244078\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891931130558345\n",
      "============================================================\n",
      "\n",
      "Epoch = 137\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7485767974736312\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062339437297695\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891141937445289\n",
      "============================================================\n",
      "\n",
      "Epoch = 138\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7397623169134242\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625524864253735\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007890352823251545\n",
      "============================================================\n",
      "\n",
      "Epoch = 139\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7125144013403435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625802070020804\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788956378796922\n",
      "============================================================\n",
      "\n",
      "Epoch = 140\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7154515785151535\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.062603497780363\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007888774831590423\n",
      "============================================================\n",
      "\n",
      "Epoch = 141\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7225099341606249\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0620954812451493\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887985954107264\n",
      "============================================================\n",
      "\n",
      "Epoch = 142\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.707918018500289\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0625049572946983\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887197155511854\n",
      "============================================================\n",
      "\n",
      "Epoch = 143\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6975683376954314\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0619689193197592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007886408435796303\n",
      "============================================================\n",
      "\n",
      "Epoch = 144\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.700227494516424\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0618935951485313\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007885619794952723\n",
      "============================================================\n",
      "\n",
      "Epoch = 145\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6993752305133722\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0618045139937036\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884831232973228\n",
      "============================================================\n",
      "\n",
      "Epoch = 146\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6913187607767922\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.061705830749499\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884042749849931\n",
      "============================================================\n",
      "\n",
      "Epoch = 147\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6866470428323337\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.061870816140458\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007883254345574946\n",
      "============================================================\n",
      "\n",
      "Epoch = 148\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6866117821393214\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.061410604245255\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007882466020140389\n",
      "============================================================\n",
      "\n",
      "Epoch = 149\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.683903761772231\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.061231991728197\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007881677773538374\n",
      "============================================================\n",
      "\n",
      "Epoch = 150\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.677677244676689\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.061231350995928\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788088960576102\n",
      "============================================================\n",
      "\n",
      "Epoch = 151\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6724219252320257\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.060662166366275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007880101516800443\n",
      "============================================================\n",
      "\n",
      "Epoch = 152\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.6689567111692338\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0598837333912017\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007879313506648764\n",
      "============================================================\n",
      "\n",
      "Epoch = 153\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6636006235287792\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.059530377625141\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007878525575298098\n",
      "============================================================\n",
      "\n",
      "Epoch = 154\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6575084377976804\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0592875546495586\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007877737722740568\n",
      "============================================================\n",
      "\n",
      "Epoch = 155\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6523432935828334\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.059779338205968\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876949948968294\n",
      "============================================================\n",
      "\n",
      "Epoch = 156\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6465764367920959\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.059398048620666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876162253973397\n",
      "============================================================\n",
      "\n",
      "Epoch = 157\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6399568946859548\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.059885275375601\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007875374637748\n",
      "============================================================\n",
      "\n",
      "Epoch = 158\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6302618420908961\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0606536913596383\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007874587100284224\n",
      "============================================================\n",
      "\n",
      "Epoch = 159\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6229267538004284\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.059944958553924\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873799641574196\n",
      "============================================================\n",
      "\n",
      "Epoch = 160\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6144280497227135\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0613238599368717\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873012261610038\n",
      "============================================================\n",
      "\n",
      "Epoch = 161\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6038049010535342\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0652324624786926\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007872224960383877\n",
      "============================================================\n",
      "\n",
      "Epoch = 162\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5935594079479358\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0671836427060235\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00787143773788784\n",
      "============================================================\n",
      "\n",
      "Epoch = 163\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.583331975916098\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065262411036507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007870650594114051\n",
      "============================================================\n",
      "\n",
      "Epoch = 164\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5740501853839195\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0675831384694594\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786986352905464\n",
      "============================================================\n",
      "\n",
      "Epoch = 165\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5612186226036473\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.071092798459219\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007869076542701735\n",
      "============================================================\n",
      "\n",
      "Epoch = 166\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5514423258863979\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0753104556164534\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007868289635047465\n",
      "============================================================\n",
      "\n",
      "Epoch = 167\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5375876920691962\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.069912045799485\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786750280608396\n",
      "============================================================\n",
      "\n",
      "Epoch = 168\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5350977851193817\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.077311501912625\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007866716055803353\n",
      "============================================================\n",
      "\n",
      "Epoch = 169\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5213915547475233\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0743135641916526\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865929384197771\n",
      "============================================================\n",
      "\n",
      "Epoch = 170\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5481714152636701\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.085717014700424\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865142791259352\n",
      "============================================================\n",
      "\n",
      "Epoch = 171\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5625060021857934\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.072575114214298\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007864356276980226\n",
      "============================================================\n",
      "\n",
      "Epoch = 172\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6576561039312678\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083930726734254\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007863569841352528\n",
      "============================================================\n",
      "\n",
      "Epoch = 173\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5554966828265294\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.086287075256192\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007862783484368393\n",
      "============================================================\n",
      "\n",
      "Epoch = 174\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4997527502821359\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0714068425460583\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861997206019955\n",
      "============================================================\n",
      "\n",
      "Epoch = 175\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4590575486546321\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0871079182009686\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861211006299353\n",
      "============================================================\n",
      "\n",
      "Epoch = 176\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4803595092421894\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0813176193723026\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007860424885198723\n",
      "============================================================\n",
      "\n",
      "Epoch = 177\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5034826774667647\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.07756997261065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007859638842710202\n",
      "============================================================\n",
      "\n",
      "Epoch = 178\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4534699701825557\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.090354456679331\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858852878825932\n",
      "============================================================\n",
      "\n",
      "Epoch = 179\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4248226354096502\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0764326773644974\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858066993538049\n",
      "============================================================\n",
      "\n",
      "Epoch = 180\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4528517674141659\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0862599968760067\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007857281186838695\n",
      "============================================================\n",
      "\n",
      "Epoch = 181\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.419976885061421\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0909910359977495\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007856495458720011\n",
      "============================================================\n",
      "\n",
      "Epoch = 182\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.42299797222817953\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0780396417660048\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00785570980917414\n",
      "============================================================\n",
      "\n",
      "Epoch = 183\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4071600324983329\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.088343483958796\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854924238193223\n",
      "============================================================\n",
      "\n",
      "Epoch = 184\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.403864901777533\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.083752486889112\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854138745769405\n",
      "============================================================\n",
      "\n",
      "Epoch = 185\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.411604546742545\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.086451951373822\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007853353331894828\n",
      "============================================================\n",
      "\n",
      "Epoch = 186\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3917540955618696\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.089121365846043\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007852567996561638\n",
      "============================================================\n",
      "\n",
      "Epoch = 187\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3921347426925864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.082458070348292\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007851782739761982\n",
      "============================================================\n",
      "\n",
      "Epoch = 188\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.39018800001079423\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0879435538171878\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850997561488006\n",
      "============================================================\n",
      "\n",
      "Epoch = 189\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3839296070338285\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.088580839558355\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850212461731856\n",
      "============================================================\n",
      "\n",
      "Epoch = 190\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3849176474722129\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.086039358056898\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007849427440485683\n",
      "============================================================\n",
      "\n",
      "Epoch = 191\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.37751592948539764\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.088210026313431\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007848642497741636\n",
      "============================================================\n",
      "\n",
      "Epoch = 192\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3727869181203696\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.086161401386894\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847857633491861\n",
      "============================================================\n",
      "\n",
      "Epoch = 193\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.37285757426069044\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.090406049104178\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847072847728512\n",
      "============================================================\n",
      "\n",
      "Epoch = 194\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.36331160028759546\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.089375059684361\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784628814044374\n",
      "============================================================\n",
      "\n",
      "Epoch = 195\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.36620518924549716\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0893935887292616\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007845503511629695\n",
      "============================================================\n",
      "\n",
      "Epoch = 196\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3560274601516858\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0922954188771916\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007844718961278533\n",
      "============================================================\n",
      "\n",
      "Epoch = 197\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3552369114592854\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0912517765355476\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843934489382405\n",
      "============================================================\n",
      "\n",
      "Epoch = 198\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.34864265392486354\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0937094537673833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843150095933466\n",
      "============================================================\n",
      "\n",
      "Epoch = 199\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.34328322645261666\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.095568303584704\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007842365780923873\n",
      "============================================================\n",
      "\n",
      "Epoch = 200\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3351582318109805\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0966470398322308\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784158154434578\n",
      "============================================================\n",
      "\n",
      "Epoch = 201\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.32792143810545965\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1040307949059085\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840797386191346\n",
      "============================================================\n",
      "\n",
      "Epoch = 202\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.31679601919983136\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1003979134997386\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840013306452728\n",
      "============================================================\n",
      "\n",
      "Epoch = 203\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3179603984368238\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.115326664239187\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007839229305122082\n",
      "============================================================\n",
      "\n",
      "Epoch = 204\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3104825668627172\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.09975550212742\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783844538219157\n",
      "============================================================\n",
      "\n",
      "Epoch = 205\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.35461646310844547\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.133422919548151\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783766153765335\n",
      "============================================================\n",
      "\n",
      "Epoch = 206\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4097050466566873\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.090997752388379\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836877771499585\n",
      "============================================================\n",
      "\n",
      "Epoch = 207\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5432707223239969\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1472330092705016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836094083722435\n",
      "============================================================\n",
      "\n",
      "Epoch = 208\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5585413003710603\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0896202436052187\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007835310474314064\n",
      "============================================================\n",
      "\n",
      "Epoch = 209\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5260436770378714\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0939882751167187\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007834526943266633\n",
      "============================================================\n",
      "\n",
      "Epoch = 210\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.30262984341422006\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.182141942635899\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007833743490572306\n",
      "============================================================\n",
      "\n",
      "Epoch = 211\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3037092787875281\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0941577956352075\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832960116223248\n",
      "============================================================\n",
      "\n",
      "Epoch = 212\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3388883216384718\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1172452137591984\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832176820211626\n",
      "============================================================\n",
      "\n",
      "Epoch = 213\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.29300026463222484\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1124427649333106\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007831393602529605\n",
      "============================================================\n",
      "\n",
      "Epoch = 214\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2920760903688303\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0930922257637277\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007830610463169352\n",
      "============================================================\n",
      "\n",
      "Epoch = 215\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.24469409594002872\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.128019798132041\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829827402123036\n",
      "============================================================\n",
      "\n",
      "Epoch = 216\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.23383978865913277\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0971563133250553\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829044419382824\n",
      "============================================================\n",
      "\n",
      "Epoch = 217\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.25255682827042564\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1000057128318184\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007828261514940886\n",
      "============================================================\n",
      "\n",
      "Epoch = 218\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2025499814240953\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.1113348161022842\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007827478688789392\n",
      "============================================================\n",
      "\n",
      "Epoch = 219\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19216785864550695\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.093751725184302\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007826695940920513\n",
      "============================================================\n",
      "\n",
      "Epoch = 220\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.197300913236911\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.10568876052168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825913271326422\n",
      "============================================================\n",
      "\n",
      "Epoch = 221\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.18264305640994916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0966807618592664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825130679999289\n",
      "============================================================\n",
      "\n",
      "Epoch = 222\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.17254314573883292\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.094076130795292\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00782434816693129\n",
      "============================================================\n",
      "\n",
      "Epoch = 223\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.14483028047409918\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0976857115906316\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007823565732114597\n",
      "============================================================\n",
      "\n",
      "Epoch = 224\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.146489283048576\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.088705067999861\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822783375541386\n",
      "============================================================\n",
      "\n",
      "Epoch = 225\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1430571554309304\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0921010927713732\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822001097203832\n",
      "============================================================\n",
      "\n",
      "Epoch = 226\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1330134650246882\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0870272275628925\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007821218897094112\n",
      "============================================================\n",
      "\n",
      "Epoch = 227\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1252223642944708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0849155740960095\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007820436775204402\n",
      "============================================================\n",
      "\n",
      "Epoch = 228\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10641067335962903\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.084768875159749\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007819654731526881\n",
      "============================================================\n",
      "\n",
      "Epoch = 229\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1041366685596139\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.082134932826629\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818872766053728\n",
      "============================================================\n",
      "\n",
      "Epoch = 230\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.09827391790459504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.079874140923841\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818090878777124\n",
      "============================================================\n",
      "\n",
      "Epoch = 231\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10062424663362446\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0792522743156554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007817309069689245\n",
      "============================================================\n",
      "\n",
      "Epoch = 232\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.09564944185735534\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0760132404194076\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007816527338782277\n",
      "============================================================\n",
      "\n",
      "Epoch = 233\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10513311156572788\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0769678822505906\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078157456860484\n",
      "============================================================\n",
      "\n",
      "Epoch = 234\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10058652380112756\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.072787495047291\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814964111479795\n",
      "============================================================\n",
      "\n",
      "Epoch = 235\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1305635158877665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.073678249136868\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814182615068646\n",
      "============================================================\n",
      "\n",
      "Epoch = 236\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12864309226806703\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0705349270451605\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781340119680714\n",
      "============================================================\n",
      "\n",
      "Epoch = 237\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1710078010619314\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.070484811644314\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007812619856687459\n",
      "============================================================\n",
      "\n",
      "Epoch = 238\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.13632054534583413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0696362647670172\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781183859470179\n",
      "============================================================\n",
      "\n",
      "Epoch = 239\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.162818844393475\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06988254000641\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781105741084232\n",
      "============================================================\n",
      "\n",
      "Epoch = 240\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.21015317541332473\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0723861278940863\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007810276305101236\n",
      "============================================================\n",
      "\n",
      "Epoch = 241\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.3092444702187894\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.068845423034253\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007809495277470726\n",
      "============================================================\n",
      "\n",
      "Epoch = 242\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.37590181787295296\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.069011807693118\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007808714327942979\n",
      "============================================================\n",
      "\n",
      "Epoch = 243\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1703284018874257\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0854925579034194\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807933456510184\n",
      "============================================================\n",
      "\n",
      "Epoch = 244\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08326080094978544\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0807417011525\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807152663164533\n",
      "============================================================\n",
      "\n",
      "Epoch = 245\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.15737403229711333\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0662350533411793\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007806371947898217\n",
      "============================================================\n",
      "\n",
      "Epoch = 246\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1072078499767878\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.086789256306373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007805591310703427\n",
      "============================================================\n",
      "\n",
      "Epoch = 247\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0712153603644423\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0675587476015824\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007804810751572357\n",
      "============================================================\n",
      "\n",
      "Epoch = 248\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.11719953876226151\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065209164112357\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078040302704972\n",
      "============================================================\n",
      "\n",
      "Epoch = 249\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08407997171586143\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0716095076158316\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00780324986747015\n",
      "============================================================\n",
      "\n",
      "Epoch = 250\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0690043432018929\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0642224417454513\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007802469542483403\n",
      "============================================================\n",
      "\n",
      "Epoch = 251\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08669662721251914\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.063684205633556\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007801689295529155\n",
      "============================================================\n",
      "\n",
      "Epoch = 252\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0615013108440319\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0671473583163773\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007800909126599601\n",
      "============================================================\n",
      "\n",
      "Epoch = 253\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06493370469125445\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0623279573307474\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078001290356869415\n",
      "============================================================\n",
      "\n",
      "Epoch = 254\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06735481102130278\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.06180483690191\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007799349022783373\n",
      "============================================================\n",
      "\n",
      "Epoch = 255\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.053026678726638916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.065187238550277\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007798569087881095\n",
      "============================================================\n",
      "\n",
      "Epoch = 256\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05404135244206793\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.060299618936027\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797789230972307\n",
      "============================================================\n",
      "\n",
      "Epoch = 257\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05603735876955371\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0586327560121838\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797009452049209\n",
      "============================================================\n",
      "\n",
      "Epoch = 258\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04736264702408492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0586093989092165\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077962297511040045\n",
      "============================================================\n",
      "\n",
      "Epoch = 259\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.046766842345441456\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.054175202995182\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007795450128128894\n",
      "============================================================\n",
      "\n",
      "Epoch = 260\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.048800816725316096\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0501600707387913\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077946705831160815\n",
      "============================================================\n",
      "\n",
      "Epoch = 261\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04272595067481115\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.045343526416458\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00779389111605777\n",
      "============================================================\n",
      "\n",
      "Epoch = 262\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04043897478664182\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.037197121509056\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007793111726946164\n",
      "============================================================\n",
      "\n",
      "Epoch = 263\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.039071465335286625\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.034613251259547\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007792332415773469\n",
      "============================================================\n",
      "\n",
      "Epoch = 264\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03597555679649077\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0298654282915276\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007791553182531892\n",
      "============================================================\n",
      "\n",
      "Epoch = 265\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03547952076778015\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0234301977076328\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007790774027213639\n",
      "============================================================\n",
      "\n",
      "Epoch = 266\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.034469854231828724\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.018724686566959\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007789994949810917\n",
      "============================================================\n",
      "\n",
      "Epoch = 267\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.033074925525871435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0143648280403452\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077892159503159366\n",
      "============================================================\n",
      "\n",
      "Epoch = 268\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.035881870103273955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0107040216885768\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077884370287209055\n",
      "============================================================\n",
      "\n",
      "Epoch = 269\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.04406951948577129\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.001308233013859\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007787658185018033\n",
      "============================================================\n",
      "\n",
      "Epoch = 270\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08536942401681413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.000053350032988\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786879419199532\n",
      "============================================================\n",
      "\n",
      "Epoch = 271\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1470175179106038\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.994059864432892\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786100731257612\n",
      "============================================================\n",
      "\n",
      "Epoch = 272\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2960037501994056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.056388079734422\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007785322121184487\n",
      "============================================================\n",
      "\n",
      "Epoch = 273\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.18329577444151504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.07383459979609\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007784543588972369\n",
      "============================================================\n",
      "\n",
      "Epoch = 274\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07967421394233144\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.111873538078915\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007783765134613472\n",
      "============================================================\n",
      "\n",
      "Epoch = 275\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04969178803712586\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0131594063826745\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007782986758100011\n",
      "============================================================\n",
      "\n",
      "Epoch = 276\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06411932412545339\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0641860688077602\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077822084594242015\n",
      "============================================================\n",
      "\n",
      "Epoch = 277\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0961052632381586\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.976309120418261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007781430238578259\n",
      "============================================================\n",
      "\n",
      "Epoch = 278\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07387949905252544\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9801190900823917\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007780652095554402\n",
      "============================================================\n",
      "\n",
      "Epoch = 279\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.060248383364748026\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9660085254286745\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779874030344846\n",
      "============================================================\n",
      "\n",
      "Epoch = 280\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06002332600330273\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9535838506925123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779096042941812\n",
      "============================================================\n",
      "\n",
      "Epoch = 281\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.054920802730777166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.945315116353802\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077783181333375175\n",
      "============================================================\n",
      "\n",
      "Epoch = 282\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0311702855998644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9288834790081963\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077775403015241835\n",
      "============================================================\n",
      "\n",
      "Epoch = 283\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03583932544657027\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.936601715426409\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077767625474940314\n",
      "============================================================\n",
      "\n",
      "Epoch = 284\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03562842961781698\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9530722614086784\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775984871239282\n",
      "============================================================\n",
      "\n",
      "Epoch = 285\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.029168700122079574\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9266231151730573\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775207272752158\n",
      "============================================================\n",
      "\n",
      "Epoch = 286\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03499707816316426\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.916790761640666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007774429752024883\n",
      "============================================================\n",
      "\n",
      "Epoch = 287\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.030868374397136113\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8989495223097592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007773652309049681\n",
      "============================================================\n",
      "\n",
      "Epoch = 288\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.059899011280617254\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.917058708634899\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772874943818776\n",
      "============================================================\n",
      "\n",
      "Epoch = 289\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.09397825364164303\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9186216698172698\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772097656324394\n",
      "============================================================\n",
      "\n",
      "Epoch = 290\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.21613699590020144\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9818195145520008\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007771320446558761\n",
      "============================================================\n",
      "\n",
      "Epoch = 291\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.2662237595642501\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8775869065258162\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007770543314514105\n",
      "============================================================\n",
      "\n",
      "Epoch = 292\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.17614450314010835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0105094370713257\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007769766260182654\n",
      "============================================================\n",
      "\n",
      "Epoch = 293\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1582920597524143\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.155302533451406\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768989283556636\n",
      "============================================================\n",
      "\n",
      "Epoch = 294\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04416969292081619\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0328554383306123\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768212384628281\n",
      "============================================================\n",
      "\n",
      "Epoch = 295\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19293784217705257\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0462297602791466\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007767435563389818\n",
      "============================================================\n",
      "\n",
      "Epoch = 296\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.218077373414367\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.931084129039149\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007766658819833479\n",
      "============================================================\n",
      "\n",
      "Epoch = 297\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06318321920737177\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.023590449504513\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765882153951496\n",
      "============================================================\n",
      "\n",
      "Epoch = 298\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12360415455395954\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.0172791220367627\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765105565736101\n",
      "============================================================\n",
      "\n",
      "Epoch = 299\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04466382107711324\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8785000315657845\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007764329055179527\n",
      "============================================================\n",
      "\n",
      "Epoch = 300\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05924232546963737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9881674779285785\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007763552622274009\n",
      "============================================================\n",
      "\n",
      "Epoch = 301\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05762933739282966\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.920213509675115\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077627762670117815\n",
      "============================================================\n",
      "\n",
      "Epoch = 302\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05241742204158205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.913277640746758\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00776199998938508\n",
      "============================================================\n",
      "\n",
      "Epoch = 303\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0689453302906952\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8646110377133456\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007761223789386142\n",
      "============================================================\n",
      "\n",
      "Epoch = 304\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0436133770394453\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8508514710562396\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007760447667007203\n",
      "============================================================\n",
      "\n",
      "Epoch = 305\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04606383008371549\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8457218336188839\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007759671622240502\n",
      "============================================================\n",
      "\n",
      "Epoch = 306\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06678649849073331\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8245876994369699\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007758895655078278\n",
      "============================================================\n",
      "\n",
      "Epoch = 307\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027560684697278025\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.8226797805080481\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775811976551277\n",
      "============================================================\n",
      "\n",
      "Epoch = 308\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05536068830061688\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8207741493829488\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077573439535362195\n",
      "============================================================\n",
      "\n",
      "Epoch = 309\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016369853327142327\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8172391556781675\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007756568219140866\n",
      "============================================================\n",
      "\n",
      "Epoch = 310\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03223712816370322\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.821898177617681\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007755792562318952\n",
      "============================================================\n",
      "\n",
      "Epoch = 311\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.020824811434995594\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.815188798900004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775501698306272\n",
      "============================================================\n",
      "\n",
      "Epoch = 312\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012800529843310444\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.815739565406893\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007754241481364414\n",
      "============================================================\n",
      "\n",
      "Epoch = 313\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013920122317719231\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.822824235030416\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007753466057216277\n",
      "============================================================\n",
      "\n",
      "Epoch = 314\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009802799109529811\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.808484977999542\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007752690710610556\n",
      "============================================================\n",
      "\n",
      "Epoch = 315\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00910446976267748\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8159412534149013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751915441539495\n",
      "============================================================\n",
      "\n",
      "Epoch = 316\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008873579075458028\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8111539494190005\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751140249995341\n",
      "============================================================\n",
      "\n",
      "Epoch = 317\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008292341395559377\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.804651481051164\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007750365135970342\n",
      "============================================================\n",
      "\n",
      "Epoch = 318\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007510904572976882\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8060888712080032\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007749590099456746\n",
      "============================================================\n",
      "\n",
      "Epoch = 319\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010880755839709016\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.8019656427050241\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077488151404468\n",
      "============================================================\n",
      "\n",
      "Epoch = 320\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0073412809407147755\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.800465809379716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007748040258932756\n",
      "============================================================\n",
      "\n",
      "Epoch = 321\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008236939803141942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7988602570808614\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007747265454906863\n",
      "============================================================\n",
      "\n",
      "Epoch = 322\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008983435600787336\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7983487045153521\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007746490728361372\n",
      "============================================================\n",
      "\n",
      "Epoch = 323\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0065027011224147195\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.797017328986532\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007745716079288536\n",
      "============================================================\n",
      "\n",
      "Epoch = 324\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00959807118308378\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7970559269308721\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744941507680608\n",
      "============================================================\n",
      "\n",
      "Epoch = 325\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011255447548895486\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7953654198841902\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744167013529839\n",
      "============================================================\n",
      "\n",
      "Epoch = 326\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.022462257804892593\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.795491519973874\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007743392596828487\n",
      "============================================================\n",
      "\n",
      "Epoch = 327\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04370284432563628\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7954389624153975\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007742618257568804\n",
      "============================================================\n",
      "\n",
      "Epoch = 328\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.09396240992589112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.796472763456507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741843995743047\n",
      "============================================================\n",
      "\n",
      "Epoch = 329\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.17554514731758636\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7931844397679324\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741069811343473\n",
      "============================================================\n",
      "\n",
      "Epoch = 330\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19434775819423356\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7930127871617534\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007740295704362339\n",
      "============================================================\n",
      "\n",
      "Epoch = 331\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.153266715308289\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7969864477318258\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007739521674791903\n",
      "============================================================\n",
      "\n",
      "Epoch = 332\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04170515924690374\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7950621207659978\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007738747722624424\n",
      "============================================================\n",
      "\n",
      "Epoch = 333\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02224672902449712\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7977152915104762\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007737973847852161\n",
      "============================================================\n",
      "\n",
      "Epoch = 334\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05159076241186869\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7960908025643918\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077372000504673764\n",
      "============================================================\n",
      "\n",
      "Epoch = 335\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05299426355436205\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7951471619272716\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00773642633046233\n",
      "============================================================\n",
      "\n",
      "Epoch = 336\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.030490786394853208\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7908283876374054\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007735652687829283\n",
      "============================================================\n",
      "\n",
      "Epoch = 337\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0198108999401652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7889209656438116\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077348791225605\n",
      "============================================================\n",
      "\n",
      "Epoch = 338\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01606760887033665\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.796482913723777\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007734105634648244\n",
      "============================================================\n",
      "\n",
      "Epoch = 339\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012072864437906729\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7997109008974848\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007733332224084779\n",
      "============================================================\n",
      "\n",
      "Epoch = 340\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01408487913102888\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7862931779829467\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077325588908623705\n",
      "============================================================\n",
      "\n",
      "Epoch = 341\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01391124434725745\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7861355491415252\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731785634973285\n",
      "============================================================\n",
      "\n",
      "Epoch = 342\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009107311442120259\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7910866699366585\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731012456409787\n",
      "============================================================\n",
      "\n",
      "Epoch = 343\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005131684968809219\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7855369988689958\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007730239355164146\n",
      "============================================================\n",
      "\n",
      "Epoch = 344\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0065088799655302915\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7803464507102416\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077294663312286295\n",
      "============================================================\n",
      "\n",
      "Epoch = 345\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00915397423358031\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.776855078070858\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077286933845955065\n",
      "============================================================\n",
      "\n",
      "Epoch = 346\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006598548896464934\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.7749305528103339\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727920515257047\n",
      "============================================================\n",
      "\n",
      "Epoch = 347\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005237096638759022\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7739191749049377\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727147723205522\n",
      "============================================================\n",
      "\n",
      "Epoch = 348\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004793775579889863\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7698642474277266\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007726375008433201\n",
      "============================================================\n",
      "\n",
      "Epoch = 349\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00438994663621804\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7637742006277342\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077256023709323576\n",
      "============================================================\n",
      "\n",
      "Epoch = 350\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003028791430537881\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.757331580404668\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724829810695264\n",
      "============================================================\n",
      "\n",
      "Epoch = 351\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002733652592044012\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7507935726500163\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724057327714195\n",
      "============================================================\n",
      "\n",
      "Epoch = 352\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0031614400306335068\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7433595112764386\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007723284921981423\n",
      "============================================================\n",
      "\n",
      "Epoch = 353\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002601519221212022\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.73339529275535\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007722512593489225\n",
      "============================================================\n",
      "\n",
      "Epoch = 354\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002547227389280169\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7228615308141586\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007721740342229876\n",
      "============================================================\n",
      "\n",
      "Epoch = 355\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018799472471604617\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7123454019304245\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720968168195653\n",
      "============================================================\n",
      "\n",
      "Epoch = 356\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002032061706357286\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7040758167828134\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720196071378833\n",
      "============================================================\n",
      "\n",
      "Epoch = 357\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0020000690938554652\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7083835128275622\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007719424051771695\n",
      "============================================================\n",
      "\n",
      "Epoch = 358\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006243448557759961\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7800531901891987\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007718652109366518\n",
      "============================================================\n",
      "\n",
      "Epoch = 359\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.014274371994660416\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7814889238667895\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717880244155581\n",
      "============================================================\n",
      "\n",
      "Epoch = 360\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0258799153098993\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.9096262201312526\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717108456131165\n",
      "============================================================\n",
      "\n",
      "Epoch = 361\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015642268969934068\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7207495674498823\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007716336745285552\n",
      "============================================================\n",
      "\n",
      "Epoch = 362\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016456106969832504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.69177511419432\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007715565111611023\n",
      "============================================================\n",
      "\n",
      "Epoch = 363\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05489474268030524\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6990200564137203\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714793555099862\n",
      "============================================================\n",
      "\n",
      "Epoch = 364\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03881716302697283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6966225970510085\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714022075744352\n",
      "============================================================\n",
      "\n",
      "Epoch = 365\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.025381069729724884\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.713586152885714\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007713250673536777\n",
      "============================================================\n",
      "\n",
      "Epoch = 366\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027832864444268718\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7001833256969965\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007712479348469424\n",
      "============================================================\n",
      "\n",
      "Epoch = 367\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010076497427958069\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6710478074953523\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007711708100534577\n",
      "============================================================\n",
      "\n",
      "Epoch = 368\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009664604693685698\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6388904273495437\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007710936929724523\n",
      "============================================================\n",
      "\n",
      "Epoch = 369\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01642649592668708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6343201218170564\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00771016583603155\n",
      "============================================================\n",
      "\n",
      "Epoch = 370\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013299007717093478\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6335092481716327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077093948194479475\n",
      "============================================================\n",
      "\n",
      "Epoch = 371\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006551906358495093\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6497024438083623\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007708623879966002\n",
      "============================================================\n",
      "\n",
      "Epoch = 372\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007502684246346874\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6663340796493662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707853017578006\n",
      "============================================================\n",
      "\n",
      "Epoch = 373\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03759923530208258\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7794882263081913\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707082232276248\n",
      "============================================================\n",
      "\n",
      "Epoch = 374\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.060507080467805625\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6915018554664278\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007706311524053021\n",
      "============================================================\n",
      "\n",
      "Epoch = 375\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0859989724758146\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7263788206900514\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007705540892900616\n",
      "============================================================\n",
      "\n",
      "Epoch = 376\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.19682285238596464\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6902373075951231\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007704770338811326\n",
      "============================================================\n",
      "\n",
      "Epoch = 377\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.4741903561461288\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7708409713033288\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703999861777445\n",
      "============================================================\n",
      "\n",
      "Epoch = 378\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.6267535508991641\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5957430502125365\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703229461791267\n",
      "============================================================\n",
      "\n",
      "Epoch = 379\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.11106802342435479\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6481529945652662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007702459138845088\n",
      "============================================================\n",
      "\n",
      "Epoch = 380\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1748735904570976\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.814494928332188\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007701688892931204\n",
      "============================================================\n",
      "\n",
      "Epoch = 381\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.18069438657716833\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6177121738223545\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700918724041911\n",
      "============================================================\n",
      "\n",
      "Epoch = 382\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0327277098882896\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6996101602595857\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700148632169506\n",
      "============================================================\n",
      "\n",
      "Epoch = 383\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.10505346565582907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6517428897092372\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007699378617306289\n",
      "============================================================\n",
      "\n",
      "Epoch = 384\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05635930202924521\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.591100257355006\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007698608679444559\n",
      "============================================================\n",
      "\n",
      "Epoch = 385\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.047449993208900976\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.59345828918384\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007697838818576615\n",
      "============================================================\n",
      "\n",
      "Epoch = 386\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.060391169622538356\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.60063199610854\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076970690346947574\n",
      "============================================================\n",
      "\n",
      "Epoch = 387\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.018514259255061945\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5274281697090524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007696299327791288\n",
      "============================================================\n",
      "\n",
      "Epoch = 388\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05875279151184146\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.540163619439879\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007695529697858509\n",
      "============================================================\n",
      "\n",
      "Epoch = 389\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.020335956750803824\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5435942789059978\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076947601448887236\n",
      "============================================================\n",
      "\n",
      "Epoch = 390\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02697006453012353\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5170474300751788\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007693990668874235\n",
      "============================================================\n",
      "\n",
      "Epoch = 391\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027126772655558885\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5123929836779675\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076932212698073476\n",
      "============================================================\n",
      "\n",
      "Epoch = 392\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012912628978827435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5215889936634437\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007692451947680367\n",
      "============================================================\n",
      "\n",
      "Epoch = 393\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.017067757921235945\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5278393583277003\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007691682702485599\n",
      "============================================================\n",
      "\n",
      "Epoch = 394\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009519044668310887\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5728196700906945\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076909135342153505\n",
      "============================================================\n",
      "\n",
      "Epoch = 395\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02219222007825738\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.575280280472574\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007690144442861929\n",
      "============================================================\n",
      "\n",
      "Epoch = 396\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01917407379237878\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.660457946029957\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076893754284176425\n",
      "============================================================\n",
      "\n",
      "Epoch = 397\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008896490740667156\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5975515158970464\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007688606490874801\n",
      "============================================================\n",
      "\n",
      "Epoch = 398\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0143353401817653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.584635016369566\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687837630225713\n",
      "============================================================\n",
      "\n",
      "Epoch = 399\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011499927579857232\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5348844006430187\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687068846462691\n",
      "============================================================\n",
      "\n",
      "Epoch = 400\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011378841741887755\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5295990764607899\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076863001395780445\n",
      "============================================================\n",
      "\n",
      "Epoch = 401\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.017997728021781137\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4953250606133202\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007685531509564087\n",
      "============================================================\n",
      "\n",
      "Epoch = 402\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005241314189510936\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4868998402721805\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076847629564131305\n",
      "============================================================\n",
      "\n",
      "Epoch = 403\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.019530652156730766\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4844943213231232\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00768399448011749\n",
      "============================================================\n",
      "\n",
      "Epoch = 404\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010497100162814367\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4840578219446712\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007683226080669478\n",
      "============================================================\n",
      "\n",
      "Epoch = 405\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004394443112390765\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4825985911350947\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007682457758061411\n",
      "============================================================\n",
      "\n",
      "Epoch = 406\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010954637822925805\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4883407554538108\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007681689512285605\n",
      "============================================================\n",
      "\n",
      "Epoch = 407\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004887561940782402\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4991554097783606\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680921343334376\n",
      "============================================================\n",
      "\n",
      "Epoch = 408\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006650646809304581\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5047445630907559\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680153251200043\n",
      "============================================================\n",
      "\n",
      "Epoch = 409\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010043773412319885\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5237593539708985\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007679385235874923\n",
      "============================================================\n",
      "\n",
      "Epoch = 410\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004933818199564544\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5383580668723853\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007678617297351336\n",
      "============================================================\n",
      "\n",
      "Epoch = 411\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004704700874211112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5893910911356504\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677849435621601\n",
      "============================================================\n",
      "\n",
      "Epoch = 412\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0036755788272261444\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5238525560516292\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677081650678039\n",
      "============================================================\n",
      "\n",
      "Epoch = 413\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003753004565353282\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4991986994055395\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007676313942512971\n",
      "============================================================\n",
      "\n",
      "Epoch = 414\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007555698156869864\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.479603941495249\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007675546311118719\n",
      "============================================================\n",
      "\n",
      "Epoch = 415\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006720803095771843\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4760942314267782\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007674778756487608\n",
      "============================================================\n",
      "\n",
      "Epoch = 416\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006920284548238166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.473900680599034\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767401127861196\n",
      "============================================================\n",
      "\n",
      "Epoch = 417\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0054405043664599246\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4757484181688956\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007673243877484098\n",
      "============================================================\n",
      "\n",
      "Epoch = 418\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004195547014655453\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4819965924900045\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767247655309635\n",
      "============================================================\n",
      "\n",
      "Epoch = 419\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005072238460083989\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.483330107296307\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767170930544104\n",
      "============================================================\n",
      "\n",
      "Epoch = 420\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004423594723358763\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4903870597027347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076709421345104965\n",
      "============================================================\n",
      "\n",
      "Epoch = 421\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002548518043086916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.49545680991301\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007670175040297046\n",
      "============================================================\n",
      "\n",
      "Epoch = 422\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003169987135734806\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5105972902359013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007669408022793016\n",
      "============================================================\n",
      "\n",
      "Epoch = 423\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0023985126526611935\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5026723643231379\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007668641081990737\n",
      "============================================================\n",
      "\n",
      "Epoch = 424\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002540781793428953\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5038812364206338\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667874217882537\n",
      "============================================================\n",
      "\n",
      "Epoch = 425\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0022386166642559997\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4901658813529577\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667107430460749\n",
      "============================================================\n",
      "\n",
      "Epoch = 426\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018387946396296382\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.483542921927722\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007666340719717703\n",
      "============================================================\n",
      "\n",
      "Epoch = 427\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017890189167531893\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4755782012097256\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076655740856457315\n",
      "============================================================\n",
      "\n",
      "Epoch = 428\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00201128118370532\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.47103521912091\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664807528237167\n",
      "============================================================\n",
      "\n",
      "Epoch = 429\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002266053609414193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4669734732698223\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664041047484343\n",
      "============================================================\n",
      "\n",
      "Epoch = 430\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0021005247601488092\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.464753061581365\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007663274643379595\n",
      "============================================================\n",
      "\n",
      "Epoch = 431\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0021029269953992307\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4636133367005144\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007662508315915257\n",
      "============================================================\n",
      "\n",
      "Epoch = 432\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016104052958940793\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4632671457422592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007661742065083665\n",
      "============================================================\n",
      "\n",
      "Epoch = 433\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001546654003513386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4630398450396538\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660975890877157\n",
      "============================================================\n",
      "\n",
      "Epoch = 434\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013984982895950979\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4634129166923595\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660209793288069\n",
      "============================================================\n",
      "\n",
      "Epoch = 435\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012200868325996802\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4643339249281624\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076594437723087406\n",
      "============================================================\n",
      "\n",
      "Epoch = 436\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012106834589274166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4649656746551414\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00765867782793151\n",
      "============================================================\n",
      "\n",
      "Epoch = 437\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015237532856157863\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.465729654263374\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076579119601487165\n",
      "============================================================\n",
      "\n",
      "Epoch = 438\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001341535337788976\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.466308097573704\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007657146168952702\n",
      "============================================================\n",
      "\n",
      "Epoch = 439\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001455374501892339\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.468213517277206\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007656380454335807\n",
      "============================================================\n",
      "\n",
      "Epoch = 440\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013896056600144983\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.469726270318816\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007655614816290374\n",
      "============================================================\n",
      "\n",
      "Epoch = 441\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015560658344591209\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4732813644339935\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076548492548087444\n",
      "============================================================\n",
      "\n",
      "Epoch = 442\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015629198892255542\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4744129104012391\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007654083769883264\n",
      "============================================================\n",
      "\n",
      "Epoch = 443\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001647395234585364\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4797481887072261\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076533183615062755\n",
      "============================================================\n",
      "\n",
      "Epoch = 444\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014353001096781386\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.481333434529611\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007652553029670125\n",
      "============================================================\n",
      "\n",
      "Epoch = 445\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015377088091877871\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.489232144005257\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651787774367158\n",
      "============================================================\n",
      "\n",
      "Epoch = 446\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014991634566719448\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4863087112804987\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651022595589722\n",
      "============================================================\n",
      "\n",
      "Epoch = 447\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015896544690617007\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4899714428720685\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007650257493330163\n",
      "============================================================\n",
      "\n",
      "Epoch = 448\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001297087920049407\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4809357167068016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00764949246758083\n",
      "============================================================\n",
      "\n",
      "Epoch = 449\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011502031010703316\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4779756835185078\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007648727518334072\n",
      "============================================================\n",
      "\n",
      "Epoch = 450\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010294001867807775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4682579652328347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647962645582239\n",
      "============================================================\n",
      "\n",
      "Epoch = 451\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009974580761101975\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4629835436348206\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647197849317681\n",
      "============================================================\n",
      "\n",
      "Epoch = 452\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001139001682494735\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4560844235188366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007646433129532749\n",
      "============================================================\n",
      "\n",
      "Epoch = 453\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001247075920468867\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4516305070149598\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007645668486219796\n",
      "============================================================\n",
      "\n",
      "Epoch = 454\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014103737406908085\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4473087244225395\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644903919371174\n",
      "============================================================\n",
      "\n",
      "Epoch = 455\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013316161239099887\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4439986200299253\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644139428979236\n",
      "============================================================\n",
      "\n",
      "Epoch = 456\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012210181971617443\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.440548133648511\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076433750150363385\n",
      "============================================================\n",
      "\n",
      "Epoch = 457\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010241544670998798\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4373531093482477\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007642610677534835\n",
      "============================================================\n",
      "\n",
      "Epoch = 458\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009412234273851364\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.433737883451874\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641846416467081\n",
      "============================================================\n",
      "\n",
      "Epoch = 459\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009175489529247504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4300266910499242\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641082231825434\n",
      "============================================================\n",
      "\n",
      "Epoch = 460\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009694797810785254\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.4259406156212604\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007640318123602252\n",
      "============================================================\n",
      "\n",
      "Epoch = 461\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010748365327987988\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4219258660204819\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076395540917898914\n",
      "============================================================\n",
      "\n",
      "Epoch = 462\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00123146462397234\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4181503707200662\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638790136380713\n",
      "============================================================\n",
      "\n",
      "Epoch = 463\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001470857007703787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4208819563960664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638026257367075\n",
      "============================================================\n",
      "\n",
      "Epoch = 464\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00262236274339104\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4429439073694803\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007637262454741338\n",
      "============================================================\n",
      "\n",
      "Epoch = 465\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0059111597818973845\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.539410763097458\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007636498728495864\n",
      "============================================================\n",
      "\n",
      "Epoch = 466\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0183898778207872\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5667294939556033\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007635735078623015\n",
      "============================================================\n",
      "\n",
      "Epoch = 467\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02650162616177354\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5822870216396812\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634971505115153\n",
      "============================================================\n",
      "\n",
      "Epoch = 468\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011834088944351586\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.6051270584863968\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634208007964641\n",
      "============================================================\n",
      "\n",
      "Epoch = 469\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011413639835705824\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.632543605853927\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007633444587163845\n",
      "============================================================\n",
      "\n",
      "Epoch = 470\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010963086274090856\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5375244404545225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007632681242705129\n",
      "============================================================\n",
      "\n",
      "Epoch = 471\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.015219488472035065\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5584424647233677\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631917974580859\n",
      "============================================================\n",
      "\n",
      "Epoch = 472\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04118296601486576\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5558728892082103\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631154782783401\n",
      "============================================================\n",
      "\n",
      "Epoch = 473\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03942238534134991\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5092043972879277\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007630391667305123\n",
      "============================================================\n",
      "\n",
      "Epoch = 474\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0633430588102071\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4887944008985208\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007629628628138392\n",
      "============================================================\n",
      "\n",
      "Epoch = 475\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08776430809270112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4404573985823297\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007628865665275579\n",
      "============================================================\n",
      "\n",
      "Epoch = 476\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08223999591052214\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.421684928609117\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076281027787090516\n",
      "============================================================\n",
      "\n",
      "Epoch = 477\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.033503029506737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4177887554825057\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007627339968431181\n",
      "============================================================\n",
      "\n",
      "Epoch = 478\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03212313701605763\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.395813936899957\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007626577234434338\n",
      "============================================================\n",
      "\n",
      "Epoch = 479\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.042116927735113524\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3934868323395575\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625814576710895\n",
      "============================================================\n",
      "\n",
      "Epoch = 480\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016434818374894286\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.417245014318456\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625051995253224\n",
      "============================================================\n",
      "\n",
      "Epoch = 481\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007590384365305564\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4133235857009927\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007624289490053699\n",
      "============================================================\n",
      "\n",
      "Epoch = 482\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027151842828819692\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4012776852166793\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007623527061104694\n",
      "============================================================\n",
      "\n",
      "Epoch = 483\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.029314928134492373\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4271125001159282\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076227647083985835\n",
      "============================================================\n",
      "\n",
      "Epoch = 484\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016647826101256327\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5147227084030117\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007622002431927744\n",
      "============================================================\n",
      "\n",
      "Epoch = 485\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004887404942025448\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5160112716048442\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007621240231684551\n",
      "============================================================\n",
      "\n",
      "Epoch = 486\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0037832092170638812\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4587903188645033\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007620478107661383\n",
      "============================================================\n",
      "\n",
      "Epoch = 487\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012306391001160035\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4169798895862877\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007619716059850617\n",
      "============================================================\n",
      "\n",
      "Epoch = 488\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.029707645600425353\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4849162711794492\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618954088244632\n",
      "============================================================\n",
      "\n",
      "Epoch = 489\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02250265651859335\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3733603627196074\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618192192835807\n",
      "============================================================\n",
      "\n",
      "Epoch = 490\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010198054020007324\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3863117325026841\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007617430373616524\n",
      "============================================================\n",
      "\n",
      "Epoch = 491\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0063840697642913976\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3510648491416484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007616668630579162\n",
      "============================================================\n",
      "\n",
      "Epoch = 492\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013787275647150491\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.389509359568227\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007615906963716104\n",
      "============================================================\n",
      "\n",
      "Epoch = 493\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011460766378908924\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3682337992188731\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076151453730197325\n",
      "============================================================\n",
      "\n",
      "Epoch = 494\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012457306861070987\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4591762625745892\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007614383858482431\n",
      "============================================================\n",
      "\n",
      "Epoch = 495\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03099606505412872\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.7027844325532355\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007613622420096583\n",
      "============================================================\n",
      "\n",
      "Epoch = 496\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04816349406097048\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4966267999526826\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612861057854573\n",
      "============================================================\n",
      "\n",
      "Epoch = 497\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.027831497849757095\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5139994787179192\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612099771748788\n",
      "============================================================\n",
      "\n",
      "Epoch = 498\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04097197608740669\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 1.613765574562677\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007611338561771613\n",
      "============================================================\n",
      "\n",
      "Epoch = 499\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.06512263261065937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4473981499120159\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007610577427915436\n",
      "============================================================\n",
      "\n",
      "Epoch = 500\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07294843851653697\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.4171523713771357\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007609816370172644\n"
     ]
    }
   ],
   "source": [
    "# vanilla PINN: initialize optimizer and scheduler\n",
    "nn_vanilla = DNN(layers=[1, 128, 128, 128, 1])\n",
    "optim = torch.optim.Adam(\n",
    "    nn_vanilla.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(inputs, outputs, nn_vanilla, optim, scheduler, 2**10, 500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0478710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Epoch = 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 2.01496536867803\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 2.007672459676306\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079992\n",
      "============================================================\n",
      "\n",
      "Epoch = 2\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.5651822142840166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.5189184823799302\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007998400079999999\n",
      "============================================================\n",
      "\n",
      "Epoch = 3\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.3839973495505409\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.412931068035669\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007997600239991999\n",
      "============================================================\n",
      "\n",
      "Epoch = 4\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.191544132139962\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.3843625235935724\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996800479968\n",
      "============================================================\n",
      "\n",
      "Epoch = 5\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 1.0318577654147196\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.2742980794371044\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007996000799920003\n",
      "============================================================\n",
      "\n",
      "Epoch = 6\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.9413896792821017\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 1.1169222705729451\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007995201199840011\n",
      "============================================================\n",
      "\n",
      "Epoch = 7\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.8689036937803079\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.9859600107786033\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007994401679720027\n",
      "============================================================\n",
      "\n",
      "Epoch = 8\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7819539723283218\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.8371756045128524\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007993602239552054\n",
      "============================================================\n",
      "\n",
      "Epoch = 9\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.7017703546724786\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.7110636790564768\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992802879328098\n",
      "============================================================\n",
      "\n",
      "Epoch = 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5632784079144468\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.5855982673329444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007992003599040166\n",
      "============================================================\n",
      "\n",
      "Epoch = 11\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.45429990159258254\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.4138388534493715\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007991204398680262\n",
      "============================================================\n",
      "\n",
      "Epoch = 12\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.37311668476459336\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2569238675258979\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007990405278240395\n",
      "============================================================\n",
      "\n",
      "Epoch = 13\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.245143735069775\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.16877481550795964\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007989606237712572\n",
      "============================================================\n",
      "\n",
      "Epoch = 14\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.21209800599423814\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2484907539083048\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079888072770888\n",
      "============================================================\n",
      "\n",
      "Epoch = 15\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.32401230893868993\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.48168764468018205\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007988008396361091\n",
      "============================================================\n",
      "\n",
      "Epoch = 16\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.5221099492077719\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.2647621346306507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007987209595521455\n",
      "============================================================\n",
      "\n",
      "Epoch = 17\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.31419631269716397\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.29713482430127974\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007986410874561903\n",
      "============================================================\n",
      "\n",
      "Epoch = 18\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.14722054905987136\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.11783821199675068\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007985612233474448\n",
      "============================================================\n",
      "\n",
      "Epoch = 19\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.20242894959248423\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.18428593849503508\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079848136722511\n",
      "============================================================\n",
      "\n",
      "Epoch = 20\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1957256544371984\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.13064896947567423\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007984015190883875\n",
      "============================================================\n",
      "\n",
      "Epoch = 21\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.12779521580696815\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.1150765267744655\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007983216789364787\n",
      "============================================================\n",
      "\n",
      "Epoch = 22\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.13451917890251472\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.11919253425263597\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00798241846768585\n",
      "============================================================\n",
      "\n",
      "Epoch = 23\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.1293558231525105\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.10012181370829087\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007981620225839082\n",
      "============================================================\n",
      "\n",
      "Epoch = 24\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08170103604229538\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.06714119128255068\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980822063816497\n",
      "============================================================\n",
      "\n",
      "Epoch = 25\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.07887452813843737\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.05459200273095849\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007980023981610115\n",
      "============================================================\n",
      "\n",
      "Epoch = 26\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.08199413950201606\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.046384648306194674\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007979225979211954\n",
      "============================================================\n",
      "\n",
      "Epoch = 27\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.05055457817297907\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.04543788795660308\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007978428056614032\n",
      "============================================================\n",
      "\n",
      "Epoch = 28\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0437016119983901\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.04608831093014725\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007977630213808371\n",
      "============================================================\n",
      "\n",
      "Epoch = 29\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03938798451957868\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.039383119687916406\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797683245078699\n",
      "============================================================\n",
      "\n",
      "Epoch = 30\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.03258096349994703\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.03370259816407554\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007976034767541912\n",
      "============================================================\n",
      "\n",
      "Epoch = 31\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.035146800547942364\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02715903667675944\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007975237164065159\n",
      "============================================================\n",
      "\n",
      "Epoch = 32\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.030081157879279632\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.026531162993897225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007974439640348753\n",
      "============================================================\n",
      "\n",
      "Epoch = 33\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.023139782741700213\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.023795807994822317\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007973642196384719\n",
      "============================================================\n",
      "\n",
      "Epoch = 34\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.022725686854374583\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.022770500555638677\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00797284483216508\n",
      "============================================================\n",
      "\n",
      "Epoch = 35\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0215643331699246\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02057469961323288\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007972047547681863\n",
      "============================================================\n",
      "\n",
      "Epoch = 36\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01805721308919666\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01760397858253813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007971250342927096\n",
      "============================================================\n",
      "\n",
      "Epoch = 37\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01823713520306456\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.016849632419660726\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007970453217892803\n",
      "============================================================\n",
      "\n",
      "Epoch = 38\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016326425084915937\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.015436556613944481\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007969656172571013\n",
      "============================================================\n",
      "\n",
      "Epoch = 39\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013494397420094045\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.015523627152771691\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968859206953756\n",
      "============================================================\n",
      "\n",
      "Epoch = 40\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.013270908593818104\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014142146244794667\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007968062321033061\n",
      "============================================================\n",
      "\n",
      "Epoch = 41\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01244356346802485\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.012652211167880699\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007967265514800958\n",
      "============================================================\n",
      "\n",
      "Epoch = 42\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01185239901436724\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.012153190549631952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007966468788249479\n",
      "============================================================\n",
      "\n",
      "Epoch = 43\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011144122006083237\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.011221507458737718\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007965672141370653\n",
      "============================================================\n",
      "\n",
      "Epoch = 44\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010297896525501404\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0108274106915484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007964875574156515\n",
      "============================================================\n",
      "\n",
      "Epoch = 45\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009427967123294209\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.010647679185021004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079640790865991\n",
      "============================================================\n",
      "\n",
      "Epoch = 46\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00903954949316527\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009778978037160239\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007963282678690441\n",
      "============================================================\n",
      "\n",
      "Epoch = 47\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008745287706448304\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009160181483131986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007962486350422572\n",
      "============================================================\n",
      "\n",
      "Epoch = 48\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008646743404071839\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008760077670235164\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00796169010178753\n",
      "============================================================\n",
      "\n",
      "Epoch = 49\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008043825175729725\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008497835942090817\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960893932777352\n",
      "============================================================\n",
      "\n",
      "Epoch = 50\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0075000649633951595\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.008173103121517592\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007960097843384074\n",
      "============================================================\n",
      "\n",
      "Epoch = 51\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007230495545331627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007706693230113909\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007959301833599735\n",
      "============================================================\n",
      "\n",
      "Epoch = 52\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0069031048151259496\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007321604253259016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007958505903416374\n",
      "============================================================\n",
      "\n",
      "Epoch = 53\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0067261636780814585\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.007050317582235673\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007957710052826033\n",
      "============================================================\n",
      "\n",
      "Epoch = 54\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006400233761504354\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0067682785608918754\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007956914281820751\n",
      "============================================================\n",
      "\n",
      "Epoch = 55\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006137380034092419\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0065528412498065585\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00795611859039257\n",
      "============================================================\n",
      "\n",
      "Epoch = 56\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005901249522276613\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00625194800017263\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007955322978533531\n",
      "============================================================\n",
      "\n",
      "Epoch = 57\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005690048998936537\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006022692095806519\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007954527446235678\n",
      "============================================================\n",
      "\n",
      "Epoch = 58\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005503832930396966\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005797457324757139\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007953731993491055\n",
      "============================================================\n",
      "\n",
      "Epoch = 59\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005271298910604726\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0056291214876275026\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952936620291706\n",
      "============================================================\n",
      "\n",
      "Epoch = 60\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005071692176827063\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005429145249572927\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007952141326629678\n",
      "============================================================\n",
      "\n",
      "Epoch = 61\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004917074036027242\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005201298880845152\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007951346112497015\n",
      "============================================================\n",
      "\n",
      "Epoch = 62\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004810301106207141\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.005009794695280842\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007950550977885766\n",
      "============================================================\n",
      "\n",
      "Epoch = 63\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004622283356079653\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004869667970290518\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007949755922787977\n",
      "============================================================\n",
      "\n",
      "Epoch = 64\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004448975406832829\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004737413954475059\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948960947195698\n",
      "============================================================\n",
      "\n",
      "Epoch = 65\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004310538366825825\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004557242122412298\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007948166051100979\n",
      "============================================================\n",
      "\n",
      "Epoch = 66\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004193300147711358\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00440397589499423\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007947371234495869\n",
      "============================================================\n",
      "\n",
      "Epoch = 67\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004065399936908422\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004278057151429532\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00794657649737242\n",
      "============================================================\n",
      "\n",
      "Epoch = 68\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003914570803556025\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004167990603578607\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007945781839722683\n",
      "============================================================\n",
      "\n",
      "Epoch = 69\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003792960033544335\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004035044158397268\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944987261538711\n",
      "============================================================\n",
      "\n",
      "Epoch = 70\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0036930083961286856\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0039056035828868275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007944192762812557\n",
      "============================================================\n",
      "\n",
      "Epoch = 71\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003586731835006235\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0037927702586321795\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007943398343536277\n",
      "============================================================\n",
      "\n",
      "Epoch = 72\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0034719810144423074\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0036942399174121027\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007942604003701923\n",
      "============================================================\n",
      "\n",
      "Epoch = 73\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0033677075254482896\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0035833972706351257\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941809743301553\n",
      "============================================================\n",
      "\n",
      "Epoch = 74\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0032801935129638943\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003473259036550868\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007941015562327224\n",
      "============================================================\n",
      "\n",
      "Epoch = 75\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0031932852840839323\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003378748621454343\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007940221460770992\n",
      "============================================================\n",
      "\n",
      "Epoch = 76\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003096627157070111\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0032914378557387307\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007939427438624915\n",
      "============================================================\n",
      "\n",
      "Epoch = 77\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0030107220205281716\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0031982760375404633\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007938633495881052\n",
      "============================================================\n",
      "\n",
      "Epoch = 78\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002930706372548361\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0031096601878022783\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007937839632531463\n",
      "============================================================\n",
      "\n",
      "Epoch = 79\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0028521363032200896\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0030290930896497373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793704584856821\n",
      "============================================================\n",
      "\n",
      "Epoch = 80\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0027722152910914406\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002951513394928786\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007936252143983354\n",
      "============================================================\n",
      "\n",
      "Epoch = 81\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0026976321809370077\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0028739688489515794\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007935458518768956\n",
      "============================================================\n",
      "\n",
      "Epoch = 82\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0026287636295425952\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002797549164814291\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00793466497291708\n",
      "============================================================\n",
      "\n",
      "Epoch = 83\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0025619704431686643\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0027254931811025824\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933871506419788\n",
      "============================================================\n",
      "\n",
      "Epoch = 84\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0024949014745321504\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0026574508092456033\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007933078119269146\n",
      "============================================================\n",
      "\n",
      "Epoch = 85\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0024307589437998637\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0025894430301209065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007932284811457219\n",
      "============================================================\n",
      "\n",
      "Epoch = 86\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0023718450514444945\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0025233228651358867\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007931491582976073\n",
      "============================================================\n",
      "\n",
      "Epoch = 87\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0023132087870711064\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002461708858645742\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007930698433817775\n",
      "============================================================\n",
      "\n",
      "Epoch = 88\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0022548292298192277\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002402027319222375\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929905363974393\n",
      "============================================================\n",
      "\n",
      "Epoch = 89\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0021997405115422985\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002343469774666016\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007929112373437996\n",
      "============================================================\n",
      "\n",
      "Epoch = 90\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002146562020529493\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022872588196783633\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007928319462200652\n",
      "============================================================\n",
      "\n",
      "Epoch = 91\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0020945906207802344\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002233487414702338\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007927526630254433\n",
      "============================================================\n",
      "\n",
      "Epoch = 92\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002043844977614495\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0021810282317665094\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007926733877591408\n",
      "============================================================\n",
      "\n",
      "Epoch = 93\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0019962003117984265\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0021291180915226624\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792594120420365\n",
      "============================================================\n",
      "\n",
      "Epoch = 94\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0019501040439379993\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0020793023800224544\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007925148610083229\n",
      "============================================================\n",
      "\n",
      "Epoch = 95\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001904820883430791\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002031934618439757\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007924356095222221\n",
      "============================================================\n",
      "\n",
      "Epoch = 96\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001860726727323436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0019848465242651232\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0079235636596127\n",
      "============================================================\n",
      "\n",
      "Epoch = 97\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018195216335370893\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0019395173808553843\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007922771303246739\n",
      "============================================================\n",
      "\n",
      "Epoch = 98\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017776727689712058\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0018965656820598541\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921979026116414\n",
      "============================================================\n",
      "\n",
      "Epoch = 99\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017378735947157413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001854018301909896\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007921186828213802\n",
      "============================================================\n",
      "\n",
      "Epoch = 100\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016992479089671427\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0018128535064247343\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00792039470953098\n",
      "============================================================\n",
      "\n",
      "Epoch = 101\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016621083126231193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00177324804161251\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007919602670060026\n",
      "============================================================\n",
      "\n",
      "Epoch = 102\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016249485449232974\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0017347175615771433\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791881070979302\n",
      "============================================================\n",
      "\n",
      "Epoch = 103\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015903472081247657\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001697045435633649\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791801882872204\n",
      "============================================================\n",
      "\n",
      "Epoch = 104\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015554652662338837\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016605983550960417\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007917227026839167\n",
      "============================================================\n",
      "\n",
      "Epoch = 105\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015231909129286851\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016251712572949964\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007916435304136483\n",
      "============================================================\n",
      "\n",
      "Epoch = 106\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014896334697729512\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015909790587768972\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791564366060607\n",
      "============================================================\n",
      "\n",
      "Epoch = 107\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0014600122931737916\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015572525604456002\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914852096240009\n",
      "============================================================\n",
      "\n",
      "Epoch = 108\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014278419495964774\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001525321563498616\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007914060611030385\n",
      "============================================================\n",
      "\n",
      "Epoch = 109\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014006721699195747\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001493614118851174\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007913269204969282\n",
      "============================================================\n",
      "\n",
      "Epoch = 110\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001369532660619181\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014638337931524444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007912477878048784\n",
      "============================================================\n",
      "\n",
      "Epoch = 111\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013459223539722472\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014344314178590081\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00791168663026098\n",
      "============================================================\n",
      "\n",
      "Epoch = 112\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013153481843351932\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014078333834616828\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910895461597954\n",
      "============================================================\n",
      "\n",
      "Epoch = 113\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012969026783361099\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013819446873656659\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007910104372051793\n",
      "============================================================\n",
      "\n",
      "Epoch = 114\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012675517280403591\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013608576509370979\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007909313361614588\n",
      "============================================================\n",
      "\n",
      "Epoch = 115\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001258820314394738\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001343013343337976\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007908522430278427\n",
      "============================================================\n",
      "\n",
      "Epoch = 116\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012338585734201614\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013355991961904214\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007907731578035399\n",
      "============================================================\n",
      "\n",
      "Epoch = 117\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012467373177816985\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013374222812176616\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906940804877595\n",
      "============================================================\n",
      "\n",
      "Epoch = 118\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00124068826476293\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001363970176697474\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007906150110797107\n",
      "============================================================\n",
      "\n",
      "Epoch = 119\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013098733696370762\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014133476683323393\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007905359495786028\n",
      "============================================================\n",
      "\n",
      "Epoch = 120\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013756449185131324\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015200414838371279\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007904568959836449\n",
      "============================================================\n",
      "\n",
      "Epoch = 121\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0016092174062486433\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0016716296090805833\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007903778502940466\n",
      "============================================================\n",
      "\n",
      "Epoch = 122\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0019244145207271066\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0019557402983454266\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902988125090172\n",
      "============================================================\n",
      "\n",
      "Epoch = 123\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0026413453274849044\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022980552438612027\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007902197826277664\n",
      "============================================================\n",
      "\n",
      "Epoch = 124\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0037068308826992817\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002994085189634522\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007901407606495036\n",
      "============================================================\n",
      "\n",
      "Epoch = 125\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005624994714851392\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0036931998656143487\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007900617465734385\n",
      "============================================================\n",
      "\n",
      "Epoch = 126\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008262168406875502\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00550465103492444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899827403987812\n",
      "============================================================\n",
      "\n",
      "Epoch = 127\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011629586191772678\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0070162095763635305\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007899037421247413\n",
      "============================================================\n",
      "\n",
      "Epoch = 128\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.014487235134782957\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01162470652494411\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789824751750529\n",
      "============================================================\n",
      "\n",
      "Epoch = 129\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01491007813578919\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.014928392171471443\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007897457692753539\n",
      "============================================================\n",
      "\n",
      "Epoch = 130\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.012407095927801023\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02220842116752796\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007896667946984263\n",
      "============================================================\n",
      "\n",
      "Epoch = 131\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010275778360486886\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.022999754933408098\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895878280189565\n",
      "============================================================\n",
      "\n",
      "Epoch = 132\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.014613409077544891\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02237346793323198\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007895088692361546\n",
      "============================================================\n",
      "\n",
      "Epoch = 133\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.02736973178596019\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009478835443647018\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00789429918349231\n",
      "============================================================\n",
      "\n",
      "Epoch = 134\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.04040591451127436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004934536509836297\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007893509753573962\n",
      "============================================================\n",
      "\n",
      "Epoch = 135\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.04016883972955303\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004979519761177318\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007892720402598604\n",
      "============================================================\n",
      "\n",
      "Epoch = 136\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016864389635712403\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.011705638617689038\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891931130558345\n",
      "============================================================\n",
      "\n",
      "Epoch = 137\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004376825663288\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0113695040586397\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007891141937445289\n",
      "============================================================\n",
      "\n",
      "Epoch = 138\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007566082385089904\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004325881011329607\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007890352823251545\n",
      "============================================================\n",
      "\n",
      "Epoch = 139\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011131778640433498\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0038062855228650034\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788956378796922\n",
      "============================================================\n",
      "\n",
      "Epoch = 140\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007549582981400757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006099439902716379\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007888774831590423\n",
      "============================================================\n",
      "\n",
      "Epoch = 141\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0030312174347940095\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004441253266940952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887985954107264\n",
      "============================================================\n",
      "\n",
      "Epoch = 142\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.005069047870057316\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002816533624272473\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007887197155511854\n",
      "============================================================\n",
      "\n",
      "Epoch = 143\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004498168555560072\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003751964874755558\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007886408435796303\n",
      "============================================================\n",
      "\n",
      "Epoch = 144\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002373068646986955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0034174346127542076\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007885619794952723\n",
      "============================================================\n",
      "\n",
      "Epoch = 145\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0025975998616884926\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0026544278559134343\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884831232973228\n",
      "============================================================\n",
      "\n",
      "Epoch = 146\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0025887000639394147\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0026848147468689215\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007884042749849931\n",
      "============================================================\n",
      "\n",
      "Epoch = 147\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018470249155171604\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022332483212831188\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007883254345574946\n",
      "============================================================\n",
      "\n",
      "Epoch = 148\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0018741231329237732\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001827197656187325\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007882466020140389\n",
      "============================================================\n",
      "\n",
      "Epoch = 149\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0017285688399182667\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00195160576786082\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007881677773538374\n",
      "============================================================\n",
      "\n",
      "Epoch = 150\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00147450535850162\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001800871676097753\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00788088960576102\n",
      "============================================================\n",
      "\n",
      "Epoch = 151\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013899529334258202\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014328275092371347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007880101516800443\n",
      "============================================================\n",
      "\n",
      "Epoch = 152\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014034819656189553\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014077667716456198\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007879313506648764\n",
      "============================================================\n",
      "\n",
      "Epoch = 153\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012347944422304003\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014416330226567876\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007878525575298098\n",
      "============================================================\n",
      "\n",
      "Epoch = 154\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00108750431968968\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0012758025323869923\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007877737722740568\n",
      "============================================================\n",
      "\n",
      "Epoch = 155\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011518397589195884\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011034018010923825\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876949948968294\n",
      "============================================================\n",
      "\n",
      "Epoch = 156\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011128171690441644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011673714021553372\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007876162253973397\n",
      "============================================================\n",
      "\n",
      "Epoch = 157\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009713872970978551\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001174818351860953\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007875374637748\n",
      "============================================================\n",
      "\n",
      "Epoch = 158\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009524651608442635\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010091536125045712\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007874587100284224\n",
      "============================================================\n",
      "\n",
      "Epoch = 159\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010013641191660833\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009546235979143482\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873799641574196\n",
      "============================================================\n",
      "\n",
      "Epoch = 160\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009319443057269956\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009989036961362547\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007873012261610038\n",
      "============================================================\n",
      "\n",
      "Epoch = 161\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0008480287601240128\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009735240907032552\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007872224960383877\n",
      "============================================================\n",
      "\n",
      "Epoch = 162\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008645718934757901\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008921136685761281\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00787143773788784\n",
      "============================================================\n",
      "\n",
      "Epoch = 163\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008617905215879006\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008839791275849708\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007870650594114051\n",
      "============================================================\n",
      "\n",
      "Epoch = 164\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0008156992009752229\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008942393229282811\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786986352905464\n",
      "============================================================\n",
      "\n",
      "Epoch = 165\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007762374270074027\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008610752490087758\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007869076542701735\n",
      "============================================================\n",
      "\n",
      "Epoch = 166\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007807428547980384\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008206108959718937\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007868289635047465\n",
      "============================================================\n",
      "\n",
      "Epoch = 167\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007664723658891866\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008116584639205887\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00786750280608396\n",
      "============================================================\n",
      "\n",
      "Epoch = 168\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007357323842274955\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008090386393790481\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007866716055803353\n",
      "============================================================\n",
      "\n",
      "Epoch = 169\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007207704339860985\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007845859485694735\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865929384197771\n",
      "============================================================\n",
      "\n",
      "Epoch = 170\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007141520895001155\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007634523799719214\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007865142791259352\n",
      "============================================================\n",
      "\n",
      "Epoch = 171\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006994951432187519\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000757099242632295\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007864356276980226\n",
      "============================================================\n",
      "\n",
      "Epoch = 172\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006842161247696966\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000740488579624219\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007863569841352528\n",
      "============================================================\n",
      "\n",
      "Epoch = 173\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006745922247171836\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007261458939255407\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007862783484368393\n",
      "============================================================\n",
      "\n",
      "Epoch = 174\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00066272622759172\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007144811996020507\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861997206019955\n",
      "============================================================\n",
      "\n",
      "Epoch = 175\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006518403963173724\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007009508264276859\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007861211006299353\n",
      "============================================================\n",
      "\n",
      "Epoch = 176\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006412935833049686\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006903583681731007\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007860424885198723\n",
      "============================================================\n",
      "\n",
      "Epoch = 177\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006316752206453865\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006766604492400626\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007859638842710202\n",
      "============================================================\n",
      "\n",
      "Epoch = 178\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006238772455362758\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006653375881186681\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858852878825932\n",
      "============================================================\n",
      "\n",
      "Epoch = 179\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006134261080044381\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006567964488921724\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007858066993538049\n",
      "============================================================\n",
      "\n",
      "Epoch = 180\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006035610520663447\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00064538741217839\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007857281186838695\n",
      "============================================================\n",
      "\n",
      "Epoch = 181\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005962494507778351\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000635111370367907\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007856495458720011\n",
      "============================================================\n",
      "\n",
      "Epoch = 182\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000587700214323289\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006252783869943394\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00785570980917414\n",
      "============================================================\n",
      "\n",
      "Epoch = 183\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005797632041954889\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006156742643830312\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854924238193223\n",
      "============================================================\n",
      "\n",
      "Epoch = 184\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005714477874365716\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000607778356401327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007854138745769405\n",
      "============================================================\n",
      "\n",
      "Epoch = 185\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005629159594720676\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005980834701255291\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007853353331894828\n",
      "============================================================\n",
      "\n",
      "Epoch = 186\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005560455799335133\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005891212312536841\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007852567996561638\n",
      "============================================================\n",
      "\n",
      "Epoch = 187\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005485175882100399\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005809517657172032\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007851782739761982\n",
      "============================================================\n",
      "\n",
      "Epoch = 188\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0005411523620351408\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005725479423626069\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850997561488006\n",
      "============================================================\n",
      "\n",
      "Epoch = 189\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005342505913320814\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005649338260421666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007850212461731856\n",
      "============================================================\n",
      "\n",
      "Epoch = 190\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005267358197093908\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000557050007184619\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007849427440485683\n",
      "============================================================\n",
      "\n",
      "Epoch = 191\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005200371726088494\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005494393604509986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007848642497741636\n",
      "============================================================\n",
      "\n",
      "Epoch = 192\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005133323368750935\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005421118542174952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847857633491861\n",
      "============================================================\n",
      "\n",
      "Epoch = 193\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005067834323586188\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005347438461339282\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007847072847728512\n",
      "============================================================\n",
      "\n",
      "Epoch = 194\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005006329566326533\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00052764872422763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784628814044374\n",
      "============================================================\n",
      "\n",
      "Epoch = 195\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004942268469281853\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005207041703922475\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007845503511629695\n",
      "============================================================\n",
      "\n",
      "Epoch = 196\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004881884086453194\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005138347078949995\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007844718961278533\n",
      "============================================================\n",
      "\n",
      "Epoch = 197\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00048220879783814866\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005073143614482366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843934489382405\n",
      "============================================================\n",
      "\n",
      "Epoch = 198\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00047618209011475096\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005008325432374802\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007843150095933466\n",
      "============================================================\n",
      "\n",
      "Epoch = 199\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00047056501422269327\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004943718163422105\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007842365780923873\n",
      "============================================================\n",
      "\n",
      "Epoch = 200\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004649555481667532\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004881956596076763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00784158154434578\n",
      "============================================================\n",
      "\n",
      "Epoch = 201\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004595384435066159\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00048183776487199597\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840797386191346\n",
      "============================================================\n",
      "\n",
      "Epoch = 202\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00045435728210314343\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004759570642473665\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007840013306452728\n",
      "============================================================\n",
      "\n",
      "Epoch = 203\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004488413029719302\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00047017256881264015\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007839229305122082\n",
      "============================================================\n",
      "\n",
      "Epoch = 204\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004436727254425907\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00046448737827503567\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783844538219157\n",
      "============================================================\n",
      "\n",
      "Epoch = 205\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00043849439381123194\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004590664201979985\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00783766153765335\n",
      "============================================================\n",
      "\n",
      "Epoch = 206\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004336452304029358\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004531456040734279\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836877771499585\n",
      "============================================================\n",
      "\n",
      "Epoch = 207\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004294557120658436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004477536154371356\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007836094083722435\n",
      "============================================================\n",
      "\n",
      "Epoch = 208\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004246668372641796\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000442354801542232\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007835310474314064\n",
      "============================================================\n",
      "\n",
      "Epoch = 209\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00042024567838051173\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004378469714811125\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007834526943266633\n",
      "============================================================\n",
      "\n",
      "Epoch = 210\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004148580403058837\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004338654275659976\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007833743490572306\n",
      "============================================================\n",
      "\n",
      "Epoch = 211\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00041031119349358255\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00042898274460204886\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832960116223248\n",
      "============================================================\n",
      "\n",
      "Epoch = 212\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040765165815847166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004237113722260225\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007832176820211626\n",
      "============================================================\n",
      "\n",
      "Epoch = 213\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040582495307093527\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004174185205183756\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007831393602529605\n",
      "============================================================\n",
      "\n",
      "Epoch = 214\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004049960154055266\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004148073108536218\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007830610463169352\n",
      "============================================================\n",
      "\n",
      "Epoch = 215\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.000398774884697396\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00041683711241167684\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829827402123036\n",
      "============================================================\n",
      "\n",
      "Epoch = 216\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00039159616489301187\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000419976762355281\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007829044419382824\n",
      "============================================================\n",
      "\n",
      "Epoch = 217\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000390689278562626\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004164610373623312\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007828261514940886\n",
      "============================================================\n",
      "\n",
      "Epoch = 218\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040599922570941436\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00040137442039038117\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007827478688789392\n",
      "============================================================\n",
      "\n",
      "Epoch = 219\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00043413663167597726\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004011153431641911\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007826695940920513\n",
      "============================================================\n",
      "\n",
      "Epoch = 220\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004356302437535398\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00044761574539415753\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825913271326422\n",
      "============================================================\n",
      "\n",
      "Epoch = 221\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004032909494933076\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005309540957927976\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007825130679999289\n",
      "============================================================\n",
      "\n",
      "Epoch = 222\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00041041136241342627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005561942644672619\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00782434816693129\n",
      "============================================================\n",
      "\n",
      "Epoch = 223\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005999092148553193\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00046182509926156323\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007823565732114597\n",
      "============================================================\n",
      "\n",
      "Epoch = 224\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009481987264047074\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005154193942224072\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822783375541386\n",
      "============================================================\n",
      "\n",
      "Epoch = 225\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001059490011649915\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011999399502982244\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007822001097203832\n",
      "============================================================\n",
      "\n",
      "Epoch = 226\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007153022294855863\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0023512915265917864\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007821218897094112\n",
      "============================================================\n",
      "\n",
      "Epoch = 227\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0011583996098577178\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002526883220261419\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007820436775204402\n",
      "============================================================\n",
      "\n",
      "Epoch = 228\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004271001428152816\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014143537624780162\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007819654731526881\n",
      "============================================================\n",
      "\n",
      "Epoch = 229\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.008670568676979913\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0033058743577532423\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818872766053728\n",
      "============================================================\n",
      "\n",
      "Epoch = 230\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00977591698139708\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01269994659990851\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007818090878777124\n",
      "============================================================\n",
      "\n",
      "Epoch = 231\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004531751167134233\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.02333083091519851\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007817309069689245\n",
      "============================================================\n",
      "\n",
      "Epoch = 232\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007572995922125366\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.020984874475913115\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007816527338782277\n",
      "============================================================\n",
      "\n",
      "Epoch = 233\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.01927590929916128\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.012149929148333514\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078157456860484\n",
      "============================================================\n",
      "\n",
      "Epoch = 234\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.020917219586904214\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006149633477722585\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814964111479795\n",
      "============================================================\n",
      "\n",
      "Epoch = 235\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.018179688255417607\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006477283779846635\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007814182615068646\n",
      "============================================================\n",
      "\n",
      "Epoch = 236\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011707953006781503\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00611556078308877\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781340119680714\n",
      "============================================================\n",
      "\n",
      "Epoch = 237\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011443172493050192\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0044620381923155\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007812619856687459\n",
      "============================================================\n",
      "\n",
      "Epoch = 238\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010259234412567911\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002989251694866307\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781183859470179\n",
      "============================================================\n",
      "\n",
      "Epoch = 239\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00806409810192839\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0022791201455060993\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00781105741084232\n",
      "============================================================\n",
      "\n",
      "Epoch = 240\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0027735293572268447\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.003247331597033218\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007810276305101236\n",
      "============================================================\n",
      "\n",
      "Epoch = 241\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0014582010184179324\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002818117119547329\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007809495277470726\n",
      "============================================================\n",
      "\n",
      "Epoch = 242\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.0017177035887585414\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001868236376787468\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007808714327942979\n",
      "============================================================\n",
      "\n",
      "Epoch = 243\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0024001191930923243\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013216720957506872\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807933456510184\n",
      "============================================================\n",
      "\n",
      "Epoch = 244\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002905374265673413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0013714482510745283\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007807152663164533\n",
      "============================================================\n",
      "\n",
      "Epoch = 245\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0019515009677788294\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0014156158494640697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007806371947898217\n",
      "============================================================\n",
      "\n",
      "Epoch = 246\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0013262992201683139\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0007281225531791712\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007805591310703427\n",
      "============================================================\n",
      "\n",
      "Epoch = 247\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012594752556063001\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006604571459462564\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007804810751572357\n",
      "============================================================\n",
      "\n",
      "Epoch = 248\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0010097932263130307\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0009512779116055864\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078040302704972\n",
      "============================================================\n",
      "\n",
      "Epoch = 249\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007970818415757244\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0011215359200699672\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00780324986747015\n",
      "============================================================\n",
      "\n",
      "Epoch = 250\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005629411623470125\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0010084630867221787\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007802469542483403\n",
      "============================================================\n",
      "\n",
      "Epoch = 251\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005140557076881698\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006961777798399765\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007801689295529155\n",
      "============================================================\n",
      "\n",
      "Epoch = 252\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006322576154186828\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0005014017542446073\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007800909126599601\n",
      "============================================================\n",
      "\n",
      "Epoch = 253\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006374583463288079\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00044056467478534094\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0078001290356869415\n",
      "============================================================\n",
      "\n",
      "Epoch = 254\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00061529444553485\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00046682824577657604\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007799349022783373\n",
      "============================================================\n",
      "\n",
      "Epoch = 255\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005399054157938663\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000445135059243406\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007798569087881095\n",
      "============================================================\n",
      "\n",
      "Epoch = 256\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0005310729035534207\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004341354116222366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797789230972307\n",
      "============================================================\n",
      "\n",
      "Epoch = 257\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00048329039755738354\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004284487717449911\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007797009452049209\n",
      "============================================================\n",
      "\n",
      "Epoch = 258\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004415384096417104\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003968156075537125\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077962297511040045\n",
      "============================================================\n",
      "\n",
      "Epoch = 259\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040529972300760064\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00037451920001747933\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007795450128128894\n",
      "============================================================\n",
      "\n",
      "Epoch = 260\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003841780359211956\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00036873847490720814\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077946705831160815\n",
      "============================================================\n",
      "\n",
      "Epoch = 261\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00040521681446481635\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003513260956162328\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00779389111605777\n",
      "============================================================\n",
      "\n",
      "Epoch = 262\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004060858223615412\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00034766926920757734\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007793111726946164\n",
      "============================================================\n",
      "\n",
      "Epoch = 263\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000378642070109245\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003341837890394726\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007792332415773469\n",
      "============================================================\n",
      "\n",
      "Epoch = 264\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003575608699598439\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00032307229995694257\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007791553182531892\n",
      "============================================================\n",
      "\n",
      "Epoch = 265\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003429620794640952\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003231567474195596\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007790774027213639\n",
      "============================================================\n",
      "\n",
      "Epoch = 266\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003304186418182492\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003191062070835275\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007789994949810917\n",
      "============================================================\n",
      "\n",
      "Epoch = 267\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00032780480109265506\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00031298157925987503\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077892159503159366\n",
      "============================================================\n",
      "\n",
      "Epoch = 268\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00032276432911575084\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.000310650824553229\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077884370287209055\n",
      "============================================================\n",
      "\n",
      "Epoch = 269\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003151694324745255\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00030504608843313685\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007787658185018033\n",
      "============================================================\n",
      "\n",
      "Epoch = 270\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003077774372050319\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003001228049914896\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786879419199532\n",
      "============================================================\n",
      "\n",
      "Epoch = 271\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00030359130781156283\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00029309796232439587\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007786100731257612\n",
      "============================================================\n",
      "\n",
      "Epoch = 272\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003003194204370439\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00028779867164020496\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007785322121184487\n",
      "============================================================\n",
      "\n",
      "Epoch = 273\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00029758766892140273\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00028262439816146727\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007784543588972369\n",
      "============================================================\n",
      "\n",
      "Epoch = 274\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002958570047432096\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002789595183062224\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007783765134613472\n",
      "============================================================\n",
      "\n",
      "Epoch = 275\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002900974016020835\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002755906544282472\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007782986758100011\n",
      "============================================================\n",
      "\n",
      "Epoch = 276\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00028614346157438385\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002724562881366079\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077822084594242015\n",
      "============================================================\n",
      "\n",
      "Epoch = 277\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00028307548792606786\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002694191394488281\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007781430238578259\n",
      "============================================================\n",
      "\n",
      "Epoch = 278\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002798891353339961\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002657542232429669\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007780652095554402\n",
      "============================================================\n",
      "\n",
      "Epoch = 279\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00027645878429656426\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00026283000532963124\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779874030344846\n",
      "============================================================\n",
      "\n",
      "Epoch = 280\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00027316080212832426\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00025970767753863547\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007779096042941812\n",
      "============================================================\n",
      "\n",
      "Epoch = 281\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002699011189065768\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000257029856086616\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077783181333375175\n",
      "============================================================\n",
      "\n",
      "Epoch = 282\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002663998263753472\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002544454886248832\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077775403015241835\n",
      "============================================================\n",
      "\n",
      "Epoch = 283\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00026359638983491126\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000251632489272192\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077767625474940314\n",
      "============================================================\n",
      "\n",
      "Epoch = 284\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002610644570132649\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00024880381707384676\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775984871239282\n",
      "============================================================\n",
      "\n",
      "Epoch = 285\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002583324943727738\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002462126273369508\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007775207272752158\n",
      "============================================================\n",
      "\n",
      "Epoch = 286\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00025587235517863236\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00024361214705045743\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007774429752024883\n",
      "============================================================\n",
      "\n",
      "Epoch = 287\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002531606709444178\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00024120436350680798\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007773652309049681\n",
      "============================================================\n",
      "\n",
      "Epoch = 288\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002507042695807106\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000238752003131026\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772874943818776\n",
      "============================================================\n",
      "\n",
      "Epoch = 289\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002480832904584578\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023642889173643836\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007772097656324394\n",
      "============================================================\n",
      "\n",
      "Epoch = 290\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00024568247602754355\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023397530239335518\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007771320446558761\n",
      "============================================================\n",
      "\n",
      "Epoch = 291\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002434374816761453\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002317595197798329\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007770543314514105\n",
      "============================================================\n",
      "\n",
      "Epoch = 292\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002410884527285037\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00022938742468536153\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007769766260182654\n",
      "============================================================\n",
      "\n",
      "Epoch = 293\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000238953782873792\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00022724232790121514\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768989283556636\n",
      "============================================================\n",
      "\n",
      "Epoch = 294\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023663933828657995\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.00022502820424321652\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007768212384628281\n",
      "============================================================\n",
      "\n",
      "Epoch = 295\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002345218772375371\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00022290101384818116\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007767435563389818\n",
      "============================================================\n",
      "\n",
      "Epoch = 296\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023231774357836572\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00022083076803725043\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007766658819833479\n",
      "============================================================\n",
      "\n",
      "Epoch = 297\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023025414545533514\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021874191731614557\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765882153951496\n",
      "============================================================\n",
      "\n",
      "Epoch = 298\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022819442118549927\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021675259446164163\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007765105565736101\n",
      "============================================================\n",
      "\n",
      "Epoch = 299\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022617750787967976\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021473922205649657\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007764329055179527\n",
      "============================================================\n",
      "\n",
      "Epoch = 300\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022420537412263847\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021279767574906952\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007763552622274009\n",
      "============================================================\n",
      "\n",
      "Epoch = 301\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002222362157758134\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002108735918134058\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077627762670117815\n",
      "============================================================\n",
      "\n",
      "Epoch = 302\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00022033405829939768\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002089701674477627\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00776199998938508\n",
      "============================================================\n",
      "\n",
      "Epoch = 303\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00021841536334125768\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020712425358316889\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007761223789386142\n",
      "============================================================\n",
      "\n",
      "Epoch = 304\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002165561241384328\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002052665942164689\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007760447667007203\n",
      "============================================================\n",
      "\n",
      "Epoch = 305\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00021471493144220493\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020348087357644347\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007759671622240502\n",
      "============================================================\n",
      "\n",
      "Epoch = 306\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00021290021156199419\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020168033325649066\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007758895655078278\n",
      "============================================================\n",
      "\n",
      "Epoch = 307\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00021112859016679942\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019994181822114272\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775811976551277\n",
      "============================================================\n",
      "\n",
      "Epoch = 308\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00020936645014519906\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001981961730912327\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077573439535362195\n",
      "============================================================\n",
      "\n",
      "Epoch = 309\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002076516625579947\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001965043993691444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007756568219140866\n",
      "============================================================\n",
      "\n",
      "Epoch = 310\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00020593890755783787\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019481708674683486\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007755792562318952\n",
      "============================================================\n",
      "\n",
      "Epoch = 311\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00020427203444159972\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019316521734999613\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00775501698306272\n",
      "============================================================\n",
      "\n",
      "Epoch = 312\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00020260935089469898\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00019153301818339793\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007754241481364414\n",
      "============================================================\n",
      "\n",
      "Epoch = 313\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002009879996169804\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018992122330718336\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007753466057216277\n",
      "============================================================\n",
      "\n",
      "Epoch = 314\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001993753768178856\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001883361153453723\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007752690710610556\n",
      "============================================================\n",
      "\n",
      "Epoch = 315\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001977913233813733\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001867716483215755\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751915441539495\n",
      "============================================================\n",
      "\n",
      "Epoch = 316\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000196229467516499\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001852235216314751\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007751140249995341\n",
      "============================================================\n",
      "\n",
      "Epoch = 317\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019468599627568413\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018370556129394168\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007750365135970342\n",
      "============================================================\n",
      "\n",
      "Epoch = 318\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019316502211841625\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018219895445370683\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007749590099456746\n",
      "============================================================\n",
      "\n",
      "Epoch = 319\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019166283414581982\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001807185128965776\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077488151404468\n",
      "============================================================\n",
      "\n",
      "Epoch = 320\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019018140268343005\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017925472429279306\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007748040258932756\n",
      "============================================================\n",
      "\n",
      "Epoch = 321\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00018871601423205628\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001778128655428316\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007747265454906863\n",
      "============================================================\n",
      "\n",
      "Epoch = 322\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018727320998919648\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017638582398114613\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007746490728361372\n",
      "============================================================\n",
      "\n",
      "Epoch = 323\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018584528772862667\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017498227156070018\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007745716079288536\n",
      "============================================================\n",
      "\n",
      "Epoch = 324\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018443784540658244\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017359144352047944\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744941507680608\n",
      "============================================================\n",
      "\n",
      "Epoch = 325\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018304578467386975\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017222319071928704\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007744167013529839\n",
      "============================================================\n",
      "\n",
      "Epoch = 326\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018167236691194627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017086910790778945\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007743392596828487\n",
      "============================================================\n",
      "\n",
      "Epoch = 327\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018031429662296203\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016953314441410037\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007742618257568804\n",
      "============================================================\n",
      "\n",
      "Epoch = 328\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017897424933147158\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016821434995952598\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741843995743047\n",
      "============================================================\n",
      "\n",
      "Epoch = 329\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017764870071387037\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016691045619437182\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007741069811343473\n",
      "============================================================\n",
      "\n",
      "Epoch = 330\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017633989406181058\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001656249171062939\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007740295704362339\n",
      "============================================================\n",
      "\n",
      "Epoch = 331\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017504664116040988\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016435219955028468\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007739521674791903\n",
      "============================================================\n",
      "\n",
      "Epoch = 332\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001737677597805483\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016309794098687678\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007738747722624424\n",
      "============================================================\n",
      "\n",
      "Epoch = 333\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017250531475204202\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016185606159504825\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007737973847852161\n",
      "============================================================\n",
      "\n",
      "Epoch = 334\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017125520251198126\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016063147892307538\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077372000504673764\n",
      "============================================================\n",
      "\n",
      "Epoch = 335\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001700225100546155\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001594198208498052\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00773642633046233\n",
      "============================================================\n",
      "\n",
      "Epoch = 336\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001687996426888246\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015822378744494986\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007735652687829283\n",
      "============================================================\n",
      "\n",
      "Epoch = 337\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016759638946601857\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001570409765051768\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077348791225605\n",
      "============================================================\n",
      "\n",
      "Epoch = 338\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016639959689585408\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015587246711851402\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007734105634648244\n",
      "============================================================\n",
      "\n",
      "Epoch = 339\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001652246628113014\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001547181062587338\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007733332224084779\n",
      "============================================================\n",
      "\n",
      "Epoch = 340\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001640533352372624\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015357526176613788\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077325588908623705\n",
      "============================================================\n",
      "\n",
      "Epoch = 341\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016290592849421042\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001524496323727404\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731785634973285\n",
      "============================================================\n",
      "\n",
      "Epoch = 342\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016175901166232403\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015133081597296444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007731012456409787\n",
      "============================================================\n",
      "\n",
      "Epoch = 343\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016063902092827297\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015023396691462264\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007730239355164146\n",
      "============================================================\n",
      "\n",
      "Epoch = 344\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015951600779220797\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000149137949537209\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077294663312286295\n",
      "============================================================\n",
      "\n",
      "Epoch = 345\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015842403829428503\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001480705008570263\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077286933845955065\n",
      "============================================================\n",
      "\n",
      "Epoch = 346\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015732585915870126\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014699619491285193\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727920515257047\n",
      "============================================================\n",
      "\n",
      "Epoch = 347\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001562652392545135\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.00014596045637844555\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007727147723205522\n",
      "============================================================\n",
      "\n",
      "Epoch = 348\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001551959687460938\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001449078579287468\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007726375008433201\n",
      "============================================================\n",
      "\n",
      "Epoch = 349\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015417749598963906\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014391085680540996\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077256023709323576\n",
      "============================================================\n",
      "\n",
      "Epoch = 350\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015315155790549535\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014288493188121905\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724829810695264\n",
      "============================================================\n",
      "\n",
      "Epoch = 351\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001522078711181614\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001419472858454323\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007724057327714195\n",
      "============================================================\n",
      "\n",
      "Epoch = 352\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001512741252013259\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001409714049070697\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007723284921981423\n",
      "============================================================\n",
      "\n",
      "Epoch = 353\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001505042882619733\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001401578518624065\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007722512593489225\n",
      "============================================================\n",
      "\n",
      "Epoch = 354\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014982457014083435\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001393235397999349\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007721740342229876\n",
      "============================================================\n",
      "\n",
      "Epoch = 355\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014953989309889843\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013884816115338231\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720968168195653\n",
      "============================================================\n",
      "\n",
      "Epoch = 356\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014965200709878056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013850396704954428\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007720196071378833\n",
      "============================================================\n",
      "\n",
      "Epoch = 357\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015086281450291879\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013911299116336877\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007719424051771695\n",
      "============================================================\n",
      "\n",
      "Epoch = 358\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015357824651490197\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014059084312691354\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007718652109366518\n",
      "============================================================\n",
      "\n",
      "Epoch = 359\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001596676425220482\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014500878531587908\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717880244155581\n",
      "============================================================\n",
      "\n",
      "Epoch = 360\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001712099120091757\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001534765627915776\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007717108456131165\n",
      "============================================================\n",
      "\n",
      "Epoch = 361\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00019382960440065644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017200346196892863\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007716336745285552\n",
      "============================================================\n",
      "\n",
      "Epoch = 362\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023602472596827596\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020785230007643548\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007715565111611023\n",
      "============================================================\n",
      "\n",
      "Epoch = 363\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000316194072582097\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000280230240602139\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714793555099862\n",
      "============================================================\n",
      "\n",
      "Epoch = 364\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0004666058428405806\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00042457921097580076\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007714022075744352\n",
      "============================================================\n",
      "\n",
      "Epoch = 365\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0007495582370533718\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000702434307799312\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007713250673536777\n",
      "============================================================\n",
      "\n",
      "Epoch = 366\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012800584611128616\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.001267870435676266\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007712479348469424\n",
      "============================================================\n",
      "\n",
      "Epoch = 367\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0022576796206647\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002267125005614064\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007711708100534577\n",
      "============================================================\n",
      "\n",
      "Epoch = 368\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0040228117966989475\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004242651390805484\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007710936929724523\n",
      "============================================================\n",
      "\n",
      "Epoch = 369\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.007010325989450202\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006897824233781645\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00771016583603155\n",
      "============================================================\n",
      "\n",
      "Epoch = 370\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011574690546589808\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01112102983754333\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0077093948194479475\n",
      "============================================================\n",
      "\n",
      "Epoch = 371\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.016980558785056422\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.01199149368278807\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007708623879966002\n",
      "============================================================\n",
      "\n",
      "Epoch = 372\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.020825732205234357\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.011787238933977593\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707853017578006\n",
      "============================================================\n",
      "\n",
      "Epoch = 373\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.018159860048171602\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.006786541422166397\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007707082232276248\n",
      "============================================================\n",
      "\n",
      "Epoch = 374\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.010641672829000779\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009951592965524444\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007706311524053021\n",
      "============================================================\n",
      "\n",
      "Epoch = 375\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.004145579543351151\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.013886241499905333\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007705540892900616\n",
      "============================================================\n",
      "\n",
      "Epoch = 376\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.006059054490734554\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.009773968357323366\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007704770338811326\n",
      "============================================================\n",
      "\n",
      "Epoch = 377\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.009779395297418728\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002208240363173247\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703999861777445\n",
      "============================================================\n",
      "\n",
      "Epoch = 378\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.011191689043654682\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0027732443411865194\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007703229461791267\n",
      "============================================================\n",
      "\n",
      "Epoch = 379\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00573400453141104\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.004763601134477402\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007702459138845088\n",
      "============================================================\n",
      "\n",
      "Epoch = 380\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0038552994873222736\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0017737415393863337\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007701688892931204\n",
      "============================================================\n",
      "\n",
      "Epoch = 381\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.003176900849361468\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0020416608235800794\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700918724041911\n",
      "============================================================\n",
      "\n",
      "Epoch = 382\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002246117762603271\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.002876127038123492\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007700148632169506\n",
      "============================================================\n",
      "\n",
      "Epoch = 383\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0015142540216176463\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000977922992736198\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007699378617306289\n",
      "============================================================\n",
      "\n",
      "Epoch = 384\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.002059705872068722\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008526782583002872\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007698608679444559\n",
      "============================================================\n",
      "\n",
      "Epoch = 385\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001507593482362615\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0015953030585082416\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007697838818576615\n",
      "============================================================\n",
      "\n",
      "Epoch = 386\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.001002239158660546\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0006471681489014636\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076970690346947574\n",
      "============================================================\n",
      "\n",
      "Epoch = 387\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009883928980614555\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000491549392648031\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007696299327791288\n",
      "============================================================\n",
      "\n",
      "Epoch = 388\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0006732622959053042\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0008450379176037857\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007695529697858509\n",
      "============================================================\n",
      "\n",
      "Epoch = 389\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0009027019478220508\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00040299079349327666\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076947601448887236\n",
      "============================================================\n",
      "\n",
      "Epoch = 390\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0012364412901105088\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0003249370564186664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007693990668874235\n",
      "============================================================\n",
      "\n",
      "Epoch = 391\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000794257853398621\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0004877053636364572\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076932212698073476\n",
      "============================================================\n",
      "\n",
      "Epoch = 392\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003966593875187644\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002864157787058221\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007692451947680367\n",
      "============================================================\n",
      "\n",
      "Epoch = 393\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00037517865374850844\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00031455864220673017\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007691682702485599\n",
      "============================================================\n",
      "\n",
      "Epoch = 394\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003568026387798944\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00039082360864937373\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076909135342153505\n",
      "============================================================\n",
      "\n",
      "Epoch = 395\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0003955032736775065\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00023896753677618858\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007690144442861929\n",
      "============================================================\n",
      "\n",
      "Epoch = 396\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000357423165587977\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000234573167426646\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076893754284176425\n",
      "============================================================\n",
      "\n",
      "Epoch = 397\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00025466175426416056\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0002840907310315708\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007688606490874801\n",
      "============================================================\n",
      "\n",
      "Epoch = 398\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0002522120846796112\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00021081636144821013\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687837630225713\n",
      "============================================================\n",
      "\n",
      "Epoch = 399\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00027044331974083406\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00020811295956069516\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007687068846462691\n",
      "============================================================\n",
      "\n",
      "Epoch = 400\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00024156623465337602\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00022156509973176024\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076863001395780445\n",
      "============================================================\n",
      "\n",
      "Epoch = 401\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00024310757501384294\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017828723052789664\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007685531509564087\n",
      "============================================================\n",
      "\n",
      "Epoch = 402\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00023391090960540365\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00017254643367464623\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076847629564131305\n",
      "============================================================\n",
      "\n",
      "Epoch = 403\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001976723169101465\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00018411231516383763\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00768399448011749\n",
      "============================================================\n",
      "\n",
      "Epoch = 404\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00017978319618397657\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016539395796802254\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007683226080669478\n",
      "============================================================\n",
      "\n",
      "Epoch = 405\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00018080326003028325\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00016242162871932443\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007682457758061411\n",
      "============================================================\n",
      "\n",
      "Epoch = 406\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001750199073415709\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001669450857311813\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007681689512285605\n",
      "============================================================\n",
      "\n",
      "Epoch = 407\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016839122421361764\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015288631448454276\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680921343334376\n",
      "============================================================\n",
      "\n",
      "Epoch = 408\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016680684060427166\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00015085042853590116\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007680153251200043\n",
      "============================================================\n",
      "\n",
      "Epoch = 409\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00016381649729262982\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001552487596564992\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007679385235874923\n",
      "============================================================\n",
      "\n",
      "Epoch = 410\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015853013200175871\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001458332896716757\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007678617297351336\n",
      "============================================================\n",
      "\n",
      "Epoch = 411\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001572516074525251\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001385849917663462\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677849435621601\n",
      "============================================================\n",
      "\n",
      "Epoch = 412\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015549190467754756\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00014010152713400252\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007677081650678039\n",
      "============================================================\n",
      "\n",
      "Epoch = 413\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015335055793974157\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001377595298385194\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007676313942512971\n",
      "============================================================\n",
      "\n",
      "Epoch = 414\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00015110196914753143\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013391383449025572\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007675546311118719\n",
      "============================================================\n",
      "\n",
      "Epoch = 415\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001483229345630109\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013280847651938755\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007674778756487608\n",
      "============================================================\n",
      "\n",
      "Epoch = 416\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014455543681769607\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00013105490755740178\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767401127861196\n",
      "============================================================\n",
      "\n",
      "Epoch = 417\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00014213416625905086\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001287168149837686\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007673243877484098\n",
      "============================================================\n",
      "\n",
      "Epoch = 418\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001405585349416561\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.000126820011894404\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767247655309635\n",
      "============================================================\n",
      "\n",
      "Epoch = 419\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013874772511971635\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012538133089587308\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00767170930544104\n",
      "============================================================\n",
      "\n",
      "Epoch = 420\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013689678122793565\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001238098797928325\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076709421345104965\n",
      "============================================================\n",
      "\n",
      "Epoch = 421\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.000135625525761605\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012257865839843346\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007670175040297046\n",
      "============================================================\n",
      "\n",
      "Epoch = 422\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013388364244738412\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012138511893827739\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007669408022793016\n",
      "============================================================\n",
      "\n",
      "Epoch = 423\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001319151829299832\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00012027764379385669\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007668641081990737\n",
      "============================================================\n",
      "\n",
      "Epoch = 424\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00013067843086812445\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011866216688406895\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667874217882537\n",
      "============================================================\n",
      "\n",
      "Epoch = 425\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012957447603446315\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001174505085424437\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007667107430460749\n",
      "============================================================\n",
      "\n",
      "Epoch = 426\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001279941314028223\n",
      "| => | Batch 2 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 1 loss = 0.00011639301653197625\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007666340719717703\n",
      "============================================================\n",
      "\n",
      "Epoch = 427\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001266975996437572\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011521433744006608\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076655740856457315\n",
      "============================================================\n",
      "\n",
      "Epoch = 428\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012545186556222807\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011416787675330657\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664807528237167\n",
      "============================================================\n",
      "\n",
      "Epoch = 429\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012416079390565558\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001131451479139214\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007664041047484343\n",
      "============================================================\n",
      "\n",
      "Epoch = 430\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012299026723596623\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011208403239614567\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007663274643379595\n",
      "============================================================\n",
      "\n",
      "Epoch = 431\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012189392978712477\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011104489953321165\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007662508315915257\n",
      "============================================================\n",
      "\n",
      "Epoch = 432\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00012085507537816422\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00011002406367854031\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007661742065083665\n",
      "============================================================\n",
      "\n",
      "Epoch = 433\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011969337880439601\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010909042975214846\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660975890877157\n",
      "============================================================\n",
      "\n",
      "Epoch = 434\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011864150215112814\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010813089903804057\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007660209793288069\n",
      "============================================================\n",
      "\n",
      "Epoch = 435\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011757920468553067\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010720508860513106\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076594437723087406\n",
      "============================================================\n",
      "\n",
      "Epoch = 436\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011656727733032095\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010632097677162405\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00765867782793151\n",
      "============================================================\n",
      "\n",
      "Epoch = 437\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011554099623891617\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.0001054844824718574\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076579119601487165\n",
      "============================================================\n",
      "\n",
      "Epoch = 438\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011460777301282897\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010460819254568874\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007657146168952702\n",
      "============================================================\n",
      "\n",
      "Epoch = 439\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011363661523567627\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010377918056621238\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007656380454335807\n",
      "============================================================\n",
      "\n",
      "Epoch = 440\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011269481974254288\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010297914382816864\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007655614816290374\n",
      "============================================================\n",
      "\n",
      "Epoch = 441\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011178199486529006\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010214411697513611\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076548492548087444\n",
      "============================================================\n",
      "\n",
      "Epoch = 442\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011088305037795009\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010137366139255004\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007654083769883264\n",
      "============================================================\n",
      "\n",
      "Epoch = 443\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00011001317110104629\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 0.00010056983908258777\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076533183615062755\n",
      "============================================================\n",
      "\n",
      "Epoch = 444\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001091418629338484\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.982115968859142e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007652553029670125\n",
      "============================================================\n",
      "\n",
      "Epoch = 445\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.0001083052564407259\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.906837589792944e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651787774367158\n",
      "============================================================\n",
      "\n",
      "Epoch = 446\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010745567579050053\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.8346389417936e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007651022595589722\n",
      "============================================================\n",
      "\n",
      "Epoch = 447\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010665509366246276\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.761432131725774e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007650257493330163\n",
      "============================================================\n",
      "\n",
      "Epoch = 448\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010583430370839656\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.692049980069313e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.00764949246758083\n",
      "============================================================\n",
      "\n",
      "Epoch = 449\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010505583412509135\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.621848441058236e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007648727518334072\n",
      "============================================================\n",
      "\n",
      "Epoch = 450\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010426826719755549\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.553753498960266e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647962645582239\n",
      "============================================================\n",
      "\n",
      "Epoch = 451\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010350268287585055\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.487740489199125e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007647197849317681\n",
      "============================================================\n",
      "\n",
      "Epoch = 452\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010274702586185889\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.419857457843099e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007646433129532749\n",
      "============================================================\n",
      "\n",
      "Epoch = 453\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 0.00010200607654594712\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.355492451506675e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007645668486219796\n",
      "============================================================\n",
      "\n",
      "Epoch = 454\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010128046003974372\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.289514363959627e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644903919371174\n",
      "============================================================\n",
      "\n",
      "Epoch = 455\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 0.00010055581549124177\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.226406043906922e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007644139428979236\n",
      "============================================================\n",
      "\n",
      "Epoch = 456\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.985247383703289e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.163647863590173e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076433750150363385\n",
      "============================================================\n",
      "\n",
      "Epoch = 457\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.91364489809829e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.102447651578678e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007642610677534835\n",
      "============================================================\n",
      "\n",
      "Epoch = 458\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.845525304618467e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 9.042113943592317e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641846416467081\n",
      "============================================================\n",
      "\n",
      "Epoch = 459\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.776078203130426e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.982788836115193e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007641082231825434\n",
      "============================================================\n",
      "\n",
      "Epoch = 460\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.710126231806038e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.924243659735134e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007640318123602252\n",
      "============================================================\n",
      "\n",
      "Epoch = 461\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.643591929808231e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.865946764948436e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076395540917898914\n",
      "============================================================\n",
      "\n",
      "Epoch = 462\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.579388146139587e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.808569639388082e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638790136380713\n",
      "============================================================\n",
      "\n",
      "Epoch = 463\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.51553577287991e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.750865416730651e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007638026257367075\n",
      "============================================================\n",
      "\n",
      "Epoch = 464\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.452529041023627e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.694410608825262e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007637262454741338\n",
      "============================================================\n",
      "\n",
      "Epoch = 465\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.390173169165515e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.638712442718607e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007636498728495864\n",
      "============================================================\n",
      "\n",
      "Epoch = 466\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.327272490153514e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.583710588603013e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007635735078623015\n",
      "============================================================\n",
      "\n",
      "Epoch = 467\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.265366878215719e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.53109242810641e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634971505115153\n",
      "============================================================\n",
      "\n",
      "Epoch = 468\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.202922912689328e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.477469453873002e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007634208007964641\n",
      "============================================================\n",
      "\n",
      "Epoch = 469\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.142506099944731e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.426485979813422e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007633444587163845\n",
      "============================================================\n",
      "\n",
      "Epoch = 470\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.08267339451004e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.373555917554628e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007632681242705129\n",
      "============================================================\n",
      "\n",
      "Epoch = 471\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 9.024927116107127e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.322639940192949e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631917974580859\n",
      "============================================================\n",
      "\n",
      "Epoch = 472\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.968013434747555e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.271061107959301e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007631154782783401\n",
      "============================================================\n",
      "\n",
      "Epoch = 473\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.911714628649493e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.220600372895445e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007630391667305123\n",
      "============================================================\n",
      "\n",
      "Epoch = 474\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.855713917691282e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.17154886686081e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007629628628138392\n",
      "============================================================\n",
      "\n",
      "Epoch = 475\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.799633784995965e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.122116723159832e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007628865665275579\n",
      "============================================================\n",
      "\n",
      "Epoch = 476\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.743853808096161e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.075034479589623e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076281027787090516\n",
      "============================================================\n",
      "\n",
      "Epoch = 477\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.68897973897892e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 8.026293867512375e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007627339968431181\n",
      "============================================================\n",
      "\n",
      "Epoch = 478\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.634557335680728e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.979764190109376e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007626577234434338\n",
      "============================================================\n",
      "\n",
      "Epoch = 479\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.581817500463739e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.932273118847864e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625814576710895\n",
      "============================================================\n",
      "\n",
      "Epoch = 480\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Batch 0 loss = 8.528719371120387e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.88631696293439e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007625051995253224\n",
      "============================================================\n",
      "\n",
      "Epoch = 481\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.477041369500595e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.841171284876892e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007624289490053699\n",
      "============================================================\n",
      "\n",
      "Epoch = 482\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.424725708682115e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.795898161541259e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007623527061104694\n",
      "============================================================\n",
      "\n",
      "Epoch = 483\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.373976761873552e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.7518518391546e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076227647083985835\n",
      "============================================================\n",
      "\n",
      "Epoch = 484\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.323698020255435e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.706769908427988e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007622002431927744\n",
      "============================================================\n",
      "\n",
      "Epoch = 485\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.274664218999076e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.662591468140804e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007621240231684551\n",
      "============================================================\n",
      "\n",
      "Epoch = 486\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.22594210715082e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.619504461187294e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007620478107661383\n",
      "============================================================\n",
      "\n",
      "Epoch = 487\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.177066217285976e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.576241424508392e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007619716059850617\n",
      "============================================================\n",
      "\n",
      "Epoch = 488\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.127969400087653e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.535540732906562e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618954088244632\n",
      "============================================================\n",
      "\n",
      "Epoch = 489\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.080002143473856e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.492321019498255e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007618192192835807\n",
      "============================================================\n",
      "\n",
      "Epoch = 490\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 8.032573271171212e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.451050916725896e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007617430373616524\n",
      "============================================================\n",
      "\n",
      "Epoch = 491\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.987570283924056e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.40968171993564e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007616668630579162\n",
      "============================================================\n",
      "\n",
      "Epoch = 492\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.941062266647443e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.369806599746313e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007615906963716104\n",
      "============================================================\n",
      "\n",
      "Epoch = 493\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.89585517740946e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.33355466352129e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.0076151453730197325\n",
      "============================================================\n",
      "\n",
      "Epoch = 494\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.850277211236581e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.293056787415373e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007614383858482431\n",
      "============================================================\n",
      "\n",
      "Epoch = 495\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.809490754986573e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.253799040475978e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007613622420096583\n",
      "============================================================\n",
      "\n",
      "Epoch = 496\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.771313730438098e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.211165629566003e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612861057854573\n",
      "============================================================\n",
      "\n",
      "Epoch = 497\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.734450395774767e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.172548992815143e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007612099771748788\n",
      "============================================================\n",
      "\n",
      "Epoch = 498\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.6928095400225e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.140103934110324e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007611338561771613\n",
      "============================================================\n",
      "\n",
      "Epoch = 499\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.653601012171582e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.103804157422119e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007610577427915436\n",
      "============================================================\n",
      "\n",
      "Epoch = 500\n",
      "\n",
      "============================================================\n",
      "\n",
      "| => | Batch 1 |\n",
      "\n",
      "==> Batch 0 loss = 7.619311824354064e-05\n",
      "| => | Batch 2 |\n",
      "\n",
      "==> Batch 1 loss = 7.067766642523574e-05\n",
      "---------- \n",
      "\n",
      "++ Learning rate reduced, now at = 0.007609816370172644\n"
     ]
    }
   ],
   "source": [
    "# test fourier net\n",
    "nn_fourier = FourierEmbeddedDNN(\n",
    "    layers=[30, 128, 128, 128, 1],\n",
    "    m=15, \n",
    "    freq_stds=[1.,2.,5.,10.,20.,50.,60.,70.,80.,90.,100,]\n",
    ")\n",
    "optim = torch.optim.Adam(\n",
    "    nn_fourier.parameters(),\n",
    "    lr=8e-3\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.9999)\n",
    "train(inputs, outputs, nn_fourier, optim, scheduler, 2**10, 500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdc5d9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5));\n",
    "ax[0].plot(xgrid, nn_vanilla(inputs).detach().numpy().flatten(), color=\"red\", lw=2.0, label=\"vanilla\");\n",
    "ax[0].plot(xgrid, f(xgrid), \"--\", color=\"blue\", alpha=0.6, lw=4.0);\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(xgrid, nn_fourier(inputs).detach().numpy().flatten(), color=\"red\", lw=2.0, label=\"fourier\");\n",
    "ax[1].plot(xgrid, f(xgrid), \"--\", color=\"blue\", alpha=0.6, lw=4.0);\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6208d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
