{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85d60f3",
   "metadata": {},
   "source": [
    "# Experiments using Temporal Normalizing Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52276be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.nn.init as init\n",
    "import torch.distributions.transforms as transform\n",
    "import torch.nn.functional as functional\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# set random seed\n",
    "SEED_ = 10\n",
    "np.random.seed(SEED_)\n",
    "torch.manual_seed(SEED_)\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import scipy\n",
    "import scipy.integrate\n",
    "import h5py\n",
    "\n",
    "# custom packages\n",
    "from utils.VanillaNF import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09232f9a",
   "metadata": {},
   "source": [
    "1 dimensional autoregressive flow (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mask = [\n",
    "    [0.0],\n",
    "    [0.0]\n",
    "]\n",
    "raw_mask = [torch.nn.Parameter(\n",
    "    torch.Tensor(m), requires_grad=False\n",
    ") for m in raw_mask]\n",
    "\n",
    "masks = torch.nn.ParameterList(\n",
    "    raw_mask\n",
    ")\n",
    "hidden_dim = 64\n",
    "in_dim = 1\n",
    "out_dim = in_dim\n",
    "\n",
    "_affine_flow_wrapper = lambda mask: AffineCouplingFlow(\n",
    "    in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim, \n",
    "    n_layers=4, activation=torch.nn.ReLU, mask=mask\n",
    ")\n",
    "realnvp_blocks = []\n",
    "for i in range(len(raw_mask)):\n",
    "    realnvp_blocks.append(_affine_flow_wrapper(raw_mask[i]))\n",
    "# realnvp_blocks.append(\n",
    "#     VanillaNormFlow(in_dim, out_dim, scaling=5.0)\n",
    "# )\n",
    "realnvp_blocks.append(\n",
    "    tBatchNormFlow(in_dim)\n",
    ")\n",
    "realNVP = NormalizingFlow(\n",
    "    realnvp_blocks, flow_length=1\n",
    ")\n",
    "if torch.cuda.device_count():\n",
    "    realNVP = realNVP.cuda()\n",
    "device = next(realNVP.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc059698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data from a 3-modal Gaussian\n",
    "n_samples = 2**15\n",
    "mixture_data = np.zeros([n_samples, 1])\n",
    "\n",
    "for i in range(n_samples):\n",
    "    tmp = np.random.rand()\n",
    "    if tmp < 1/3:\n",
    "        mixture_data[i] = 0.5*np.random.randn()+(-2.0)\n",
    "    elif 1/3 <= tmp <= 2/3:\n",
    "        mixture_data[i] = np.random.randn()\n",
    "    else:\n",
    "        mixture_data[i] = 0.5*np.random.randn()+(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize\n",
    "optimizer = torch.optim.Adam(realNVP.parameters(), lr = 0.0001)\n",
    "num_steps = 100\n",
    "batch_size = 2**7\n",
    "num_batches = int(np.floor(n_samples/batch_size))\n",
    "for idx_step in range(num_steps):\n",
    "    # shuffle data\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    mixture_data = mixture_data[idx, :]\n",
    "    iter_loss = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_idx = np.arange(j*batch_size, (j+1)*batch_size)\n",
    "        # get batch\n",
    "        X = mixture_data[batch_idx, :]\n",
    "        X = torch.Tensor(X).to(device = device)\n",
    "\n",
    "        ## transform data X to latent space Z\n",
    "        z, logdet = realNVP.inverse(X)\n",
    "\n",
    "        ## calculate the negative loglikelihood of X\n",
    "        loss = torch.log(z.new_tensor([2*np.pi])) + torch.mean(torch.sum(0.5*z**2, -1) - logdet)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        iter_loss += loss.item()\n",
    "        if j % 500 == 0:\n",
    "            print(loss.item())\n",
    "    if (idx_step + 1) % 2 == 0:\n",
    "        print(f\"idx_steps: {idx_step:}, loss: {iter_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c574e90",
   "metadata": {},
   "source": [
    "2d stochastic Van der Pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5867fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time dimension is not transformed\n",
    "raw_mask = [[1.0, 1.0, 0.0],\n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],         \n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],         \n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],\n",
    "             [1.0, 0.0, 1.0]]\n",
    "\n",
    "raw_mask = [torch.nn.Parameter(\n",
    "    torch.Tensor(m), requires_grad=False\n",
    ") for m in raw_mask]\n",
    "\n",
    "\n",
    "masks = torch.nn.ParameterList(\n",
    "    raw_mask\n",
    ")\n",
    "hidden_dim = 64\n",
    "in_dim = 2\n",
    "out_dim = in_dim\n",
    "# create blocks for RealNVP\n",
    "_affine_flow_wrapper = lambda mask: tAffineCouplingFlow(\n",
    "    in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim, \n",
    "    n_layers=6, activation=torch.nn.ReLU, mask=mask\n",
    ")\n",
    "\n",
    "realnvp_blocks = []\n",
    "for i in range(len(raw_mask)):\n",
    "    realnvp_blocks.append(_affine_flow_wrapper(raw_mask[i]))\n",
    "realnvp_blocks.append(tVanillaNormFlow(in_dim, out_dim, scaling=5.0))\n",
    "        \n",
    "# create realnvp\n",
    "realNVP = NormalizingFlow(\n",
    "    realnvp_blocks, flow_length=1\n",
    ")\n",
    "if torch.cuda.device_count():\n",
    "    realNVP = realNVP.cuda()\n",
    "device = next(realNVP.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simultate van der pol with random normal initial condition\n",
    "def rhs(z, t, mu=1.0):\n",
    "    \"\"\" \n",
    "        Right hand side of the van der pol oscillator.\n",
    "        Formula taken from Tyler's nonlocal paper.\n",
    "    \"\"\"\n",
    "    dx = z[1]\n",
    "    dy = mu * (1 - z[0]**2)*z[1] - z[0]\n",
    "    dzdt = [dx, dy]\n",
    "    return dzdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d716d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_simulated = True\n",
    "num_paths = 500\n",
    "t_end = 20.0\n",
    "nt = 500+1\n",
    "tgrid = np.linspace(0.0, t_end, nt)\n",
    "dt = tgrid[1]-tgrid[0]\n",
    "paths = np.zeros([num_paths, nt, 3])\n",
    "mean = np.array([1, 0])\n",
    "covmat = 0.01*np.eye(2)\n",
    "if not load_simulated:\n",
    "    for i in range(num_paths):\n",
    "        z0 = np.random.multivariate_normal(mean, covmat)\n",
    "        sol = scipy.integrate.odeint(rhs, z0, tgrid)\n",
    "        paths[i, :, 0] = tgrid\n",
    "        paths[i, :, 1:] = sol\n",
    "else:\n",
    "    # load pre-generated .mat file\n",
    "    with h5py.File('VanderPol.mat', 'r') as f:\n",
    "        data = f['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(1);\n",
    "    plt.plot(paths[:, :, 1:][i, :, 0], paths[:, :, 1:][i, :, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using RealNVP\n",
    "optimizer = torch.optim.Adam(realNVP.parameters(), lr = 0.0005)\n",
    "num_steps = 100\n",
    "\n",
    "## the following loop learns the RealNVP_2D model by data\n",
    "## in each loop, data is dynamically sampled from the scipy moon dataset\n",
    "for idx_step in range(num_steps):\n",
    "    # shuffle paths\n",
    "    idx = np.arange(num_paths)\n",
    "    np.random.shuffle(idx)\n",
    "    paths = paths[idx, :, :]\n",
    "    iter_loss = 0\n",
    "    for j in range(num_paths):\n",
    "        ## get a path from all paths\n",
    "        X = paths[j, :, :]\n",
    "        X = torch.Tensor(X).to(device = device)\n",
    "\n",
    "        ## transform data X to latent space Z\n",
    "        z, logdet = realNVP.inverse(X)\n",
    "\n",
    "        ## calculate the negative loglikelihood of X\n",
    "        loss = torch.log(torch.tensor(100.0)) + torch.log(z.new_tensor([2*np.pi])) + \\\n",
    "            torch.mean(torch.sum(0.5*100.0*(z[:, 1:]-torch.tensor([1,0]))**2, -1) - logdet)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        iter_loss += loss.item()\n",
    "        if j % 500 == 0:\n",
    "            print(loss.item())\n",
    "    if (idx_step + 1) % 2 == 0:\n",
    "        print(f\"idx_steps: {idx_step:}, loss: {iter_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min, x1_max = -5.0, 5.0\n",
    "x2_min, x2_max = -5.0, 5.0\n",
    "N = 200\n",
    "x1_grid = np.linspace(x1_min, x1_max, N)\n",
    "x2_grid = np.linspace(x2_min, x2_max, N)\n",
    "\n",
    "dx = x1_grid[1]-x1_grid[0]\n",
    "assert dx == x2_grid[2]-x2_grid[1]\n",
    "# meshgrid\n",
    "x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "# get list of coordinates\n",
    "x_data = np.concatenate((x1_mesh.ravel().reshape(-1,1), x2_mesh.ravel().reshape(-1,1)), axis=1)\n",
    "x_data = torch.tensor(x_data)\n",
    "\n",
    "\n",
    "t = 2.0\n",
    "xt_data = torch.cat([torch.Tensor.repeat(torch.tensor(t), x_data.shape[0]).reshape(-1, 1), x_data], 1)\n",
    "zt_data, jac = realNVP.inverse(xt_data)\n",
    "\n",
    "p_x = torch.exp( torch.log(torch.tensor(100.0)) + torch.log(2*torch.tensor(torch.pi)) - \\\n",
    "            torch.sum(0.5*100.0*(zt_data[:, 1:]-torch.tensor([1,0]))**2, -1) - jac ).reshape(N, N).detach().numpy()\n",
    "\n",
    "plt.contourf(x1_mesh, x2_mesh, p_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44466d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate solution for a range of times\n",
    "err_tgrid = np.arange(0.0, 10.0, 0.1)\n",
    "err_nt = len(err_tgrid)\n",
    "all_preds = np.zeros([err_nt, N, N])\n",
    "for i in range(err_nt):\n",
    "    t = err_tgrid[i]\n",
    "    if i % 10 == 0:\n",
    "        print(\"Time step = {}\".format(t))\n",
    "    x1_min, x1_max = -5.0, 5.0\n",
    "    x2_min, x2_max = -5.0, 5.0\n",
    "    N = 200\n",
    "    x1_grid = np.linspace(x1_min, x1_max, N)\n",
    "    x2_grid = np.linspace(x2_min, x2_max, N)\n",
    "\n",
    "    dx = x1_grid[1]-x1_grid[0]\n",
    "    assert dx == x2_grid[2]-x2_grid[1]\n",
    "    # meshgrid\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "    # get list of coordinates\n",
    "    x_data = np.concatenate((x1_mesh.ravel().reshape(-1,1), x2_mesh.ravel().reshape(-1,1)), axis=1)\n",
    "    x_data = torch.tensor(x_data)\n",
    "\n",
    "    xt_data = torch.cat([torch.Tensor.repeat(torch.tensor(t), x_data.shape[0]).reshape(-1, 1), x_data], 1)\n",
    "    zt_data, jac = realNVP.inverse(xt_data)\n",
    "\n",
    "    p_x = torch.exp( torch.log(torch.tensor(100.0)) + torch.log(2*torch.tensor(torch.pi)) - \\\n",
    "                torch.sum(0.5*100.0*(zt_data[:, 1:]-torch.tensor([1,0]))**2, -1) - jac ).reshape(N, N).detach().numpy()\n",
    "    # replace NaN's with 0.0\n",
    "    #p_x = np.nan_to_num(p_x)\n",
    "    # save un-normalized prediction\n",
    "    all_preds[i, :, :] = p_x\n",
    "    # divide by constant to integrate to 1\n",
    "    int_p_x = np.trapz(np.trapz(p_x, dx=dx), dx=dx)\n",
    "    p_x = p_x / int_p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53473511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all graphs\n",
    "%matplotlib inline\n",
    "import time\n",
    "from IPython import display\n",
    "for i in range(0, err_nt):\n",
    "    plt.figure(1)\n",
    "    # display predicted solution i\n",
    "    plot_density = all_preds[i, :, :]\n",
    "    plt.contourf(x1_mesh, x2_mesh, plot_density);\n",
    "    plt.title(\"Time = {}\".format(err_tgrid[i]))\n",
    "    if err_tgrid[i]>20:\n",
    "        plt.title(\"Time = {}, out of sample\".format(err_tgrid[i]))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf());\n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b7da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
