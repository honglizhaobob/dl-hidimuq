{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1675631d",
   "metadata": {},
   "source": [
    "# Experiments using Temporal Normalizing Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aafd34",
   "metadata": {},
   "source": [
    "## Training 2d Brownian particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f95dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.nn.init as init\n",
    "import torch.distributions.transforms as transform\n",
    "import torch.nn.functional as functional\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# set random seed\n",
    "SEED_ = 10\n",
    "np.random.seed(SEED_)\n",
    "torch.manual_seed(SEED_)\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "# custom packages\n",
    "from utils.VanillaNF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time dimension is not transformed\n",
    "raw_mask = [[1.0, 1.0, 0.0],\n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],         \n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],         \n",
    "             [1.0, 0.0, 1.0],\n",
    "             [1.0, 1.0, 0.0],\n",
    "             [1.0, 0.0, 1.0]]\n",
    "\n",
    "raw_mask = [torch.nn.Parameter(\n",
    "    torch.Tensor(m), requires_grad=False\n",
    ") for m in raw_mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "masks = torch.nn.ParameterList(\n",
    "    raw_mask\n",
    ")\n",
    "hidden_dim = 64\n",
    "in_dim = 2\n",
    "out_dim = in_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create blocks for RealNVP\n",
    "_affine_flow_wrapper = lambda mask: tAffineCouplingFlow(\n",
    "    in_dim=in_dim, hidden_dim=hidden_dim, out_dim=out_dim, \n",
    "    n_layers=6, activation=torch.nn.ReLU, mask=mask\n",
    ")\n",
    "realnvp_blocks = []\n",
    "for i in range(len(raw_mask)):\n",
    "    realnvp_blocks.append(_affine_flow_wrapper(raw_mask[i]))\n",
    "    if (i + 1) % 2 == 0:\n",
    "        realnvp_blocks.append(tVanillaNormFlow(in_dim, out_dim))\n",
    "\n",
    "realnvp_blocks.append(\n",
    "    tVanillaNormFlow(in_dim, out_dim)\n",
    ")\n",
    "\n",
    "# create realnvp\n",
    "realNVP = NormalizingFlow(\n",
    "    realnvp_blocks, flow_length=1\n",
    ")\n",
    "if torch.cuda.device_count():\n",
    "    realNVP = realNVP.cuda()\n",
    "device = next(realNVP.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c277723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate n-d Brownian motion\n",
    "num_paths = 1000\n",
    "t_start, t_end = 0.0, 5.0\n",
    "# discretize\n",
    "nt = 100+1\n",
    "tgrid = np.linspace(t_start, t_end, nt)\n",
    "dt = tgrid[1]-tgrid[0]\n",
    "# record trajectories along with time\n",
    "\n",
    "# number of dimensions\n",
    "d = 2\n",
    "dims = [num_paths] + [nt] + [1+d]\n",
    "paths = np.zeros(dims)\n",
    "for i in range(num_paths):\n",
    "    # initial condition is dirac at (0,0)\n",
    "    paths[i, 0, 1:] = 0.0\n",
    "    for j in range(1, nt):\n",
    "        t_j = tgrid[j]\n",
    "        paths[i, j, 0] = t_j\n",
    "        # independent increment\n",
    "        paths[i, j, 1:] = paths[i, j-1, 1:] + np.sqrt(dt)*np.random.randn(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    plt.figure(1)\n",
    "    plt.plot(paths[i, :][:, 1], paths[i, :][:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc186254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using RealNVP\n",
    "optimizer = torch.optim.Adam(realNVP.parameters(), lr = 0.0005)\n",
    "num_steps = 100\n",
    "\n",
    "## the following loop learns the RealNVP_2D model by data\n",
    "## in each loop, data is dynamically sampled from the scipy moon dataset\n",
    "for idx_step in range(num_steps):\n",
    "    # shuffle paths\n",
    "    idx = np.arange(num_paths)\n",
    "    np.random.shuffle(idx)\n",
    "    paths = paths[idx, :, :]\n",
    "    iter_loss = 0\n",
    "    for j in range(num_paths):\n",
    "        ## get a path from all paths\n",
    "        X = paths[j, :, :]\n",
    "        X = torch.Tensor(X).to(device = device)\n",
    "\n",
    "        ## transform data X to latent space Z\n",
    "        z, logdet = realNVP.inverse(X)\n",
    "\n",
    "        ## calculate the negative loglikelihood of X\n",
    "        loss = torch.log(z.new_tensor([2*np.pi])) + torch.mean(torch.sum(0.5*z**2, -1) - logdet)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        iter_loss += loss.item()\n",
    "        if j % 500 == 0:\n",
    "            print(loss.item())\n",
    "    if (idx_step + 1) % 2 == 0:\n",
    "        print(f\"idx_steps: {idx_step:}, loss: {iter_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "dims = [1000] + [nt] + [1+d]\n",
    "new_z = np.zeros(dims)\n",
    "for i in range(10):\n",
    "    # initial condition is normal\n",
    "    new_z[i, :, 0] = tgrid\n",
    "    new_z[i, :, 1:] = np.random.randn(nt, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.zeros(dims)\n",
    "for i in range(10):\n",
    "    new_x[i, :, :] = realNVP(torch.Tensor(new_z[i, :, :]))[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8515a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.figure(1)\n",
    "    plt.plot(new_x[i, :][:, 1], new_x[i, :][:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate density at different times\n",
    "x1_min, x1_max = -6.0, 6.0\n",
    "x2_min, x2_max = -6.0, 6.0\n",
    "N = 200\n",
    "x1_grid = np.linspace(x1_min, x1_max, N)\n",
    "x2_grid = np.linspace(x2_min, x2_max, N)\n",
    "\n",
    "dx = x1_grid[1]-x1_grid[0]\n",
    "assert dx == x2_grid[2]-x2_grid[1]\n",
    "# meshgrid\n",
    "x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "# get list of coordinates\n",
    "x_data = np.concatenate((x1_mesh.ravel().reshape(-1,1), x2_mesh.ravel().reshape(-1,1)), axis=1)\n",
    "x_data = torch.tensor(x_data)\n",
    "t = 0.5\n",
    "xt_data = torch.cat([torch.Tensor.repeat(torch.tensor(t), x_data.shape[0]).reshape(-1, 1), x_data], 1)\n",
    "zt_data, jac = realNVP.inverse(xt_data)\n",
    "p_x = torch.exp(-(torch.sum(0.5*zt_data**2, -1) - jac + torch.log(2*torch.tensor(torch.pi)))).reshape(N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "realNVP.inverse(xt_data[0, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "realNVP.bijectors[6].inverse(xt_data[0, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "realNVP.bijectors[5].inverse(realNVP.bijectors[6].inverse(xt_data[4, :].reshape(1, -1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ffa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = p_x.detach().numpy()\n",
    "#p_x = np.nan_to_num(p_x)\n",
    "plt.contourf(x1_mesh, x2_mesh, p_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_p_x = np.trapz(np.trapz(p_x, dx=dx), dx=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(x1_mesh, x2_mesh, p_x/int_p_x, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d81a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_x/int_p_x).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5288073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the diffusion directly with dirac initial condition\n",
    "x1_grid, x2_grid;\n",
    "x1_mesh, x2_mesh;\n",
    "nt_pde = 10001\n",
    "tgrid_pde = np.linspace(t_start, t_end, nt_pde)\n",
    "dt_pde = tgrid_pde[1]-tgrid_pde[0]\n",
    "# with dirac initial condition, solution to Fokker-Planck is closed\n",
    "# https://math.stackexchange.com/questions/3924499/analytical-solution-to-2d-diffusion-equation-with-a-drift-term\n",
    "def analytic_solution(t, x, y):\n",
    "    return (1/(2*np.pi*t))*np.exp(-(x**2+y**2)/(2*t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad332da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "t_query = 0.5\n",
    "ax2.plot_surface(x1_mesh, x2_mesh, analytic_solution(t_query, x1_mesh, x2_mesh), cmap=cm.coolwarm, \n",
    "                linewidth=0.0, antialiased=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e21c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_solution(t_query, x1_mesh, x2_mesh).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f20f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(((p_x/int_p_x)-analytic_solution(t_query, x1_mesh, x2_mesh))**2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ddcecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute L^2 error for a range of times\n",
    "err_tgrid = np.arange(0.025, 6.025, 0.025)\n",
    "err_nt = len(err_tgrid)\n",
    "l2_error = np.zeros(err_nt)\n",
    "rel_l2_error = np.zeros(err_nt)\n",
    "all_preds = np.zeros([err_nt, N, N])\n",
    "for i in range(err_nt):\n",
    "    t = err_tgrid[i]\n",
    "    if i % 10 == 0:\n",
    "        print(\"Time step = {}\".format(t))\n",
    "    # predict with NF\n",
    "    x1_min, x1_max = -6.0, 6.0\n",
    "    x2_min, x2_max = -6.0, 6.0\n",
    "    N = 200\n",
    "    x1_grid = np.linspace(x1_min, x1_max, N)\n",
    "    x2_grid = np.linspace(x2_min, x2_max, N)\n",
    "\n",
    "    dx = x1_grid[1]-x1_grid[0]\n",
    "    assert dx == x2_grid[2]-x2_grid[1]\n",
    "    # meshgrid\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
    "    # get list of coordinates\n",
    "    x_data = np.concatenate((x1_mesh.ravel().reshape(-1,1), x2_mesh.ravel().reshape(-1,1)), axis=1)\n",
    "    x_data = torch.tensor(x_data)\n",
    "    xt_data = torch.cat([torch.Tensor.repeat(torch.tensor(t), x_data.shape[0]).reshape(-1, 1), x_data], 1)\n",
    "    zt_data, jac = realNVP.inverse(xt_data)\n",
    "    p_x = torch.exp(-(torch.sum(0.5*zt_data**2, -1) - jac + torch.log(2*torch.tensor(torch.pi)))).reshape(N, N)\n",
    "    p_x = p_x.detach().numpy()\n",
    "    # replace NaN's with 0.0\n",
    "    p_x = np.nan_to_num(p_x)\n",
    "    # save un-normalized prediction\n",
    "    all_preds[i, :, :] = p_x\n",
    "    # divide by constant to integrate to 1\n",
    "    int_p_x = np.trapz(np.trapz(p_x, dx=dx), dx=dx)\n",
    "    p_x = p_x / int_p_x\n",
    "    \n",
    "    \n",
    "    # compare with analytic\n",
    "    p_x_analytic = analytic_solution(t, x1_mesh, x2_mesh)\n",
    "    # divide bby constant to integrate to 1\n",
    "    int_p_x_analytic = np.trapz(np.trapz(p_x_analytic, dx=dx), dx=dx)\n",
    "    p_x_analytic = p_x_analytic / int_p_x_analytic\n",
    "    # compare error between predicted and approximated\n",
    "    l2_error[i] = ((p_x - p_x_analytic)**2).sum() * dx * dx\n",
    "    rel_l2_error[i] = l2_error[i] / ((p_x_analytic**2).sum() * dx * dx)\n",
    "    if i % 10 == 0:\n",
    "        print(rel_l2_error[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39964f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_tgrid[39:], l2_error[39:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b98602",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(err_tgrid[39:], rel_l2_error[39:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223608b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot all graphs\n",
    "%matplotlib inline\n",
    "import time\n",
    "from IPython import display\n",
    "for i in range(0, err_nt):\n",
    "    plt.figure(1)\n",
    "    # display predicted solution i\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    # normalize the density\n",
    "    plot_density = all_preds[i, :, :]\n",
    "    int_density = np.trapz(np.trapz(plot_density, dx=dx), dx=dx)\n",
    "    plot_density = plot_density / int_density\n",
    "    ax[0].contourf(x1_mesh, x2_mesh, plot_density);\n",
    "    ax[0].set_title(r\"$t = {}$\".format(np.round(err_tgrid[i], 3)))\n",
    "    ax[1].contourf(x1_mesh, x2_mesh, analytic_solution(err_tgrid[i], x1_mesh, x2_mesh));\n",
    "    ax[1].set_title(r\"$t = {}$\".format(np.round(err_tgrid[i], 3)))\n",
    "    ax[2].plot(err_tgrid[0:i], rel_l2_error[0:i], color='red', lw=1.5)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf());\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3185b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(realNVP.state_dict(), \"trained_models/Brownian_Motion_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f6dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "47601158b52ab6205fc590a501992e1857ff6a6e9eb9288af5c971d04ddf977c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
